
@inproceedings{kohlbrecher_flexible_2011,
	address = {Kyoto, Japan},
	title = {A flexible and scalable {SLAM} system with full {3D} motion estimation},
	isbn = {978-1-61284-769-6 978-1-61284-770-2 978-1-61284-768-9},
	url = {http://ieeexplore.ieee.org/document/6106777/},
	doi = {10.1109/SSRR.2011.6106777},
	abstract = {For many applications in Urban Search and Rescue (USAR) scenarios robots need to learn a map of unknown environments. We present a system for fast online learning of occupancy grid maps requiring low computational resources. It combines a robust scan matching approach using a LIDAR system with a 3D attitude estimation system based on inertial sensing. By using a fast approximation of map gradients and a multi-resolution grid, reliable localization and mapping capabilities in a variety of challenging environments are realized. Multiple datasets showing the applicability in an embedded hand-held mapping system are provided. We show that the system is sufﬁciently accurate as to not require explicit loop closing techniques in the considered scenarios. The software is available as an open source package for ROS.},
	language = {en},
	urldate = {2020-03-06},
	booktitle = {2011 {IEEE} {International} {Symposium} on {Safety}, {Security}, and {Rescue} {Robotics}},
	publisher = {IEEE},
	author = {Kohlbrecher, Stefan and von Stryk, Oskar and Meyer, Johannes and Klingauf, Uwe},
	month = nov,
	year = {2011},
	pages = {155--160},
}

@inproceedings{moleski_effects_2021,
	title = {Effects of {Velocity} and {Known} {Pose} {Injection} {Rate} on {Scan} {Matching} {2D} {SLAM} {Accuracy}},
	copyright = {All rights reserved},
	url = {https://arc.aiaa.org/doi/abs/10.2514/6.2021-1582},
	doi = {10.2514/6.2021-1582},
	abstract = {Accurate localization estimation in a global or local frame is needed for a navigation solution which results in safe and efficient vehicle guidance. SLAM is a common approach to vehicle localization in GPS denied environments, but solutions often require odometry that may not be available to UAVs. ICP and Hector SLAM are common approaches for vehicle localization that rely on scan matching without the need for odometry, however both suffer when operating in long corridors with limited features for 2D single laser LiDAR scan matching. The present work injected localization solutions for the ICP method with known pose while the vehicle injection rate to velocity ratio was varied to explore their effects on average cross track error, accumulated position error, and to compare to Hector SLAM, another common method for scan matching based SLAM. The impact of the present work is that there has been an investigation on how vehicle velocity and known pose injection rate effect cumulative localization accuracy using scan matching ICP based SLAM techniques. Performance was measured using the cross track error and accumulative position error of ICP and Hector SLAM when compared to known vehicle position in simulation. Results may be used to identify system constraints such as maximum vehicle velocity for a successful mission completion given a known position injection rate and acceptable localization error.},
	urldate = {2021-02-01},
	booktitle = {{AIAA} {Scitech} 2021 {Forum}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Moleski, Travis W. and Wilhelm, Jay},
	month = jan,
	year = {2021},
	note = {\_eprint: https://arc.aiaa.org/doi/pdf/10.2514/6.2021-1582},
}

@incollection{hutchison_hector_2014,
	address = {Berlin, Heidelberg},
	title = {Hector {Open} {Source} {Modules} for {Autonomous} {Mapping} and {Navigation} with {Rescue} {Robots}},
	volume = {8371},
	isbn = {978-3-662-44467-2 978-3-662-44468-9},
	url = {http://link.springer.com/10.1007/978-3-662-44468-9_58},
	abstract = {Key abilities for robots deployed in urban search and rescue tasks include autonomous exploration of disaster sites and recognition of victims and other objects of interest. In this paper, we present related open source software modules for the development of such complex capabilities which include hector slam for self-localization and mapping in a degraded urban environment. All modules have been successfully applied and tested originally in the RoboCup Rescue competition. Up to now they have already been re-used and adopted by numerous international research groups for a wide variety of tasks. Recently, they have also become part of the basis of a broader initiative for key open source software modules for urban search and rescue robots.},
	language = {en},
	urldate = {2020-03-06},
	booktitle = {{RoboCup} 2013: {Robot} {World} {Cup} {XVII}},
	publisher = {Springer Berlin Heidelberg},
	author = {Kohlbrecher, Stefan and Meyer, Johannes and Graber, Thorsten and Petersen, Karen and Klingauf, Uwe and von Stryk, Oskar},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Kobsa, Alfred and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Terzopoulos, Demetri and Tygar, Doug and Weikum, Gerhard and Behnke, Sven and Veloso, Manuela and Visser, Arnoud and Xiong, Rong},
	year = {2014},
	doi = {10.1007/978-3-662-44468-9_58},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {624--631},
	file = {Submitted Version:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/Q5E3TQVM/Kohlbrecher et al. - 2014 - Hector Open Source Modules for Autonomous Mapping .pdf:application/pdf},
}

@article{durrant-whyte_simultaneous_nodate,
	title = {Simultaneous {Localisation} and {Mapping} ({SLAM}): {Part} {I} {The} {Essential} {Algorithms}},
	abstract = {This tutorial provides an introduction to Simultaneous Localisation and Mapping (SLAM) and the extensive research on SLAM that has been undertaken over the past decade. SLAM is the process by which a mobile robot can build a map of an environment and at the same time use this map to compute it’s own location. The past decade has seen rapid and exciting progress in solving the SLAM problem together with many compelling implementations of SLAM methods. Part I of this tutorial (this paper), describes the probabilistic form of the SLAM problem, essential solution methods and signiﬁcant implementations. Part II of this tutorial will be concerned with recent advances in computational methods and new formulations of the SLAM problem for large scale and complex environments.},
	language = {en},
	author = {Durrant-Whyte, Hugh and Bailey, Tim},
	pages = {9},
}

@article{bailey_simultaneous_2006,
	title = {Simultaneous localization and mapping ({SLAM}): part {II}},
	volume = {13},
	issn = {1070-9932},
	shorttitle = {Simultaneous localization and mapping ({SLAM})},
	url = {http://ieeexplore.ieee.org/document/1678144/},
	doi = {10.1109/MRA.2006.1678144},
	language = {en},
	number = {3},
	urldate = {2020-02-20},
	journal = {IEEE Robotics \& Automation Magazine},
	author = {Bailey, T. and Durrant-Whyte, H.},
	month = sep,
	year = {2006},
	pages = {108--117},
}

@incollection{moleski_trilateration_nodate,
	title = {Trilateration {Positioning} {Using} {Hybrid} {Camera}-{LiDAR} {System}},
	copyright = {All rights reserved},
	url = {https://arc.aiaa.org/doi/abs/10.2514/6.2020-0393},
	abstract = {Accurate position estimation in a global or local frame is needed for a navigation solution which results in safe and efficient vehicle guidance. Visual identification of landmarks and laser ranging was investigated to bridge a gap between accuracy and computational needs for position estimation. Visual classification of landmarks in a scene and laser ranging was hybridized using a camera and scanning LiDAR facing the same direction. The hybrid landmark localization process was explored and performance was evaluated using computer vision from simulated environments. The hybrid method resulted in an average position error of 0.08 m in 2D, but when extended to 3D the error increased due to limited landmark separation in the third direction. The developed hybrid camera-LiDAR provided a successful position estimation for different landmark views.},
	urldate = {2021-02-01},
	booktitle = {{AIAA} {Scitech} 2020 {Forum}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Moleski, Travis W. and Wilhelm, Jay},
	doi = {10.2514/6.2020-0393},
	note = {\_eprint: https://arc.aiaa.org/doi/pdf/10.2514/6.2020-0393},
}

@article{yadav_road_2018,
	title = {{ROAD} {SURFACE} {DETECTION} {FROM} {MOBILE} {LIDAR} {DATA}},
	volume = {IV-5},
	doi = {10.5194/isprs-annals-IV-5-95-2018},
	abstract = {The accurate three-dimensional road surface information is highly useful for health assessment and maintenance of roads. It is basic information for further analysis in several applications including road surface settlement, pavement condition assessment and slope collapse. Mobile LiDAR system (MLS) is frequently used now a days to collect detail road surface and its surrounding information in terms three-dimensional (3D) point cloud. Extraction of road surface from volumetric point cloud data is still in infancy stage because of heavy data processing requirement and the complexity in the road environment. The extraction of roads especially rural road, where road-curb is not present is very tedious job especially in Indian roadway settings. Only a few studies are available, and none for Indian roads, in the literature for rural road detection. The limitations of existing studies are in terms of their lower accuracy, very slow speed of data processing and detection of other objects having similar characteristics as the road surface. A fast and accurate method is proposed for LiDAR data points of road surface detection, keeping in mind the essence of road surface extraction especially for Indian rural roads. The Mobile LiDAR data in XYZI format is used as input in the proposed method. First square gridding is performed and ground points are roughly extracted. Then planar surface detection using mathematical framework of principal component analysis (PCA) is performed and further road surface points are detected using similarity in intensity and height difference of road surface pointe in their neighbourhood.
A case study was performed on the MLS data points captured along wide-street (two-lane road without curb) of 156m length along rural roadway site in the outskirt of Bengaluru city (South-West of India). The proposed algorithm was implemented on the MLS data of test site and its performance was evaluated it terms of recall, precision and overall accuracy that were 95.27\%, 98.85\% and 94.23\%, respectively. The algorithm was found computationally time efficient. A 7.6 million MLS data points of size 27.1MB from test site were processed in 24 minutes using the available computational resources. The proposed method is found to work even for worst case scenarios, i.e., complex road environments and rural roads, where road boundary is not clear and generally merged with road-side features.},
	journal = {ISPRS Annals of Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Yadav, Manohar and Lohani, Bharat and Singh, Ajoy},
	month = nov,
	year = {2018},
	pages = {95--101},
	file = {Full Text:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/YHBPLZTP/Yadav et al. - 2018 - ROAD SURFACE DETECTION FROM MOBILE LIDAR DATA.pdf:application/pdf},
}

@article{milenkovic_roughness_2018,
	title = {Roughness {Spectra} {Derived} from {Multi}-{Scale} {LiDAR} {Point} {Clouds} of a {Gravel} {Surface}: {A} {Comparison} and {Sensitivity} {Analysis}},
	volume = {7},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = {Roughness {Spectra} {Derived} from {Multi}-{Scale} {LiDAR} {Point} {Clouds} of a {Gravel} {Surface}},
	url = {https://www.mdpi.com/2220-9964/7/2/69},
	doi = {10.3390/ijgi7020069},
	abstract = {The roughness spectrum (i.e., the power spectral density) is a derivative of digital terrain models (DTMs) that is used as a surface roughness descriptor in many geomorphological and physical models. Although light detection and ranging (LiDAR) has become one of the main data sources for DTM calculation, it is still unknown how roughness spectra are affected when calculated from different LiDAR point clouds, or when they are processed differently. In this paper, we used three different LiDAR point clouds of a 1 m × 10 m gravel plot to derive and analyze the roughness spectra from the interpolated DTMs. The LiDAR point clouds were acquired using terrestrial laser scanning (TLS), and laser scanning from both an unmanned aerial vehicle (ULS) and an airplane (ALS). The corresponding roughness spectra are derived first as ensemble averaged periodograms and then the spectral differences are analyzed with a dB threshold that is based on the 95\% confidence intervals of the periodograms. The aim is to determine scales (spatial wavelengths) over which the analyzed spectra can be used interchangeably. The results show that one TLS scan can measure the roughness spectra for wavelengths larger than 1 cm (i.e., two times its footprint size) and up to 10 m, with spectral differences less than 0.65 dB. For the same dB threshold, the ULS and TLS spectra can be used interchangeably for wavelengths larger than about 1.2 dm (i.e., five times the ULS footprint size). However, the interpolation parameters should be optimized to make the ULS spectrum more accurate at wavelengths smaller than 1 m. The plot size was, however, too small to draw particular conclusions about ALS spectra. These results show that novel ULS data has a high potential to replace TLS for roughness spectrum calculation in many applications.},
	language = {en},
	number = {2},
	urldate = {2021-10-14},
	journal = {ISPRS International Journal of Geo-Information},
	author = {Milenković, Milutin and Ressl, Camillo and Karel, Wilfried and Mandlburger, Gottfried and Pfeifer, Norbert},
	month = feb,
	year = {2018},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {gravel roughness, laser scanning, power spectral density, spectral slope, surface interpolation, UAV},
	pages = {69},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/LK5MJ6CJ/Milenković et al. - 2018 - Roughness Spectra Derived from Multi-Scale LiDAR P.pdf:application/pdf;Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/ZZQA9D63/htm.html:text/html},
}

@article{moretto_assessing_nodate,
	title = {Assessing morphological changes in gravel-bed rivers using {LiDAR} data and colour bathymetry},
	abstract = {Estimating underwater features of channel bed surfaces without the use of bathymetric sensors results in very high levels of uncertainty. A novel approach to create more accurate and detailed Digital Terrain Models (DTMs) integrates LiDAR-derived elevations of dry surfaces, water depth of wetted areas derived from aerial photos and a predictive depth–colour relationship. This method was applied in three different sub-reaches of a northeastern Italian gravel-bed river (Brenta) before and after flood events occurred in November and December 2010 (recurrence interval: 8 and 10 years). From the data collected through channel field survey, a regression model which calculates channel depths using the correct intensity of three colour bands was implemented. LiDAR and depth points were merged and interpolated into a DTM which features an average error of ±18 cm. The morphological evolution and the sediment volume change calculated through a difference of DTMs shows deposition and erosion areas, indicating a deficit which reduces as it goes downstream.},
	language = {en},
	author = {Moretto, J and Rigon, E and Mao, L and Delai, F and Picco, L and Lenzi, M A},
	pages = {9},
	file = {Moretto et al. - Assessing morphological changes in gravel-bed rive.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/DVSSPCHZ/Moretto et al. - Assessing morphological changes in gravel-bed rive.pdf:application/pdf},
}

@article{anderson_gravel_2013,
	title = {The {Gravel} {Pit} {Lidar}-{Intensity} {Imagery} {Dataset}},
	abstract = {This dataset contains intensity and range data collected using a high-framerate, two-axis scanning lidar over ten individual traversals of the same 1.1km path. The experiment was conducted over a full diurnal cycle at a planetary analogue in Sudbury, Ontario, Canada and should be of interest to researchers who develop algorithms for visual odometry, simultaneous localization and mapping (SLAM) or place recognition in three-dimensional, unstructured, and natural environments. Catering to the strength of state-of-the-art SLAM techniques, this dataset creates ample opportunity for loop closure; in addition to having multiple traversals of the same path, the trajectory was speciﬁcally chosen to include both small- and large-scale loops. The lidar scans were taken with a 480×360 resolution at 2Hz, while driving roughly 0.3-0.4 meters per second; therefore, one of the challenges in using this dataset is to compensate for the motion distortion present in the data (resulting from the ‘rolling-shutter’ effect). Ground truth position is provided by means of a Thales DG-16 Differential GPS unit.},
	language = {en},
	author = {Anderson, Sean and McManus, Colin and Dong, Hang and Beerepoot, Erik and Barfoot, Timothy D},
	year = {2013},
	pages = {7},
	file = {Anderson et al. - 2013 - The Gravel Pit Lidar-Intensity Imagery Dataset.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/27X2IQEC/Anderson et al. - 2013 - The Gravel Pit Lidar-Intensity Imagery Dataset.pdf:application/pdf},
}

@article{kaasalainen_radiometric_2009,
	title = {Radiometric {Calibration} of {LIDAR} {Intensity} {With} {Commercially} {Available} {Reference} {Targets}},
	volume = {47},
	issn = {1558-0644},
	doi = {10.1109/TGRS.2008.2003351},
	abstract = {We present a new approach for radiometric calibration of light detection and ranging (LIDAR) intensity data and demonstrate an application of this method to natural targets. The method is based on 1) using commercially available sand and gravel as reference targets and 2) the calibration of these reference targets in the laboratory conditions to know their backscatter properties. We have investigated the target properties crucial for accurate and consistent reflectance calibration and present a set of ideal targets easily available for calibration purposes. The first results from LIDAR-based brightness measurement of grass and sand show that the gravel-based calibration approach works in practice, is cost effective, and produces statistically meaningful results: Comparison of results from two separate airborne laser scanning campaigns shows that the relative calibration produces repeatable reflectance values.},
	number = {2},
	journal = {IEEE Transactions on Geoscience and Remote Sensing},
	author = {Kaasalainen, Sanna and Hyyppa, Hannu and Kukko, Antero and Litkey, Paula and Ahokas, Eero and Hyyppa, Juha and Lehner, Hubert and Jaakkola, Anttoni and Suomalainen, Juha and Akujarvi, Altti and Kaasalainen, Mikko and Pyysalo, Ulla},
	month = feb,
	year = {2009},
	note = {Conference Name: IEEE Transactions on Geoscience and Remote Sensing},
	keywords = {Backscatter, Brightness, Calibration, Costs, Hyperspectral sensors, laser measurements, laser radar, Laser radar, laser radiation effects, Laser theory, Radiometry, Reflectivity, remote sensing, Remote sensing},
	pages = {588--598},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/PTI2YXIF/4689353.html:text/html},
}

@misc{a_automatic_nodate,
	title = {Automatic {Road} {Vector} {Extraction} for {Mobile} {Mapping} {Systems}},
	abstract = {ABSTRACT: Land-based mobile mapping systems have yielded an enormous time saving in capturing road networks and their surrounding. However, the manual extraction of the road information from the mobile mapping data is still a time-consuming task. This paper presents ARVEE (Automated Road Geometry Vectors Extraction Engine), a robust automatic road geometry extraction system developed by Absolute Mapping Solution Inc. (AMS). The extracted road information includes 3D continuous lane lines, road edges as well as lane lines attributes. There are three innovations in this work. First, all the visible lane lines in the georeferenced image sequences are extracted, instead of only extracting the central lane line or the nearby lane line pair. Second, lane line attributes are recognized, so the output is a functional description of the road geometry. Third, the output is an absolute-georeferenced model of lane lines in mapping coordinates, and is directly compatible to GIS databases. ARVEE includes four steps: First, extracting linear features in each image. Second, extracting, filtering and grouping linear features into lane line segments (LLS) based on their geometric and radiometric characteristics. Third, linking the LLSs into long lane lines 3D model using Multiple-Hypothesis Analysis (MHA). Finally, classifying each lane line into a lane line type based on the synthetic analysis of the included LLSs ’ features. The system has been tested on large number of VISAT ™ mobile mapping data. The experiments on massive real MMS data sets demonstrate that ARVEE can deliver accurate and robust 3D continuous functional road geometry model. Full automatic processing result from ARVEE can replace most of the human efforts in road geometry modelling. 1.},
	author = {A, Wang Cheng and B, T. Hassan and B, N. El-sheimy and B, M. Lavigne},
	file = {Citeseer - Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/77P8IAKW/A et al. - Automatic Road Vector Extraction for Mobile Mappin.pdf:application/pdf;Citeseer - Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/HKIVMD85/summary.html:text/html},
}

@inproceedings{hervieu_road_2013,
	title = {Road side detection and reconstruction using {LIDAR} sensor},
	doi = {10.1109/IVS.2013.6629637},
	abstract = {Road edge localization is key knowledge for automatic road modeling and hence, in the field of autonomous vehicles. In this paper, we investigate the case of road border detection using LIDAR data. The aim is to propose a system recognizing curbs and curb ramps and to reconstruct the missing information in case of occlusion. A prediction/estimation process (inspired by Kalman filter models) has been analyzed. The map of angle deviation to ground normal is considered as a feature set, helping to characterize efficiently curbs while curb ramps and occluded curbs have been handled with the proposed model. Such a method may be used for both road map modeling and driver-assistance systems. A user interface scheme has also been described, providing an effective tool for semi-automatic processing of a large amount of data.},
	booktitle = {2013 {IEEE} {Intelligent} {Vehicles} {Symposium} ({IV})},
	author = {Hervieu, Alexandre and Soheilian, Bahman},
	month = jun,
	year = {2013},
	note = {ISSN: 1931-0587},
	keywords = {Laser radar, Computational modeling, Estimation, Image edge detection, Predictive models, Roads, Three-dimensional displays},
	pages = {1247--1252},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/MF7ZBNTI/6629637.html:text/html},
}

@misc{noauthor_radiometric_nodate,
	title = {Radiometric {Calibration} of {LIDAR} {Intensity} {With} {Commercially} {Available} {Reference} {Targets} {\textbar} {IEEE} {Journals} \& {Magazine} {\textbar} {IEEE} {Xplore}},
	url = {https://ieeexplore.ieee.org/abstract/document/4689353},
	urldate = {2021-10-14},
}

@article{ibrahim_curb-based_2012,
	title = {Curb-based street floor extraction from mobile terrestrial lidar point cloud},
	volume = {39},
	doi = {10.5194/isprsarchives-XXXIX-B5-193-2012},
	abstract = {Mobile terrestrial laser scanners (MTLS) produce huge 3D point clouds describing the terrestrial surface, from which objects like
different street furniture can be generated. Extraction and modelling of the street curb and the street floor from MTLS point clouds
is important for many applications such as right-of-way asset inventory, road maintenance and city planning. The proposed pipeline
for the curb and street floor extraction consists of a sequence of five steps: organizing the 3D point cloud and nearest neighbour
search; 3D density-based segmentation to segment the ground; morphological analysis to refine out the ground segment; derivative
of Gaussian filtering to detect the curb; solving the travelling salesman problem to form a closed polygon of the curb and point-inpolygon
test to extract the street floor. Two mobile laser scanning datasets of different scenes are tested with the proposed pipeline.
The results of the extracted curb and street floor are evaluated based on a truth data. The obtained detection rates for the extracted
street floor for the datasets are 95\% and 96.53\%. This study presents a novel approach to the detection and extraction of the road
curb and the street floor from unorganized 3D point clouds captured by MTLS. It utilizes only the 3D coordinates of the point cloud.},
	journal = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
	author = {Ibrahim, S. and Lichti, D.},
	month = jul,
	year = {2012},
	pages = {193--198},
	file = {Full Text:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/YAVGSPER/Ibrahim and Lichti - 2012 - Curb-based street floor extraction from mobile ter.pdf:application/pdf},
}

@article{jalayer_comprehensive_2014,
	title = {A {Comprehensive} {Assessment} of {Highway} {Inventory} {Data} {Collection} {Methods}},
	doi = {10.5399/OSU/JTRF.53.2.4219},
	abstract = {This study evaluated existing highway inventory methods through a nationwide survey and a field trial of identified promising highway inventory data collection (HIDC) methods on various types of highway segments to characterize the capability of existing methods for collecting highway Inventory data vital to the implementation of the recently published HSM. The implementation of the Highway Safety Manual (HSM) at the state level has the potential to allow transportation agencies to proactively address safety concerns. However, the widespread utilization of HSM faces significant barriers as many state departments of transportations (DOTs) do not have sufficient HSM-required highway inventory data. Many techniques have been utilized by state DOTs and local agencies to collect highway inventory data for other purposes. Nevertheless, it is unknown which of these methods or any combination of them is capable of efficiently collecting the required dataset while minimizing cost and safety concerns. The focus of this study is to characterize the capability of existing methods for collecting highway inventory data vital to the implementation of the recently published HSM. More specifically, this study evaluated existing highway inventory methods through a nationwide survey and a field trial of identified promising highway inventory data collection (HIDC) methods on various types of highway segments. A comparative analysis was conducted to present an example on how to incorporate weights provided by state DOT stakeholders to select the most suitable HIDC method for the specific purpose.},
	author = {Jalayer, M. and Zhou, Huaguo and Gong, J. and Hu, Shunfu and Grinter, M.},
	year = {2014},
	file = {Submitted Version:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/P7KSS6KD/Jalayer et al. - 2014 - A Comprehensive Assessment of Highway Inventory Da.pdf:application/pdf},
}

@inproceedings{jiangui_method_2011,
	title = {A method for main road extraction from airborne {LiDAR} data in urban area},
	doi = {10.1109/ICECC.2011.6066443},
	abstract = {A method for the automatic main road extraction in urban area from airborne LiDAR (Light Detection And Ranging) data is proposed. Elevation and intensity information are used to classify road points from the raw airborne LiDAR point clouds. Firstly, the adaptive TIN (Triangulated Irregular Network) model filtering algorithm is utilized to classify the LiDAR point clouds into ground and non-ground point clouds. Secondly, the ground point clouds are classified into candidate road and non-road point clouds by intensity information. Lastly, the constrained Delaunay TIN of candidate road point clouds is constructed to improve the accuracy of classification and then the road contour is extracted from the road points image. Experimental results show that the method can extract the main road of urban area effectively.},
	booktitle = {2011 {International} {Conference} on {Electronics}, {Communications} and {Control} ({ICECC})},
	author = {Jiangui, Peng and Guang, Gao},
	month = sep,
	year = {2011},
	keywords = {Laser radar, Remote sensing, Roads, Airborne LiDAR, constrained Delaunay TIN(CD-TIN), Data mining, Filtering algorithms, intensity, point clouds, road, Tin, Urban areas},
	pages = {2425--2428},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/EY5RPV64/6066443.html:text/html},
}

@article{kavzoglu_mapping_2009,
	title = {Mapping urban road infrastructure using remotely sensed images},
	volume = {30},
	doi = {10.1080/01431160802639582},
	abstract = {Comprehensive and accurate information on the conditions of the road infrastructure is essential for effective management and planning of the road network, especially in cities facing serious traffic congestion problems, as in the city of Istanbul, Turkey. One of the most important services of the local authorities is the rehabilitation of road surfaces. Asphalt resurfacing is carried out to renew the road surface and restore its resistance to weathered and traffic worn pavements. Today, the determination of pavement surface conditions is usually carried out through visual inspections by the experts and interpretation of in situ photographs/videos. In this study, an investigation has been made to understand the spectral behaviour of the asphalt in terms of its contents and age, also to discover the feasibility of using widely available satellite sensors in the determination of road surface conditions. Two datasets in the study area from D‐100 road and TEM highway were used to examine asphalt road aging and deterioration. The changes to the conditions of the roads were detected using multispectral IKONOS images and ground spectral measurements for asphalt samples were obtained using an Analytical Spectral Devices full range (ASD FR) instrument in a laboratory environment. It was found that the road deformations mainly occur in areas where vehicles reduce or increase their speeds suddenly. Road sections just before toll booths and junctions are found to be more prone to deformations. IKONOS images can be effectively used to determine the condition of the asphalt pixels.},
	journal = {International Journal of Remote Sensing},
	author = {Kavzoglu, Taskin and Sen, Yunus and Cetin, Mufit},
	month = apr,
	year = {2009},
	pages = {1759--1769},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/6NPJ6LF9/Kavzoglu et al. - 2009 - Mapping urban road infrastructure using remotely s.pdf:application/pdf},
}

@article{lehtomaki_detection_2010,
	title = {Detection of {Vertical} {Pole}-{Like} {Objects} in a {Road} {Environment} {Using} {Vehicle}-{Based} {Laser} {Scanning} {Data}},
	volume = {2},
	doi = {10.3390/rs2030641},
	abstract = {Accurate road environment information is needed in applications such as road maintenance and virtual 3D city modelling. Vehicle-based laser scanning (VLS) can produce dense point clouds from large areas efficiently from which the road and its environment can be modelled in detail. Pole-like objects such as traffic signs, lamp posts and tree trunks are an important part of road environments. An automatic method was developed for the extraction of pole-like objects from VLS data. The method was able to find 77.7\% of the poles which were found by a manual investigation of the data. Correctness of the detection was 81.0\%.},
	journal = {Remote Sensing},
	author = {Lehtomäki, Matti and Jaakkola, Anttoni and Hyyppä, Juha and Kukko, Antero and Kaartinen, Harri},
	month = mar,
	year = {2010},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/W9SIQ2ER/Lehtomäki et al. - 2010 - Detection of Vertical Pole-Like Objects in a Road .pdf:application/pdf},
}

@article{lien_recognizing_2012,
	title = {Recognizing the road points and road marks from mobile {LiDAR} point clouds},
	volume = {2},
	abstract = {Mobile lidar system is a cost-effective way to acquire spatial data in the urban area effectively. It can be used to generate a detailed street-level road model. As the need for Location Based Service (LBS) is increasing, the demand of understanding the city structure is growing up rapidly as well. For this reason, street-level road model is one of the most important elements to connect the geospatial objects in the urban area. The purpose of this paper is to extract the 3D road points and road marks from mobile lidar system effectively. The major works include road points selection and road marks extraction. In the road points selection, we select the lowest point as potential ground points from all points using elevation threshold. Then, we use the cubic curve fitting and point-to-curve distance to extract road points. It can remove non-ground points like cars and pedestrians. In the road marks extraction, we generate an intensity image by the interpolation of lidar intensity and create the road marking template for matching. Then, we extract location of road marks from the point clouds based on SIFT (Scale-invariant feature transform) matching. The test data acquired by Riegl VMX-250 system is located in Chiu-Chung Road in Taipei city. The accuracy of data is better than 10cm. The pixel size of intensity image is 7.5cm. The experiment results show that this method can extract ground points correctly. However, only limited road mark can be found in the preliminary result. The descriptors of the keypoints have a great effect on performance in matching.},
	author = {Lien, Y.-N and Teo, T.-A and Chen, C.-T and Huang, P.-Y},
	month = jan,
	year = {2012},
	pages = {1054--1059},
}

@article{liu_new_2013,
	title = {A {New} {Curb} {Detection} {Method} for {Unmanned} {Ground} {Vehicles} {Using} {2D} {Sequential} {Laser} {Data}},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/13/1/1102},
	doi = {10.3390/s130101102},
	abstract = {Curb detection is an important research topic in environment perception, which is an essential part of unmanned ground vehicle (UGV) operations. In this paper, a new curb detection method using a 2D laser range finder in a semi-structured environment is presented. In the proposed method, firstly, a local Digital Elevation Map (DEM) is built using 2D sequential laser rangefinder data and vehicle state data in a dynamic environment and a probabilistic moving object deletion approach is proposed to cope with the effect of moving objects. Secondly, the curb candidate points are extracted based on the moving direction of the vehicle in the local DEM. Finally, the straight and curved curbs are detected by the Hough transform and the multi-model RANSAC algorithm, respectively. The proposed method can detect the curbs robustly in both static and typical dynamic environments. The proposed method has been verified in real vehicle experiments.},
	language = {en},
	number = {1},
	urldate = {2021-10-14},
	journal = {Sensors},
	author = {Liu, Zhao and Wang, Jinling and Liu, Daxue},
	month = jan,
	year = {2013},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {curb detection, dynamic environment, laser range finder, mapping},
	pages = {1102--1120},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/7LS66YLC/Liu et al. - 2013 - A New Curb Detection Method for Unmanned Ground Ve.pdf:application/pdf;Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/5BRVHSDM/htm.html:text/html},
}

@inproceedings{mc_elhinney_initial_2010,
	title = {Initial results from {European} {Road} {Safety} {Inspection} ({EURSI}) mobile mapping project},
	volume = {38},
	abstract = {Mobile mapping systems are becoming a popular method for collecting high quality near 3D information of terrestrial scenes. Modern mobile mapping systems can produce millions of georeferenced points per minute. These can be used to gather quantitative information about surfaces and objects. With this geospatial data it is becoming possible to segment and extract the road surface. In this paper, we will detail a novel LIDAR based road edge extraction algorithm which is applicable to both urban and rural road sections.},
	author = {Mc Elhinney, Conor and Kumar, Pankaj and Cahalane, Conor and Mccarthy, Timothy},
	month = jun,
	year = {2010},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/3VFXEG9R/Mc Elhinney et al. - 2010 - Initial results from European Road Safety Inspecti.pdf:application/pdf},
}

@article{mena_automatic_2005,
	title = {An automatic method for road extraction in rural and semi-urban areas starting from high resolution satellite imagery},
	volume = {26},
	issn = {0167-8655},
	url = {https://www.sciencedirect.com/science/article/pii/S0167865504003265},
	doi = {10.1016/j.patrec.2004.11.005},
	abstract = {In this paper an efficient method for automatic road extraction in rural and semi-urban areas is presented. This work seeks the GIS update starting from color images and using preexisting vectorial information. As input data only the RGB bands of a satellite or aerial color image of high resolution is required. The system includes four different modules: data preprocessing; binary segmentation based on three levels of texture statistical evaluation; automatic vectorization by means of skeletal extraction; and finally a module for system evaluation. In the first module the color image is rectified and geo-referenced. The second module uses a new technique, named Texture Progressive Analysis (TPA), in order to obtain the segmented binary image. The TPA technique is developed in the evidence theory framework, and it consists in fusing information streaming from three different sources for the image. In the third module the obtained binary image is vectorized using an algorithm based on skeleton extraction techniques and morphological methods. The result is an extracted road network which is defined as a structural set of elements geometrically and topologically corrects. The fourth module is an evaluation of the procedure using a popular method. Experimental results show that this method is efficient in extracting and defining road networks from high resolution satellite and aerial imagery.},
	language = {en},
	number = {9},
	urldate = {2021-10-14},
	journal = {Pattern Recognition Letters},
	author = {Mena, J. B. and Malpica, J. A.},
	month = jul,
	year = {2005},
	keywords = {Evaluation, Evidence theory, Mathematical morphology, Road extraction, Segmentation, Skeleton, Texture analysis, Vectorization},
	pages = {1201--1220},
	file = {ScienceDirect Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/LNSHX69B/S0167865504003265.html:text/html},
}

@article{miyazaki_line-based_2014,
	title = {A line-based approach for precise extraction of road and curb region from mobile mapping data},
	volume = {II-5},
	issn = {2194-9050},
	url = {https://www.isprs-ann-photogramm-remote-sens-spatial-inf-sci.net/II-5/243/2014/},
	doi = {10.5194/isprsannals-II-5-243-2014},
	abstract = {Planar structure detection from point clouds is important process in many applications such as maintenance of infrastructure facility including roads and curbs because most artiﬁcial structures consists of planar surfaces. The Mobile Mapping System can obtain a large amount of points with traveling at a standard speed. However, in the case that the high-end laser scanning system is equipped, the distribution density of points is uneven. In the point-based method, this situation causes the problem to the method of calculating geometric information using neighborhood points. In this paper, we propose a line-based region growing method in order to detect planar structures with precise boundary from point clouds with uneven distribution density of points. The precise boundary of a planar structure is maintained by appropriately creating line segments from the input clouds. We adapt the deﬁnition of neighborhood and the estimation of the normal vector to the line-based region growing. The evaluation by comparing our result with manually extracted points shows that more than 98\% of curb points are detected. And, about 90\% of the boundary points between a road and a curb are detected with less than 0.005 meters of the distance error.},
	language = {en},
	urldate = {2021-10-14},
	journal = {ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Miyazaki, R. and Yamamoto, M. and Hanamoto, E. and Izumi, H. and Harada, K.},
	month = may,
	year = {2014},
	pages = {243--250},
	file = {Miyazaki et al. - 2014 - A line-based approach for precise extraction of ro.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/8CPXCRXD/Miyazaki et al. - 2014 - A line-based approach for precise extraction of ro.pdf:application/pdf},
}

@inproceedings{sock_probabilistic_2016,
	title = {Probabilistic traversability map generation using {3D}-{LIDAR} and camera},
	doi = {10.1109/ICRA.2016.7487782},
	abstract = {Estimating the traversability of rough terrain is a critical task for an outdoor mobile robot. While classifying structured environment can be learned from large number of training data, it is an extremely difficult task to learn and estimate traversability of unstructured rough terrain. Moreover, in many cases information from a single sensor may not be sufficient for estimating traversability reliably in the absence of artificial landmarks such as lane markings or curbs. Our approach estimates traversability of the terrain and build a 2D probabilistic grid map online using 3D-LIDAR and camera. The combination of LIDAR and camera is favoured in many robotic application because they provide complementary information. Our approach assumes the data captured by these two sensors are independent and build separate traversability maps, each with information captured from one sensor. Traversability estimation with vision sensor autonomously collects training data and update classifier without human intervention as the vehicle traverse the terrain. Traversability estimation with 3D-LIDAR measures the slopes of the ground to predict the traversability. Two independently built probabilistic maps are fused using Bayes' rule to improve the detection performance. This is in contrast with other methods in which each sensor performs different tasks. We have implemented the algorithm on a UGV(Unmanned Ground Vehicle) and tested our approach on a rough terrain to evaluate the detection performance.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Sock, Juil and Kim, Jun and Min, Jihong and Kwak, Kiho},
	month = may,
	year = {2016},
	keywords = {Laser radar, Roads, Cameras, Probabilistic logic, Robot sensing systems, Vehicles},
	pages = {5631--5637},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/XQRM3C3T/7487782.html:text/html},
}

@article{puente_review_2013,
	title = {Review of mobile mapping and surveying technologies},
	volume = {46},
	issn = {0263-2241},
	url = {https://www.sciencedirect.com/science/article/pii/S0263224113000730},
	doi = {10.1016/j.measurement.2013.03.006},
	abstract = {Mobile surveying is currently one of the most popular topics in the LiDAR industry. The collection of highly precise point cloud data is provided by laser scanning systems on moving platforms with an integrated navigation solution. The potential of LiDAR based mobile surveying technology is now well proven. This article introduces an analysis on the current performance of some outstanding mobile terrestrial laser scanning systems. In this work, an overview of the positioning, scanning and imaging devices integrated into these systems is also presented. As part of this study, a systematic comparison of the navigation and LiDAR specifications provided by the manufacturers is provided. Our review suggests that mobile laser scanning systems can mainly be divided into two categories (mapping and surveying) depending on their final purpose, accuracy, range and resolution requirements. A refined integrated analysis based on hardware components could be expected to cause further improvements on these results.},
	language = {en},
	number = {7},
	urldate = {2021-10-14},
	journal = {Measurement},
	author = {Puente, I. and González-Jorge, H. and Martínez-Sánchez, J. and Arias, P.},
	month = aug,
	year = {2013},
	keywords = {Laser scanning, LiDAR, Mobile mapping, Photogrammetry, Surveying},
	pages = {2127--2145},
}

@article{serna_detection_2014,
	title = {Detection, segmentation and classification of {3D} urban objects using mathematical morphology and supervised learning},
	volume = {93},
	issn = {0924-2716},
	url = {https://www.sciencedirect.com/science/article/pii/S0924271614000872},
	doi = {10.1016/j.isprsjprs.2014.03.015},
	abstract = {We propose an automatic and robust approach to detect, segment and classify urban objects from 3D point clouds. Processing is carried out using elevation images and the result is reprojected onto the 3D point cloud. First, the ground is segmented and objects are detected as discontinuities on the ground. Then, connected objects are segmented using a watershed approach. Finally, objects are classified using SVM with geometrical and contextual features. Our methodology is evaluated on databases from Ohio (USA) and Paris (France). In the former, our method detects 98\% of the objects, 78\% of them are correctly segmented and 82\% of the well-segmented objects are correctly classified. In the latter, our method leads to an improvement of about 15\% on the classification step with respect to previous works. Quantitative results prove that our method not only provides a good performance but is also faster than other works reported in the literature.},
	language = {en},
	urldate = {2021-10-14},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
	author = {Serna, Andrés and Marcotegui, Beatriz},
	month = jul,
	year = {2014},
	keywords = {Mathematical morphology, Segmentation, Laser scanning, 3D urban analysis, Classification, Detection, Support vector machine (SVM)},
	pages = {243--255},
	file = {Submitted Version:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/QNRLJGRY/Serna and Marcotegui - 2014 - Detection, segmentation and classification of 3D u.pdf:application/pdf},
}

@article{wu_voxel-based_2013,
	title = {A {Voxel}-{Based} {Method} for {Automated} {Identification} and {Morphological} {Parameters} {Estimation} of {Individual} {Street} {Trees} from {Mobile} {Laser} {Scanning} {Data}},
	volume = {5},
	issn = {2072-4292},
	url = {http://www.mdpi.com/2072-4292/5/2/584},
	doi = {10.3390/rs5020584},
	language = {en},
	number = {2},
	urldate = {2021-10-14},
	journal = {Remote Sensing},
	author = {Wu, Bin and Yu, Bailang and Yue, Wenhui and Shu, Song and Tan, Wenqi and Hu, Chunling and Huang, Yan and Wu, Jianping and Liu, Hongxing},
	month = jan,
	year = {2013},
	pages = {584--611},
	file = {Wu et al. - 2013 - A Voxel-Based Method for Automated Identification .pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/QUVJ37ZM/Wu et al. - 2013 - A Voxel-Based Method for Automated Identification .pdf:application/pdf},
}

@article{yadav_pole-shaped_2015,
	title = {{POLE}-{SHAPED} {OBJECT} {DETECTION} {USING} {MOBILE} {LIDAR} {DATA} {IN} {RURAL} {ROAD} {ENVIRONMENTS}},
	volume = {II-3/W5},
	doi = {10.5194/isprsannals-II-3-W5-11-2015},
	abstract = {Pole-shaped objects (PSOs) located along a road play key role in road safety and planning. Automation is required for calculating the numbers of trees need to be removed and utility poles need to be relocated during rural road widening. Road-side poles are among the most frequently struck road-side objects during road-side accidents. An automatic method is therefore proposed for detecting PSOs using LiDAR point cloud captured along the roadway using Mobile LiDAR system. The proposed method is tested on the point cloud data of rural road environment in India. Dataset of study area having text file size of 1.22 GB is processed in 13 minutes resulting in completeness of 88.63 \% and correctness of 95.12 \% in identifying PSOs within 10m of the road boundary. In data of across road coverage of 5m of the road boundary, the completeness of 93.10 \% and correctness of 100\% are achieved. Poles attached with other objects, tilted poles and the poles occluded by tree branches and shrubs are detected by the proposed method.},
	journal = {ISPRS Annals of Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Yadav, Manohar and Husain, A. and Singh, Ajoy and Lohani, Bharat},
	month = aug,
	year = {2015},
	pages = {11--16},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/ASB44P4M/Yadav et al. - 2015 - POLE-SHAPED OBJECT DETECTION USING MOBILE LIDAR DA.pdf:application/pdf},
}

@article{kumar_automated_2013,
	title = {An automated algorithm for extracting road edges from terrestrial mobile {LiDAR} data},
	volume = {85},
	issn = {0924-2716},
	url = {https://www.sciencedirect.com/science/article/pii/S0924271613001834},
	doi = {10.1016/j.isprsjprs.2013.08.003},
	abstract = {Terrestrial mobile laser scanning systems provide rapid and cost effective 3D point cloud data which can be used for extracting features such as the road edge along a route corridor. This information can assist road authorities in carrying out safety risk assessment studies along road networks. The knowledge of the road edge is also a prerequisite for the automatic estimation of most other road features. In this paper, we present an algorithm which has been developed for extracting left and right road edges from terrestrial mobile LiDAR data. The algorithm is based on a novel combination of two modified versions of the parametric active contour or snake model. The parameters involved in the algorithm are selected empirically and are fixed for all the road sections. We have developed a novel way of initialising the snake model based on the navigation information obtained from the mobile mapping vehicle. We tested our algorithm on different types of road sections representing rural, urban and national primary road sections. The successful extraction of road edges from these multiple road section environments validates our algorithm. These findings and knowledge provide valuable insights as well as a prototype road edge extraction tool-set, for both national road authorities and survey companies.},
	language = {en},
	urldate = {2021-10-14},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
	author = {Kumar, Pankaj and McElhinney, Conor P. and Lewis, Paul and McCarthy, Timothy},
	month = nov,
	year = {2013},
	keywords = {LiDAR, Automation, Edge, Extraction, Terrestrial mobile},
	pages = {44--55},
	file = {Accepted Version:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/N7BD6GS7/Kumar et al. - 2013 - An automated algorithm for extracting road edges f.pdf:application/pdf;ScienceDirect Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/G7S9P3ZI/S0924271613001834.html:text/html},
}

@article{qiu_fast_2016,
	title = {A {FAST} {AND} {ROBUST} {ALGORITHM} {FOR} {ROAD} {EDGES} {EXTRACTION} {FROM} {LIDAR} {DATA}},
	volume = {XLI-B5},
	issn = {2194-9034},
	url = {http://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLI-B5/693/2016/isprs-archives-XLI-B5-693-2016.pdf},
	doi = {10.5194/isprsarchives-XLI-B5-693-2016},
	abstract = {Fast mapping of roads plays an important role in many geospatial applications, such as infrastructure planning, traffic monitoring, and driver assistance. How to extract various road edges fast and robustly is a challenging task. In this paper, we present a fast and robust algorithm for the automatic road edges extraction from terrestrial mobile LiDAR data. The algorithm is based on a key observation: most roads around edges have difference in elevation and road edges with pavement are seen in two different planes. In our algorithm, we firstly extract a rough plane based on RANSAC algorithm, and then multiple refined planes which only contains pavement are extracted from the rough plane. The road edges are extracted based on these refined planes. In practice, there is a serious problem that the rough and refined planes usually extracted badly due to rough roads and different density of point cloud. To eliminate the influence of rough roads, the technology which is similar with the difference of DSM (digital surface model) and DTM (digital terrain model) is used, and we also propose a method which adjust the point clouds to a similar density to eliminate the influence of different density. Experiments show the validities of the proposed method with multiple datasets (e.g. urban road, highway, and some rural road). We use the same parameters through the experiments and our algorithm can achieve real-time processing speeds.},
	language = {en},
	urldate = {2021-10-14},
	journal = {ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Qiu, Kaijin and Sun, Kai and Ding, Kou and Shu, Zhen},
	month = jun,
	year = {2016},
	pages = {693--698},
	file = {Qiu et al. - 2016 - A FAST AND ROBUST ALGORITHM FOR ROAD EDGES EXTRACT.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/P9ZIUCCC/Qiu et al. - 2016 - A FAST AND ROBUST ALGORITHM FOR ROAD EDGES EXTRACT.pdf:application/pdf},
}

@article{xu_real-time_2019,
	title = {A real-time road detection method based on reorganized lidar data},
	volume = {14},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0215159},
	doi = {10.1371/journal.pone.0215159},
	abstract = {Road Detection is a basic task in automated driving field, in which 3D lidar data is commonly used recently. In this paper, we propose to rearrange 3D lidar data into a new organized form to construct direct spatial relationship among point cloud, and put forward new features for real-time road detection tasks. Our model works based on two prerequisites: (1) Road regions are always flatter than non-road regions. (2) Light travels in straight lines in a uniform medium. Based on prerequisite 1, we put forward difference-between-lines feature, while ScanID density and obstacle radial map are generated based on prerequisite 2. According to our method, we construct an array of structures to store and reorganize 3D input firstly. Then, two novel features, difference-between-lines and ScanID density, are extracted, based on which we construct a consistency map and an obstacle map in Bird Eye View (BEV). Finally, the road region is extracted by fusing these two maps and refinement is used to polish up our outcome. We have carried out experiments on the public KITTI-Road benchmark, achieving one of the best performances among the lidar-based road detection methods. To further prove the efficiency of our method on unstructured road, the visual outcomes in rural areas are also proposed.},
	language = {en},
	number = {4},
	urldate = {2021-10-14},
	journal = {PLOS ONE},
	author = {Xu, Fenglei and Chen, Longtao and Lou, Jing and Ren, Mingwu},
	month = apr,
	year = {2019},
	note = {Publisher: Public Library of Science},
	keywords = {Roads, Birds, Built structures, Cartesian coordinates, Distance measurement, Lasers, Lidar, Smart materials},
	pages = {e0215159},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/S5VWK9QD/Xu et al. - 2019 - A real-time road detection method based on reorgan.pdf:application/pdf},
}

@inproceedings{manz_detection_2011,
	title = {Detection and tracking of road networks in rural terrain by fusing vision and {LIDAR}},
	doi = {10.1109/IROS.2011.6094559},
	abstract = {The ability to perceive a robot's local environment is one of the main challenges in the development of mobile ground robots. Here, we present a robust model-based approach for detection and tracking of road networks in rural terrain. To get a rich environment representation, we fuse the complementary data provided by a 3D LIDAR and an active camera platform into an accumulated, colored 3D elevation map of the terrain. Additionally, we use commercially available GIS data to get a rough idea about the geometry of the road network ahead of the robot. This way, the system is able to dynamically adjust the geometric model used within a particle filter framework for both detection and estimation of the road network's geometry. The estimation process makes use of edge- and region-based image features as well as obstacle information, all supplied by the dense terrain map. Instead of tuning the likelihood functions used within the particle filter's cue fusion concept by hand, as commonly done, we apply supervised learning techniques to derive an appropriate weighting of all features. We finally show that the proposed approach enables our ground robot MuCAR-3 to autonomously navigate on rural- and dirt-road networks.},
	booktitle = {2011 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Manz, Michael and Himmelsbach, Michael and Luettel, Thorsten and Wuensche, Hans-Joachim},
	month = sep,
	year = {2011},
	note = {ISSN: 2153-0866},
	keywords = {Laser radar, Roads, Robot sensing systems, Vehicles, Global Positioning System, Three dimensional displays},
	pages = {4562--4568},
}

@article{yadav_identification_2016,
	title = {Identification of pole-like structures from mobile lidar data of complex road environment},
	volume = {37},
	issn = {0143-1161},
	url = {https://doi.org/10.1080/01431161.2016.1219462},
	doi = {10.1080/01431161.2016.1219462},
	abstract = {Pole-like structures (PLSs) located in road environment are important roadway assets. They play a vital role in road safety inspection and road planning. The use of light detection and ranging (lidar) based mobile mapping technology for mapping of PLSs is an important area of research as it holds the potential for automation. Point cloud data of rural, peri-urban, and urban road environment are used in this study, which pose special challenge in view of the complexity of terrain, unlike well-planned roads, which have been the subject of interest in existing literature for identification of PLSs. A new five-step method is proposed in this article. The first two steps, i.e. ground filtering and voxelization of filtered non-ground points, are used for data size reduction. Next three steps are used to extract PLSs from reduced data. The proposed method was tested on point cloud data of three test sites having different levels of complexities. PLSs including partially occluded pole, tilted pole, pole situated very close to other objects, and vertical pole attached to tilted pole were accurately identified. Average correctness and completeness, respectively of 92.6\% and 94.9\%, were achieved in three different complex test sites, i.e. urban, peri-urban, and rural sites, respectively. Computation complexity shows that our proposed method delivers fast and computationally efficient solution for identifying the PLSs from volumetric mobile lidar point cloud. Impact of PLSs on road safety and road planning is also addressed for these selected test sites.},
	number = {20},
	urldate = {2021-10-14},
	journal = {International Journal of Remote Sensing},
	author = {Yadav, Manohar and Lohani, Bharat and Singh, Ajai Kumar and Husain, Arshad},
	month = oct,
	year = {2016},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/01431161.2016.1219462},
	pages = {4748--4777},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/KUWPRXR5/01431161.2016.html:text/html},
}

@article{yadav_extraction_2017,
	title = {Extraction of road surface from mobile {LiDAR} data of complex road environment},
	volume = {38},
	issn = {0143-1161},
	url = {https://doi.org/10.1080/01431161.2017.1320451},
	doi = {10.1080/01431161.2017.1320451},
	abstract = {Three-dimensional (3D) data of roadways are frequently used for extraction of detailed roadway information which is essential for several planning and engineering applications. Recent past has seen rapid growth in utilization of mobile LiDAR system (MLS) to acquire volumetric 3D data of roadway for this purpose. MLS data are capable of capturing highly detailed road information, which is useful for road maintenance and road safety operations. The existing literature shows that road environment complexity, unevenness, and absence of raised curb limit the extraction of road information from MLS data. It must be noted that a large number of roads, especially in developing world, are characterized by these complexities and thus raise the need for a technique which can work in these road environments. Considering the above, this paper proposes a method to extract road information, where road boundary is not geometrically well-defined. The proposed method is constructed using unstructured MLS data as input and does not require any other additional data. The method is divided into three major steps, that is, MLS data structuring and ground filtering, road surface point extraction, and road boundary refinement. The first step filters ground points from input MLS data, while the second step identifies road surface points from among the ground points. The second step is designed using specific characteristics of a road, that is, topology, surface roughness, and variation of point density. Third step refines road boundary. Three test sites, quite complex with heterogeneous characteristics, were used for demonstration of the proposed method. Road surfaces of these three roadways were accurately extracted without being affected by on-road objects and absence of raised curb. Average accuracy measures like completeness, correctness, and quality were found to be 93.8\%, 98.3\%, and 92.3\%, respectively, in three test sites. Further, road boundaries of extracted road surfaces of these three test sites were refined at average completeness, correctness, and quality of 95.6\%, 97.9\%, and 93.7\%, respectively. The proposed method has shown satisfactory performance for complex roadways having road section with and without raised curb, and has potential to be employed for such road environments, which are not uncommon. Proposed method was implemented on GPU-based parallel computing framework, which significantly saved the run time in processing of MLS data of three test sites.},
	number = {16},
	urldate = {2021-10-14},
	journal = {International Journal of Remote Sensing},
	author = {Yadav, Manohar and Singh, Ajai Kumar and Lohani, Bharat},
	month = aug,
	year = {2017},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/01431161.2017.1320451},
	pages = {4655--4682},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/UZKLSLLG/01431161.2017.html:text/html},
}

@article{yadav_rural_2018,
	title = {Rural {Road} {Surface} {Extraction} {Using} {Mobile} {LiDAR} {Point} {Cloud} {Data}},
	volume = {46},
	issn = {0974-3006},
	url = {https://doi.org/10.1007/s12524-017-0732-4},
	doi = {10.1007/s12524-017-0732-4},
	abstract = {The existing roadway infrastructures are mostly archived with two-dimensional (2D) drawings that lack the possibility for three-dimensional (3D) interpretation and advanced 3D analysis. The mobile LiDAR system (MLS) is gaining popularity in 3D mapping applications along various types of road corridors. MLS achieves the highest data quality and completeness among the traditional roadway data collection methods. The rural roads in different countries especially in India form a substantial portion of the road network. Therefore the proper maintenance and road safety analysis of rural roads are recommended activity, which could be addressed using detailed 3D road surface information. The absence of raised curb at road boundary, and presence of complexity, heterogeneity and occlusions along the rural roadway settings restrict the use of existing studies for road surface extraction using MLS point cloud data. Therefore considering the above requirement, this research paper proposes a two-stage method. The first stage extract planar ground surfaces which are further used to filter road surface in the second stage. Global properties of road, that is, topology and smoothness and its radiometric response to laser beam of MLS are used in the second stage. MLS point cloud data of rural roadway were used to test the proposed method. The road surface points were accurately extracted without being affected by the absence of raised curb and hanging objects over the road surface, that is, tree canopies and overhead power lines. The quantitative assessment of the proposed method was performed in terms of correctness, completeness and quality, which were 96.3, 94.2, and 90.9\%, respectively.},
	language = {en},
	number = {4},
	urldate = {2021-10-14},
	journal = {Journal of the Indian Society of Remote Sensing},
	author = {Yadav, Manohar and Singh, Ajai Kumar},
	month = apr,
	year = {2018},
	pages = {531--538},
	file = {Springer Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/VIA664AV/Yadav and Singh - 2018 - Rural Road Surface Extraction Using Mobile LiDAR P.pdf:application/pdf},
}

@inproceedings{zhang_lidar-based_2010,
	title = {{LIDAR}-based road and road-edge detection},
	doi = {10.1109/IVS.2010.5548134},
	abstract = {In this paper, a LIDAR-based road and road-edge detection method is proposed to identify road regions and road-edges, which is an essential component of autonomous vehicles. LIDAR range data is decomposed into signals in elevation and signals projected on the ground plane. First, the elevation-based signals are processed by filtering techniques to identify the road candidate region, and by pattern recognition techniques to determine whether the candidate region is a road segment. Then, the line representation of the projected signals on the ground plane is identified and compared to a simple road model in the top-down view to determine whether the candidate region is a road segment with its road-edges. The proposed method provides fast processing speed and reliable detection performance of road and road-edge detection. The proposed framework has been verified through the DARPA Urban Challenge to show its robustness and efficiency on the winning entry Boss vehicle.},
	booktitle = {2010 {IEEE} {Intelligent} {Vehicles} {Symposium}},
	author = {Zhang, Wende},
	month = jun,
	year = {2010},
	note = {ISSN: 1931-0587},
	keywords = {Laser radar, Data mining, Algorithm design and analysis, Mobile robots, Remotely operated vehicles, Road vehicles, Robustness, Sensor arrays, Signal processing, Vehicle detection},
	pages = {845--848},
}

@article{zeybek_extraction_2021,
	title = {Extraction of {Road} {Lane} {Markings} from {Mobile} {LiDAR} {Data}},
	volume = {2675},
	doi = {10.1177/0361198120981948},
	abstract = {This study presents a method for automatic extraction of road lane markings from mobile light detection and ranging (LiDAR) data. Road lanes and traffic signs on the road surface provide safe driving for drivers and aid traffic flow movement along the highway and street. Mobile LiDAR systems acquire massive datasets very quickly in a short time. To simplify the data structure and feature extraction, it is essential for traffic management personnel to apply the right methods. Road lanes must be visible and are a major factor in road safety for drivers. In this study, a methodology is devised and implemented for the extraction of features such as dashed lines, continuous lanes, and direction arrows on the pavement from point clouds. Point cloud data was collected from the Riegl VMX-450 mobile LiDAR system. The alpha shape algorithm is implemented on a point cloud and compared with the widespread use of edge detection techniques applied for intensity-based raster images. The proposed methodology directly extracts three-dimensional and two-dimensional road features to control the quality of road markings and spatial positions with the obtained marking boundaries. State-of-the-art results are obtained and compared with manually digitized reference markings. The standard deviations were evaluated and acquired for intensity image-based and direct point cloud-based extractions, at 1.2 cm and 1.7 cm, respectively.},
	journal = {Transportation Research Record Journal of the Transportation Research Board},
	author = {Zeybek, Mustafa},
	month = jan,
	year = {2021},
}

@article{bujan_forest_2021,
	title = {Forest {Road} {Detection} {Using} {LiDAR} {Data} and {Hybrid} {Classification}},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2072-4292/13/3/393},
	doi = {10.3390/rs13030393},
	abstract = {Knowledge about forest road networks is essential for sustainable forest management and fire management. The aim of this study was to assess the accuracy of a new hierarchical-hybrid classification tool (HyClass) for mapping paved and unpaved forest roads with LiDAR data. Bare-earth and low-lying vegetation were also identified. For this purpose, a rural landscape (area 70 ha) in northwestern Spain was selected for study, and a road network map was extracted from the cadastral maps as the ground truth data. The HyClass tool is based on a decision tree which integrates segmentation processes at local scale with decision rules. The proposed approach yielded an overall accuracy (OA) of 96.5\%, with a confidence interval (CI) of 94.0\&ndash;97.6\%, representing an improvement over pixel-based classification (OA = 87.0\%, CI = 83.7\&ndash;89.8\%) using Random Forest (RF). In addition, with the HyClass tool, the classification precision varied significantly after reducing the original point density from 8.7 to 1 point/m2. The proposed method can provide accurate road mapping to support forest management as an alternative to pixel-based RF classification when the LiDAR point density is higher than 1 point/m2.},
	language = {en},
	number = {3},
	urldate = {2021-10-14},
	journal = {Remote Sensing},
	author = {Buján, Sandra and Guerra-Hernández, Juan and González-Ferreiro, Eduardo and Miranda, David},
	month = jan,
	year = {2021},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {forest network extraction, importance of variables, object/pixel based classification, quality measures, random forest, sensitivity analysis},
	pages = {393},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/IBJ8HB64/393.html:text/html;Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/BYRDPUUA/Buján et al. - 2021 - Forest Road Detection Using LiDAR Data and Hybrid .pdf:application/pdf},
}

@article{pollyea_experimental_2012,
	title = {Experimental evaluation of terrestrial {LiDAR}-based surface roughness estimates},
	volume = {8},
	issn = {1553-040X},
	url = {https://doi.org/10.1130/GES00733.1},
	doi = {10.1130/GES00733.1},
	abstract = {The rapid proliferation of portable, ground-based light detection and ranging (LiDAR) instruments suggests the need for additional quantitative tools complementary to the commonly invoked digital terrain model (DTM). One such metric is surface roughness, which is a measure of local-scale topographic variability and has been shown to be effective for mapping discrete morphometric features, i.e., fractures in outcrop, landslide scarps, and alluvial fan deposits, to name a few. Several surface roughness models have been proposed, the most common of which is based on the standard deviation of point distances from a reference datum, e.g., DTM panels or best-fit planes. In the present work, we evaluate the accuracy of these types of surface roughness models experimentally by constructing a surface of known roughness, acquiring terrestrial LiDAR scans of the surface at 25 dual-axis rotations, and comparing surface roughness estimates for each rotation calculated by three surface roughness models. Results indicate that a recently proposed surface roughness model based on orthogonal distance regression (ODR) planes and orthogonal point-to-plane distance measurements is generally preferred on the basis of minimum error surface roughness estimates. In addition, the effects of terrestrial LiDAR sampling errors are discussed with respect to this ODR-based surface roughness model, and several practical suggestions are made for minimizing these effects. These include (1) positioning the laser scanner at the largest reasonable distance from the scanned surface, (2) maintaining half-angles for individual scans at less than 22.5°, and (3) minimizing occlusion (shadowing) errors by using multiple, merged scans with the least possible overlap.},
	number = {1},
	urldate = {2021-10-14},
	journal = {Geosphere},
	author = {Pollyea, Ryan M. and Fairley, Jerry P.},
	month = feb,
	year = {2012},
	pages = {222--228},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/3WNKQDTI/Pollyea and Fairley - 2012 - Experimental evaluation of terrestrial LiDAR-based.pdf:application/pdf},
}

@inproceedings{kang_pothole_2017,
	title = {Pothole detection system using {2D} {LiDAR} and camera},
	doi = {10.1109/ICUFN.2017.7993890},
	abstract = {Automatic Pothole detection is important task for determining proper strategies of asphalt-surfaced pavement maintenance. In this paper, we develop a pothole detection system and method using 2D LiDAR and Camera. To improve the pothole detection accuracy, the combination of heterogeneous sensor system is used. By using 2D LiDAR, the distance and angle information of road are obtained. The pothole detection algorithm includes noise reduction pre-processing, clustering, line segment extraction, and gradient of pothole data function. Next, image-based pothole detection method is used to improve the accuracy of pothole detection and to obtain pothole shape. Image-based algorithm includes noise filtering, brightness control, binarization, addictive noise filtering, edge extraction, and object extraction and pothole detection. To show the pothole detection performance, experiments of pothole detection system using 2D LiDAR and camera are performed.},
	booktitle = {2017 {Ninth} {International} {Conference} on {Ubiquitous} and {Future} {Networks} ({ICUFN})},
	author = {Kang, Byeong-ho and Choi, Su-il},
	month = jul,
	year = {2017},
	note = {ISSN: 2165-8536},
	keywords = {Laser radar, Roads, Three-dimensional displays, Data mining, Cameras, 2D LiDAR, camera, Filtering, pothole detection, Two dimensional displays},
	pages = {744--746},
}

@article{sucgang_road_2017,
	title = {Road {Surface} {Obstacle} {Detection} using {Vision} and {LIDAR} for {Autonomous} {Vehicle}},
	abstract = {The project aims to present a system that detects and estimates road surface obstacles - potholes and speed humps using low-cost camera and LIDAR sensor. Regions are determined using histogram-based data from gray-scale image. Image segmentation and spectral clustering are used for identification and rough estimation of potholes. Speed hump; on the other hand, are detected by integrating the LIDAR measurements in time, relative to the motion of the vehicle. The algorithm is implemented in C++ with Open Source Computer Vision (OpenCV) Library. The pothole detection system can detect potholes 1.6m to 5m away from the vehicle with 86.18 percent accuracy, while the speed hump detection system can detect speed humps at an optimal distance of 4.13m with an accuracy of 98.36 percent. Errors during the detection are due to the algorithms implemented, and hardware limitations. When the two systems are cascaded, the resulting system is reliable with 80.83 percent accuracy in pothole detection, and 98.46 percent accuracy in speed hump detection. However, this is only true if the number of potholes and speed humps to be detected are minimal. The limitation of the cascaded system is imposed by the single execution capability of the processing module. Thus, to be able to use the system together, separate processing module should be used for each system.},
	language = {en},
	journal = {Hong Kong},
	author = {Sucgang, Nathalie Joy and Jr, Manuel Ramos and Arriola, Nicolette Ann},
	year = {2017},
	pages = {5},
	file = {Sucgang et al. - 2017 - Road Surface Obstacle Detection using Vision and L.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/RZHRFZQA/Sucgang et al. - 2017 - Road Surface Obstacle Detection using Vision and L.pdf:application/pdf},
}

@article{ravi_pothole_2020,
	title = {Pothole {Mapping} and {Patching} {Quantity} {Estimates} using {LiDAR}-{Based} {Mobile} {Mapping} {Systems}},
	volume = {2674},
	issn = {0361-1981},
	url = {https://doi.org/10.1177/0361198120927006},
	doi = {10.1177/0361198120927006},
	abstract = {Pavement distress or pothole mapping is important to public agencies responsible for maintaining roadways. The efficient capture of 3D point cloud data using mapping systems equipped with LiDAR eliminates the time-consuming and labor-intensive manual classification and quantity estimates. This paper proposes a methodology to map potholes along the road surface using ultra-high accuracy LiDAR units onboard a wheel-based mobile mapping system. LiDAR point clouds are processed to detect and report the location and severity of potholes by identifying the below-road 3D points pertaining to potholes, along with their depths. The surface area and volume of each detected pothole is also estimated along with the volume of its minimum bounding box to serve as an aide to choose the ideal method of repair as well as to estimate the cost of repair. The proposed approach was tested on a 10 mi-long segment on a U.S. Highway and it is observed to accurately detect potholes with varying severity and different causes. A sample of potholes detected in a 1 mi segment has been reported in the experimental results of this paper. The point clouds generated using the system are observed to have a single-track relative accuracy of less than ±1 cm and a multi-track relative accuracy of ±1–2 cm, which has been verified through comparing point clouds captured by different sensors from different tracks.},
	language = {en},
	number = {9},
	urldate = {2021-10-14},
	journal = {Transportation Research Record},
	author = {Ravi, Radhika and Habib, Ayman and Bullock, Darcy},
	month = sep,
	year = {2020},
	note = {Publisher: SAGE Publications Inc},
	pages = {124--134},
}

@inproceedings{chang_detection_2005,
	address = {Cancun, Mexico},
	title = {Detection of {Pavement} {Distresses} {Using} {3D} {Laser} {Scanning} {Technology}},
	isbn = {978-0-7844-0794-3},
	url = {http://ascelibrary.org/doi/10.1061/40794%28179%29103},
	doi = {10.1061/40794(179)103},
	language = {en},
	urldate = {2021-10-14},
	booktitle = {Computing in {Civil} {Engineering} (2005)},
	publisher = {American Society of Civil Engineers},
	author = {Chang, K. T. and Chang, J. R. and Liu, J. K.},
	month = jun,
	year = {2005},
	pages = {1--11},
}

@inproceedings{korotkova_lidar_2004,
	address = {Barcelona, Spain},
	title = {Lidar model for a rough-surface target: method of partial coherence},
	shorttitle = {Lidar model for a rough-surface target},
	url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.515086},
	doi = {10.1117/12.515086},
	urldate = {2021-10-14},
	author = {Korotkova, Olga and Andrews, Larry C. and Phillips, Ronald L.},
	editor = {Gonglewski, John D. and Stein, Karin},
	month = feb,
	year = {2004},
	pages = {49},
}

@article{rychkov_computational_2012,
	title = {Computational and methodological aspects of terrestrial surface analysis based on point clouds},
	volume = {42},
	issn = {0098-3004},
	url = {https://www.sciencedirect.com/science/article/pii/S0098300412000465},
	doi = {10.1016/j.cageo.2012.02.011},
	abstract = {Processing of high-resolution terrestrial laser scanning (TLS) point clouds presents methodological and computational challenges before a geomorphological analysis can be carried out. We present a software library that effectively deals with billions of points and implements a simple methodology to study the surface profile and roughness. Adequate performance and scalability were achieved through the use of 64-bit memory mapped files, regular 2D grid sorting, and parallel processing. The plethora of the spatial scales found in a TLS dataset were grouped into the “ground” model at the grid scale and per cell, sub-grid surface roughness. We used centroid-thinning to build a piecewise linear ground model, and studied “detrended” standard deviation of relative elevations as a measure of surface roughness. Two applications to the point clouds from gravel river bed surveys are described. Linking empirically the standard deviation to the grain size allowed us to retrieve morphological and sedimentological models of channel topology evolution and movement of the gravel with richer quantitative results and deeper insights than the previous survey techniques.},
	language = {en},
	urldate = {2021-10-14},
	journal = {Computers \& Geosciences},
	author = {Rychkov, Igor and Brasington, James and Vericat, Damià},
	month = may,
	year = {2012},
	keywords = {Geomorphology, Point clouds, Sedimentology, Surface roughness, TLS},
	pages = {64--70},
	file = {ScienceDirect Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/Z76FUL7R/S0098300412000465.html:text/html},
}

@article{lague_accurate_2013,
	title = {Accurate {3D} comparison of complex topography with terrestrial laser scanner: {Application} to the {Rangitikei} canyon ({N}-{Z})},
	volume = {82},
	issn = {0924-2716},
	shorttitle = {Accurate {3D} comparison of complex topography with terrestrial laser scanner},
	url = {https://www.sciencedirect.com/science/article/pii/S0924271613001184},
	doi = {10.1016/j.isprsjprs.2013.04.009},
	abstract = {Surveying techniques such as terrestrial laser scanner have recently been used to measure surface changes via 3D point cloud (PC) comparison. Two types of approaches have been pursued: 3D tracking of homologous parts of the surface to compute a displacement field, and distance calculation between two point clouds when homologous parts cannot be defined. This study deals with the second approach, typical of natural surfaces altered by erosion, sedimentation or vegetation between surveys. Current comparison methods are based on a closest point distance or require at least one of the PC to be meshed with severe limitations when surfaces present roughness elements at all scales. To solve these issues, we introduce a new algorithm performing a direct comparison of point clouds in 3D. The method has two steps: (1) surface normal estimation and orientation in 3D at a scale consistent with the local surface roughness; (2) measurement of the mean surface change along the normal direction with explicit calculation of a local confidence interval. Comparison with existing methods demonstrates the higher accuracy of our approach, as well as an easier workflow due to the absence of surface meshing or Digital Elevation Model (DEM) generation. Application of the method in a rapidly eroding, meandering bedrock river (Rangitikei River canyon) illustrates its ability to handle 3D differences in complex situations (flat and vertical surfaces on the same scene), to reduce uncertainty related to point cloud roughness by local averaging and to generate 3D maps of uncertainty levels. We also demonstrate that for high precision survey scanners, the total error budget on change detection is dominated by the point clouds registration error and the surface roughness. Combined with mm-range local georeferencing of the point clouds, levels of detection down to 6mm (defined at 95\% confidence) can be routinely attained in situ over ranges of 50m. We provide evidence for the self-affine behaviour of different surfaces. We show how this impacts the calculation of normal vectors and demonstrate the scaling behaviour of the level of change detection. The algorithm has been implemented in a freely available open source software package. It operates in complex 3D cases and can also be used as a simpler and more robust alternative to DEM differencing for the 2D cases.},
	language = {en},
	urldate = {2021-10-15},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
	author = {Lague, Dimitri and Brodu, Nicolas and Leroux, Jérôme},
	month = aug,
	year = {2013},
	keywords = {Geomorphology, Surface roughness, 3D change detection, Point cloud, Self-affinity, Terrestrial laser scanner},
	pages = {10--26},
	file = {ScienceDirect Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/VFTEAK5W/S0924271613001184.html:text/html},
}

@article{schnabel_efficient_2007,
	title = {Efficient {RANSAC} for {Point}-{Cloud} {Shape} {Detection}},
	volume = {26},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2007.01016.x},
	doi = {10.1111/j.1467-8659.2007.01016.x},
	abstract = {In this paper we present an automatic algorithm to detect basic shapes in unorganized point clouds. The algorithm decomposes the point cloud into a concise, hybrid structure of inherent shapes and a set of remaining points. Each detected shape serves as a proxy for a set of corresponding points. Our method is based on random sampling and detects planes, spheres, cylinders, cones and tori. For models with surfaces composed of these basic shapes only, for example, CAD models, we automatically obtain a representation solely consisting of shape proxies. We demonstrate that the algorithm is robust even in the presence of many outliers and a high degree of noise. The proposed method scales well with respect to the size of the input point cloud and the number and size of the shapes within the data. Even point sets with several millions of samples are robustly decomposed within less than a minute. Moreover, the algorithm is conceptually simple and easy to implement. Application areas include measurement of physical parameters, scan registration, surface compression, hybrid rendering, shape classification, meshing, simplification, approximation and reverse engineering.},
	language = {en},
	number = {2},
	urldate = {2021-10-18},
	journal = {Computer Graphics Forum},
	author = {Schnabel, R. and Wahl, R. and Klein, R.},
	year = {2007},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8659.2007.01016.x},
	keywords = {geometry analysis, I.3.5: Computational Geometry and Object Modeling Curve, I.4.8: Scene Analysis Shape, large point-clouds, localized RANSAC, object representations, primitive shapes, shape fitting, solid, surface, Surface Fitting},
	pages = {214--226},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/TLC8W7IN/Schnabel et al. - 2007 - Efficient RANSAC for Point-Cloud Shape Detection.pdf:application/pdf;Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/UEBHVV4C/j.1467-8659.2007.01016.html:text/html},
}

@article{li_improved_2017,
	title = {An {Improved} {RANSAC} for {3D} {Point} {Cloud} {Plane} {Segmentation} {Based} on {Normal} {Distribution} {Transformation} {Cells}},
	volume = {9},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2072-4292/9/5/433},
	doi = {10.3390/rs9050433},
	abstract = {Plane segmentation is a basic task in the automatic reconstruction of indoor and urban environments from unorganized point clouds acquired by laser scanners. As one of the most common plane-segmentation methods, standard Random Sample Consensus (RANSAC) is often used to continually detect planes one after another. However, it suffers from the spurious-plane problem when noise and outliers exist due to the uncertainty of randomly sampling the minimum subset with 3 points. An improved RANSAC method based on Normal Distribution Transformation (NDT) cells is proposed in this study to avoid spurious planes for 3D point-cloud plane segmentation. A planar NDT cell is selected as a minimal sample in each iteration to ensure the correctness of sampling on the same plane surface. The 3D NDT represents the point cloud with a set of NDT cells and models the observed points with a normal distribution within each cell. The geometric appearances of NDT cells are used to classify the NDT cells into planar and non-planar cells. The proposed method is verified on three indoor scenes. The experimental results show that the correctness exceeds 88.5\% and the completeness exceeds 85.0\%, which indicates that the proposed method identifies more reliable and accurate planes than standard RANSAC. It also executes faster. These results validate the suitability of the method.},
	language = {en},
	number = {5},
	urldate = {2021-10-18},
	journal = {Remote Sensing},
	author = {Li, Lin and Yang, Fan and Zhu, Haihong and Li, Dalin and Li, You and Tang, Lei},
	month = may,
	year = {2017},
	note = {Number: 5
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {NDT features, normal distribution transformation, plane segmentation, point cloud, RANSAC},
	pages = {433},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/MVGNTFV3/Li et al. - 2017 - An Improved RANSAC for 3D Point Cloud Plane Segmen.pdf:application/pdf;Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/2AHRB7VV/433.html:text/html},
}

@article{li_point_2021,
	title = {Point {Cloud} {Registration} {Based} on {One}-{Point} {RANSAC} and {Scale}-{Annealing} {Biweight} {Estimation}},
	issn = {1558-0644},
	doi = {10.1109/TGRS.2020.3045456},
	abstract = {Point cloud registration (PCR) is an important task in photogrammetry and remote sensing, whose goal is to seek a seven-parameter similarity transformation to register a pair of point clouds. Traditional iterative closest point (ICP) variants highly rely on the initial parameters, and most of them cannot deal with cross-source (multisource) point clouds with scale changes. In this article, we propose a flexible correspondence-based PCR method, which is initial-guess free, fast, and robust. We first decompose the full seven-parameter registration problem into three subproblems, i.e., scale, rotation, and translation estimations, based on line vectors. Then, we propose a one-point random sample consensus (RANSAC) algorithm to estimate the scale and translation parameters. For the rotation estimation, we introduce a graduated optimization strategy into Tukey's biweight function and propose a scale-annealing biweight estimator. We evaluate the proposed method on both same-source and cross-source data. Results show that the proposed method is robust against over 99\% outliers and is one to two orders of magnitude faster than its competitors. The source code of our method will be made public.},
	journal = {IEEE Transactions on Geoscience and Remote Sensing},
	author = {Li, Jiayuan and Hu, Qingwu and Ai, Mingyao},
	year = {2021},
	note = {Conference Name: IEEE Transactions on Geoscience and Remote Sensing},
	keywords = {Laser radar, Estimation, Three-dimensional displays, Robustness, Biweight estimator, correspondence, cross-source (multisource), Detectors, Feature extraction, point cloud registration (PCR), random sample consensus (RANSAC)., Shape},
	pages = {1--14},
}

@article{li_integrate_2020,
	title = {Integrate {Point}-{Cloud} {Segmentation} with {3D} {LiDAR} {Scan}-{Matching} for {Mobile} {Robot} {Localization} and {Mapping}},
	volume = {20},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/20/1/237},
	doi = {10.3390/s20010237},
	abstract = {Localization and mapping are key requirements for autonomous mobile systems to perform navigation and interaction tasks. Iterative Closest Point (ICP) is widely applied for LiDAR scan-matching in the robotic community. In addition, the standard ICP algorithm only considers geometric information when iteratively searching for the nearest point. However, ICP individually cannot achieve accurate point-cloud registration performance in challenging environments such as dynamic environments and highways. Moreover, the computation of searching for the closest points is an expensive step in the ICP algorithm, which is limited to meet real-time requirements, especially when dealing with large-scale point-cloud data. In this paper, we propose a segment-based scan-matching framework for six degree-of-freedom pose estimation and mapping. The LiDAR generates a large number of ground points when scanning, but many of these points are useless and increase the burden of subsequent processing. To address this problem, we first apply an image-based ground-point extraction method to filter out noise and ground points. The point cloud after removing the ground points is then segmented into disjoint sets. After this step, a standard point-to-point ICP is applied into to calculate the six degree-of-freedom transformation between consecutive scans. Furthermore, once closed loops are detected in the environment, a 6D graph-optimization algorithm for global relaxation (6D simultaneous localization and mapping (SLAM)) is employed. Experiments based on publicly available KITTI datasets show that our method requires less runtime while at the same time achieves higher pose estimation accuracy compared with the standard ICP method and its variants.},
	language = {en},
	number = {1},
	urldate = {2021-10-18},
	journal = {Sensors},
	author = {Li, Xuyou and Du, Shitong and Li, Guangchun and Li, Haoyu},
	month = jan,
	year = {2020},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {6D SLAM, closed loops, dynamic environments, ground point, ICP, segmentation},
	pages = {237},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/TEH7ZDZ9/Li et al. - 2020 - Integrate Point-Cloud Segmentation with 3D LiDAR S.pdf:application/pdf},
}

@inproceedings{gojcic_perfect_2019,
	address = {Long Beach, CA, USA},
	title = {The {Perfect} {Match}: {3D} {Point} {Cloud} {Matching} {With} {Smoothed} {Densities}},
	isbn = {978-1-72813-293-8},
	shorttitle = {The {Perfect} {Match}},
	url = {https://ieeexplore.ieee.org/document/8954296/},
	doi = {10.1109/CVPR.2019.00569},
	abstract = {We propose 3DSmoothNet, a full workﬂow to match 3D point clouds with a siamese deep learning architecture and fully convolutional layers using a voxelized smoothed density value (SDV) representation. The latter is computed per interest point and aligned to the local reference frame (LRF) to achieve rotation invariance. Our compact, learned, rotation invariant 3D point cloud descriptor achieves 94.9\% average recall on the 3DMatch benchmark data set [49], outperforming the state-of-the-art by more than 20 percent points with only 32 output dimensions. This very low output dimension allows for near realtime correspondence search with 0.1 ms per feature point on a standard PC. Our approach is sensor- and sceneagnostic because of SDV, LRF and learning highly descriptive features with fully convolutional layers. We show that 3DSmoothNet trained only on RGB-D indoor scenes of buildings achieves 79.0\% average recall on laser scans of outdoor vegetation, more than double the performance of our closest, learning-based competitors [49, 17, 5, 4]. Code, data and pre-trained models are available online at https://github.com/zgojcic/3DSmoothNet.},
	language = {en},
	urldate = {2021-10-18},
	booktitle = {2019 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Gojcic, Zan and Zhou, Caifa and Wegner, Jan D. and Wieser, Andreas},
	month = jun,
	year = {2019},
	pages = {5540--5549},
	file = {Gojcic et al. - 2019 - The Perfect Match 3D Point Cloud Matching With Sm.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/J3VP5Y29/Gojcic et al. - 2019 - The Perfect Match 3D Point Cloud Matching With Sm.pdf:application/pdf},
}

@inproceedings{yuan_3d_2016,
	title = {{3D} point cloud matching based on principal component analysis and iterative closest point algorithm},
	doi = {10.1109/ICALIP.2016.7846655},
	abstract = {Point cloud matching is one of the key technologies of optical three-dimensional contour measurement. Most of the point cloud matching without landmark used the iterative closest point algorithm. In order to improve the performance of the iterative closest point algorithm, the two-step iterative closest point algorithm was proposed. The improved algorithm is divided into a rough matching step and accurate matching step. Rough matching used the principal component analysis algorithm, while the fine matching used the improved iterative closest point algorithm. Compared with the classic iterative closest point algorithm, the improved algorithm can match the partial coincident point cloud. At the same time, the experiment can validate the effectiveness of the proposed algorithm.},
	booktitle = {2016 {International} {Conference} on {Audio}, {Language} and {Image} {Processing} ({ICALIP})},
	author = {Yuan, Chi and Yu, Xiaoqing and Luo, Ziyue},
	month = jul,
	year = {2016},
	keywords = {Three-dimensional displays, Algorithm design and analysis, 3D matching, Automation measuring, Convergence, Iterative closest point algorithm, iterative closet point algorithm, Principal component analysis, Quaternions, Transforms},
	pages = {404--408},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/6RVHK7MX/7846655.html:text/html},
}

@inproceedings{huang_point_2012,
	address = {Providence, RI, USA},
	title = {Point cloud matching based on {3D} self-similarity},
	isbn = {978-1-4673-1612-5 978-1-4673-1611-8 978-1-4673-1610-1},
	url = {http://ieeexplore.ieee.org/document/6238913/},
	doi = {10.1109/CVPRW.2012.6238913},
	urldate = {2021-10-18},
	booktitle = {2012 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops}},
	publisher = {IEEE},
	author = {Huang, Jing and You, Suya},
	month = jun,
	year = {2012},
	pages = {41--48},
}

@article{yang_plane_nodate,
	title = {Plane {Detection} in {Point} {Cloud} {Data}},
	abstract = {Plane detection is a prerequisite to a wide variety of vision tasks. RANdom SAmple Consensus (RANSAC) algorithm is widely used for plane detection in point cloud data. Minimum description length (MDL) principle is used to deal with several competing hypothesis. This paper presents a new approach to the plane detection by integrating RANSAC and MDL. The method could avoid detecting wrong planes due to the complex geometry of the 3D data. The paper tests the performance of proposed method on both synthetic and real data.},
	language = {en},
	author = {Yang, Michael Ying and Forstner, Wolfgang},
	pages = {16},
	file = {Yang and Forstner - Plane Detection in Point Cloud Data.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/EDJG8BJR/Yang and Forstner - Plane Detection in Point Cloud Data.pdf:application/pdf},
}

@inproceedings{yue_new_2018,
	title = {A new plane segmentation method of point cloud based on mean shift and {RANSAC}},
	doi = {10.1109/CCDC.2018.8407394},
	abstract = {Three dimensional laser scanning technology has been widely used in machine vision and reverse engineering. Plane segmentation is an important step for object recognition in the point cloud obtained by laser scanner. Traditional plane segmentation method cannot obtain a specific plane accurately when normal is unknown. This paper proposes a new method based on Mean Shift normal clustering and RANSAC with constraints and initial point to segment the specific plane whose the normal is unknown. Firstly, the point cloud is down sampled using Voxel Grid method. Secondly, the algorithm uses Mean Shift clustering method on the normal sphere to obtain the actual normal of the plane to be segmented. Thirdly, with stopping point as initial condition and actual normal as constraint, RANSAC algorithm is used to segment the specific plane. Finally this algorithm is experimentally validated in point cloud data of actual scene.},
	booktitle = {2018 {Chinese} {Control} {And} {Decision} {Conference} ({CCDC})},
	author = {Yue, Wenlong and Lu, Junguo and Zhou, Weihang and Miao, Yubin},
	month = jun,
	year = {2018},
	note = {ISSN: 1948-9447},
	keywords = {Estimation, Three-dimensional displays, RANSAC, Clustering algorithms, Covariance matrices, Mathematical model, Mean Shift, Object segmentation, Plane Segmentation, Point Cloud, Surface reconstruction},
	pages = {1658--1663},
}

@article{koguciuk_parallel_2017,
	title = {Parallel {RANSAC} for {Point} {Cloud} {Registration}},
	volume = {42},
	issn = {2300-3405},
	url = {https://www.sciendo.com/article/10.1515/fcds-2017-0010},
	doi = {10.1515/fcds-2017-0010},
	abstract = {In this paper, a project and implementation of the parallel RANSAC algorithm in CUDA architecture for point cloud registration are presented. At the beginning, a serial state of the art method with several heuristic improvements from the literature compared to basic RANSAC is introduced. Subsequently, its algorithmic parallelization and CUDA implementation details are discussed. The comparative test has proven a signiﬁcant program execution acceleration. The result is ﬁnding of the local coordinate system of the object in the scene in the near realtime conditions. The source code is shared on the Internet as a part of the Heuros system.},
	language = {en},
	number = {3},
	urldate = {2021-10-18},
	journal = {Foundations of Computing and Decision Sciences},
	author = {Koguciuk, Daniel},
	month = sep,
	year = {2017},
	pages = {203--217},
	file = {Koguciuk - 2017 - Parallel RANSAC for Point Cloud Registration.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/VKTVPMBC/Koguciuk - 2017 - Parallel RANSAC for Point Cloud Registration.pdf:application/pdf},
}

@article{tarsha-kurdi_hough-transform_2007,
	title = {Hough-{Transform} and {Extended} {RANSAC} {Algorithms} for {Automatic} {Detection} of {3D} {Building} {Roof} {Planes} from {Lidar} {Data}},
	abstract = {Airborne laser scanner technique is broadly the most appropriate way to acquire rapidly and with high density 3D data over a city. Once the 3D Lidar data are available, the next task is the automatic data processing, with major aim to construct 3D building models. Among the numerous automatic reconstruction methods, the techniques allowing the detection of 3D building roof planes are of crucial importance. Three main methods arise from the literature: region growing, Hough-transform and Random Sample Consensus (RANSAC) paradigm. Since region growing algorithms are sometimes not very transparent and not homogenously applied, this paper focuses only on the Hough-transform and the RANSAC algorithm. Their principles, their pseudocode - rarely detailed in the related literature - as well as their complete analyses are presented in this paper. An analytic comparison of both algorithms, in terms of processing time and sensitivity to cloud characteristics, shows that despite the limitation encountered in both methods, RANSAC algorithm is still more efficient than the first one. Under other advantages, its processing time is negligible even when the input data size is very large. On the other hand, Hough-transform is very sensitive to the segmentation parameters values. Therefore, RANSAC algorithm has been chosen and extended to exceed its limitations. Its major limitation is that it searches to detect the best mathematical plane among 3D building point cloud even if this plane does not always represent a roof plane. So the proposed extension allows harmonizing the mathematical aspect of the algorithm with the geometry of a roof. At last, it is shown that the extended approach provides very satisfying results, even in the case of very weak point density and for different levels of building complexity. Therefore, once the roof planes are successfully detected, the automatic building modelling can be carried out.},
	language = {en},
	author = {Tarsha-Kurdi, Fayez and Landes, Tania and Grussenmeyer, Pierre},
	year = {2007},
	pages = {7},
	file = {Tarsha-Kurdi et al. - 2007 - Hough-Transform and Extended RANSAC Algorithms for.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/L8SPGNSM/Tarsha-Kurdi et al. - 2007 - Hough-Transform and Extended RANSAC Algorithms for.pdf:application/pdf},
}

@inproceedings{petrelli_repeatable_2012,
	title = {A {Repeatable} and {Efficient} {Canonical} {Reference} for {Surface} {Matching}},
	doi = {10.1109/3DIMPVT.2012.51},
	abstract = {The paper investigates on canonical references used for local surface description and matching. We formulate a novel proposal and carry out an extensive experimental evaluation addressing two major surface matching scenarios, namely shape registration and object recognition. We provide also a methodological contribution as, unlike previous work in the field, we propose a repeatability metric that captures the actual impact of the adopted local reference frame algorithm within surface matching tasks based on local 3D descriptors. Our proposal outperforms existing algorithms by a wide margin on several datasets acquired with different devices, such as laser scanners, stereo cameras and the Kinect, and in experiments relying on randomly extracted feature as well as state-of-the art key points.},
	booktitle = {Visualization {Transmission} 2012 {Second} {International} {Conference} on {3D} {Imaging}, {Modeling}, {Processing}},
	author = {Petrelli, Alioscia and Di Stefano, Luigi},
	month = oct,
	year = {2012},
	note = {ISSN: 1550-6185},
	keywords = {Feature extraction, Shape, 3D descriptor, Indexes, local reference frame, Measurement, Object recognition, Proposals, surface matching, Vectors},
	pages = {403--410},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/Z74GCHVP/6375021.html:text/html},
}

@inproceedings{petrelli_repeatable_2012-1,
	address = {Zurich, Switzerland},
	title = {A {Repeatable} and {Efficient} {Canonical} {Reference} for {Surface} {Matching}},
	isbn = {978-0-7695-4873-9 978-1-4673-4470-8},
	url = {http://ieeexplore.ieee.org/document/6375021/},
	doi = {10.1109/3DIMPVT.2012.51},
	urldate = {2021-10-18},
	booktitle = {2012 {Second} {International} {Conference} on {3D} {Imaging}, {Modeling}, {Processing}, {Visualization} \& {Transmission}},
	publisher = {IEEE},
	author = {Petrelli, Alioscia and Di Stefano, Luigi},
	month = oct,
	year = {2012},
	pages = {403--410},
}

@inproceedings{bosse_continuous_2009,
	title = {Continuous {3D} scan-matching with a spinning {2D} laser},
	doi = {10.1109/ROBOT.2009.5152851},
	abstract = {Scan-matching is a technique that can be used for building accurate maps and estimating vehicle motion by comparing a sequence of point cloud measurements of the environment taken from a moving sensor. One challenge that arises in mapping applications where the sensor motion is fast relative to the measurement time is that scans become locally distorted and difficult to align. This problem is common when using 3D laser range sensors, which typically require more scanning time than their 2D counterparts. Existing 3D mapping solutions either eliminate sensor motion by taking a “stop-and-scan” approach, or attempt to correct the motion in an open-loop fashion using odometric or inertial sensors. We propose a solution to 3D scan-matching in which a continuous 6DOF sensor trajectory is recovered to correct the point cloud alignments, producing locally accurate maps and allowing for a reliable estimate of the vehicle motion. Our method is applied to data collected from a 3D spinning lidar sensor mounted on a skid-steer loader vehicle to produce quality maps of outdoor scenes and estimates of the vehicle trajectory during the mapping sequences.},
	booktitle = {2009 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Bosse, Michael and Zlot, Robert},
	month = may,
	year = {2009},
	note = {ISSN: 1050-4729},
	keywords = {Laser radar, Vehicles, 3D mapping, Clouds, Distortion measurement, Laser noise, motion estimation, Motion estimation, Motion measurement, scan-matching, Spinning, spinning laser, Time measurement, Trajectory},
	pages = {4312--4319},
}

@article{brady_describing_1985,
	title = {Describing surfaces},
	volume = {32},
	issn = {0734-189X},
	url = {https://www.sciencedirect.com/science/article/pii/0734189X85900015},
	doi = {10.1016/0734-189X(85)90001-5},
	abstract = {This paper continues our work on visual representations of 2-dimensional surfaces. The theoretical component of our work is a study of classes of surface curves as a source of constraint on the surface on which they lie, and as a basis for describing it. We analyze bounding contours, surface intersections, lines of curvature, and asymptotes. Our experimental work investigates whether the information suggested by our theoretical study can be computed reliably and efficiently. We demonstrate algorithms that compute lines of curvature of a (Gaussian smoothed) surface; determine planar patches and umbilic regions; extract axes of surfaces of revolution and tube surfaces. We report preliminary results on adapting the curvature primal sketch algorithms of Asada and Brady [1984] to detect and describe surface intersections.},
	language = {en},
	number = {1},
	urldate = {2021-10-18},
	journal = {Computer Vision, Graphics, and Image Processing},
	author = {Brady, Michael and Ponce, Jean and Yuille, Alan and Asada, Haruo},
	month = oct,
	year = {1985},
	pages = {1--28},
	file = {ScienceDirect Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/BXDZUWWZ/0734189X85900015.html:text/html},
}

@article{catalucci_comparison_2018,
	title = {Comparison between point cloud processing techniques},
	volume = {127},
	issn = {0263-2241},
	url = {https://www.sciencedirect.com/science/article/pii/S0263224118305116},
	doi = {10.1016/j.measurement.2018.05.111},
	abstract = {Photomodelling is an innovative, economical and fast technique based on the same principles of photogrammetry, which leads to the creation of 3-dimensional models starting from the simple acquisition of photographs. The aim of this paper is to define performances and metrological characteristics of this new technique and to understand the full potential offered by point cloud processing software. The analytical comparison considers a structured light 3D scanning system Creaform Go Scan 50 with metrological certification as a reference, in order to verify the accuracy and precision of photomodelling, using a modified function of the ICP algorithm and spatial, volumetric and superficial comparison criteria.},
	language = {en},
	urldate = {2021-10-18},
	journal = {Measurement},
	author = {Catalucci, Sofia and Marsili, Roberto and Moretti, Michele and Rossi, Gianluca},
	month = oct,
	year = {2018},
	keywords = {Point cloud, Iterative Closest Point algorithm, Measurement criteria, Photomodelling},
	pages = {221--226},
	file = {ScienceDirect Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/88VWXV2L/S0263224118305116.html:text/html},
}

@article{droeschel_continuous_2017,
	title = {Continuous mapping and localization for autonomous navigation in rough terrain using a {3D} laser scanner},
	volume = {88},
	issn = {0921-8890},
	url = {https://www.sciencedirect.com/science/article/pii/S0921889015303110},
	doi = {10.1016/j.robot.2016.10.017},
	abstract = {For autonomous navigation in difficult terrain, such as degraded environments in disaster response scenarios, robots are required to create a map of an unknown environment and to localize within this map. In this paper, we describe our approach to simultaneous localization and mapping that is based on the measurements of a 3D laser-range finder. We aggregate laser-range measurements by registering sparse 3D scans with a local multiresolution surfel map that has high resolution in the vicinity of the robot and coarser resolutions with increasing distance, which corresponds well to measurement density and accuracy of our sensor. By modeling measurements by surface elements, our approach allows for efficient and accurate registration and leverages online mapping and localization. The incrementally built local dense 3D maps of nearby key poses are registered against each other. Graph optimization yields a globally consistent dense 3D map of the environment. Continuous registration of local maps with the global map allows for tracking the 6D robot pose in real time. We assess the drivability of the terrain by analyzing height differences in an allocentric height map and plan cost-optimal paths. The system has been successfully demonstrated during the DARPA Robotics Challenge and the DLR SpaceBot Camp. In experiments, we evaluate accuracy and efficiency of our approach.},
	language = {en},
	urldate = {2021-10-18},
	journal = {Robotics and Autonomous Systems},
	author = {Droeschel, David and Schwarz, Max and Behnke, Sven},
	month = feb,
	year = {2017},
	keywords = {Localization, Mapping, Rough terrain},
	pages = {104--115},
	file = {ScienceDirect Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/BT8MELZS/S0921889015303110.html:text/html},
}

@article{brubaker_use_2013,
	title = {The {Use} of {LiDAR} {Terrain} {Data} in {Characterizing} {Surface} {Roughness} and {Microtopography}},
	volume = {2013},
	issn = {1687-7667},
	url = {https://www.hindawi.com/journals/aess/2013/891534/},
	doi = {10.1155/2013/891534},
	abstract = {The availability of light detection and ranging data (LiDAR) has resulted in a new era of landscape analysis. For example, improvements in LiDAR data resolution may make it possible to accurately model microtopography over a large geographic area; however, data resolution and processing costs versus resulting accuracy may be too costly. We examined two LiDAR datasets of differing resolutions, a low point density (0.714 points/m2 spacing) 1 m DEM available statewide in Pennsylvania and a high point density (10.28 points/m2 spacing) 1 m DEM research-grade DEM, and compared the calculated roughness between both resulting DEMs using standard deviation of slope, standard deviation of curvature, a pit fill index, and the difference between a smoothed splined surface and the original DEM. These results were then compared to field-surveyed plots and transects of microterrain. Using both datasets, patterns of roughness were identified, which were associated with different landforms derived from hydrogeomorphic features such as stream channels, gullies, and depressions. Lowland areas tended to have the highest roughness values for all methods, with other areas showing distinctive patterns of roughness values across metrics. However, our results suggest that the high-resolution research-grade LiDAR did not improve roughness modeling in comparison to the coarser statewide LiDAR. We conclude that resolution and initial point density may not be as important as the algorithm and methodology used to generate a LiDAR-derived DEM for roughness modeling purposes.},
	language = {en},
	urldate = {2021-10-19},
	journal = {Applied and Environmental Soil Science},
	author = {Brubaker, Kristen M. and Myers, Wayne L. and Drohan, Patrick J. and Miller, Douglas A. and Boyer, Elizabeth W.},
	month = apr,
	year = {2013},
	note = {Publisher: Hindawi},
	pages = {e891534},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/9F8KZY86/Brubaker et al. - 2013 - The Use of LiDAR Terrain Data in Characterizing Su.pdf:application/pdf;Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/BFWWMX9B/891534.html:text/html},
}

@article{turner_estimation_2014,
	title = {Estimation of soil surface roughness of agricultural soils using airborne {LiDAR}},
	volume = {140},
	issn = {0034-4257},
	url = {https://www.sciencedirect.com/science/article/pii/S0034425713002885},
	doi = {10.1016/j.rse.2013.08.030},
	abstract = {Soil Surface Roughness (SR) provides a representation of surface variability which can be an important factor in a range of modelling applications such as surface water flow and sediment/nutrient transport. Moreover, it is a crucial parameter for interpreting backscatter characteristics of Synthetic Aperture Radar (SAR) for agricultural application such as near-surface soil moisture retrieval. SR is typically estimated using manual profiles of height variation along short transects (1 to 3m). However, this approach can be very time consuming and often only a small number of transects can be measured in this way, which may not be adequate to characterize the spatial variability of SR across the landscape. This study investigated the feasibility of utilising airborne Light Detection and Ranging (LiDAR) observations as an alternative for mapping SR attributes across an agricultural environment in New South Wales, Australia. To that end, SR attributes were extracted from airborne LiDAR observations and compared with those extracted from an extensive ground survey of SR making use of manual pin-profilers. Results show that LiDAR-estimates of soil profile surface heights Root Mean Square (RMS) are both accurate (compared to manual profiles) and precise (repeatable stable estimates) for fields presenting bare or fallow conditions and either presenting no row structure or as long as the orientation of the LiDAR scan line is perpendicular to the row structure. In such cases results indicated a strong correlation between LiDAR-estimated and ground-measured RMS estimates (R2{\textgreater}0.68, p{\textless}0.05), with an RMSE better than 0.81cm and bias smaller than 0.48cm from a 400m flight altitude. Moreover, estimates produced from repeat pass LiDAR datasets were consistent and highly correlated (R2 0.98) suggesting that the approach is precise and robust, provided that key tillage parameters (i.e. presence of vegetative material and row direction) can be pre-classified. LiDAR estimates of surface height RMS were shown to be accurate enough to allow the tracking of temporal changes in surface roughness due to farming activities. In contrast, LiDAR-derived surface Correlation Length (CL) estimates were not found to be a reliable proxy of the ground-measured CL.},
	language = {en},
	urldate = {2021-10-19},
	journal = {Remote Sensing of Environment},
	author = {Turner, Russell and Panciera, Rocco and Tanase, Mihai A. and Lowell, Kim and Hacker, Jorg M. and Walker, Jeffrey P.},
	month = jan,
	year = {2014},
	keywords = {Remote sensing, LiDAR, Surface roughness, Airborne},
	pages = {107--117},
	file = {ScienceDirect Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/G6QIQTLZ/S0034425713002885.html:text/html},
}

@article{campbell_lidar-based_2017,
	title = {A {LiDAR}-based analysis of the effects of slope, vegetation density, and ground surface roughness on travel rates for wildland firefighter escape route mapping},
	volume = {26},
	issn = {1049-8001},
	url = {http://www.publish.csiro.au/?paper=WF17031},
	doi = {10.1071/WF17031},
	abstract = {Escape routes are essential components of wildland firefighter safety, providing pre-defined pathways to a safety zone. Among the many factors that affect travel rates along an escape route, landscape conditions such as slope, lowlying vegetation density, and ground surface roughness are particularly influential, and can be measured using airborne light detection and ranging (LiDAR) data. In order to develop a robust, quantitative understanding of the effects of these landscape conditions on travel rates, we performed an experiment wherein study participants were timed while walking along a series of transects within a study area dominated by grasses, sagebrush and juniper. We compared resultant travel rates to LiDAR-derived estimates of slope, vegetation density and ground surface roughness using linear mixed effects modelling to quantify the relationships between these landscape conditions and travel rates. The best-fit model revealed significant negative relationships between travel rates and each of the three landscape conditions, suggesting that, in order of decreasing magnitude, as density, slope and roughness increase, travel rates decrease. Model coefficients were used to map travel impedance within the study area using LiDAR data, which enabled mapping the most efficient routes from fire crew locations to safety zones and provided an estimate of travel time.},
	language = {en},
	number = {10},
	urldate = {2021-10-19},
	journal = {International Journal of Wildland Fire},
	author = {Campbell, Michael J. and Dennison, Philip E. and Butler, Bret W.},
	year = {2017},
	pages = {884},
	file = {Campbell et al. - 2017 - A LiDAR-based analysis of the effects of slope, ve.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/H2AYTULD/Campbell et al. - 2017 - A LiDAR-based analysis of the effects of slope, ve.pdf:application/pdf},
}

@article{shepard_roughness_2001,
	title = {The roughness of natural terrain: {A} planetary and remote sensing perspective},
	volume = {106},
	issn = {2156-2202},
	shorttitle = {The roughness of natural terrain},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2000JE001429},
	doi = {10.1029/2000JE001429},
	abstract = {We examine the various methods and parameters in common use for quantifying and reporting surface topographic “roughness.” It is shown that scale-dependent roughness parameters are almost always required, though not widely used. We suggest a method of standardizing the parameters that are computed and reported so that topographic data gathered by different workers using different field techniques can be directly and easily intercompared. We illustrate the proposed method by analyzing topographic data from 60 different surfaces gathered by five different groups and examine the information for common features. We briefly discuss the implications of our analysis for studies of planetary surface roughness, lander safety, and radar remote sensing modeling and analysis.},
	language = {en},
	number = {E12},
	urldate = {2021-10-19},
	journal = {Journal of Geophysical Research: Planets},
	author = {Shepard, Michael K. and Campbell, Bruce A. and Bulmer, Mark H. and Farr, Tom G. and Gaddis, Lisa R. and Plaut, Jeffrey J.},
	year = {2001},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2000JE001429},
	pages = {32777--32795},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/TUDLXWDP/2000JE001429.html:text/html;Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/8PDI44R7/Shepard et al. - 2001 - The roughness of natural terrain A planetary and .pdf:application/pdf},
}

@article{tegowski_statistical_2016,
	title = {Statistical and {Spectral} {Features} of {Corrugated} {Seafloor} {Shaped} by the {Hans} {Glacier} in {Svalbard}},
	volume = {8},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2072-4292/8/9/744},
	doi = {10.3390/rs8090744},
	abstract = {High-resolution images of the seabed obtained with the use of hydroacoustic measurements allow a detailed identification of inaccessible seabed areas such as the Hans Glacier foreland in the Hornsund Fjord on Spitsbergen. Analyses presented in the paper were carried out on a Digital Elevation Model (DEM) of the bay’s seafloor exposed in the process of deglaciation, obtained from bathymetric data recorded by a multibeam echosounder. The main objective of this study was to show the relevance of the autocorrelation length parameter used to describe the roughness of the bottom surface based on the example of seafloor postglacial forms in the Hans Glacier foreland. The resulting parameter reflects the scale of the terrain roughness, which varies between geomorphologic forms. Maps of the autocorrelation length were derived from successive tiles of the data, overlapping by 90\%. Based on this, the two-dimensional Fourier transform (2D FFT) was successively conducted, and the power spectral density and autocorrelation were calculated following the Wiener–Khinchin theorem. The thus obtained parameter describes the scale of the glacial bay seafloor roughness, which was assigned to the geomorphological features observed.},
	language = {en},
	number = {9},
	urldate = {2021-10-19},
	journal = {Remote Sensing},
	author = {Tegowski, Jaroslaw and Trzcinska, Karolina and Kasprzak, Marek and Nowak, Jaroslaw},
	month = sep,
	year = {2016},
	note = {Number: 9
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {DEM, glacial morphology, multibeam echosounder, rough surface, seafloor, spectral and statistical properties, terrain analysis},
	pages = {744},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/8SX5QR4G/Tegowski et al. - 2016 - Statistical and Spectral Features of Corrugated Se.pdf:application/pdf;Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/ZGFL393D/744.html:text/html},
}

@article{hegge_spectral_1996,
	title = {Spectral {Analysis} of {Geomorphic} {Time} {Series}: {Auto}-{Spectrum}},
	volume = {21},
	issn = {1096-9837},
	shorttitle = {Spectral {Analysis} of {Geomorphic} {Time} {Series}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291096-9837%28199611%2921%3A11%3C1021%3A%3AAID-ESP703%3E3.0.CO%3B2-D},
	doi = {10.1002/(SICI)1096-9837(199611)21:11<1021::AID-ESP703>3.0.CO;2-D},
	abstract = {The collection of time series data is an essential component in the investigation of earth surface processes. Spectral analysis of these time series can provide an invaluable insight into the behaviour of geophysical processes. Spectral analysis of a single time series produces an auto-spectrum which provides a representation of the amount variance of the time series as a function of frequency. Prior to spectral analysis, the time series should be plotted to identify the presence of any trends in the mean or the variance of the series, and to identify anomalies in the data which should be corrected. To satisfy the assumption of stationarity, any trend (in either the mean or variance) should be removed from the time series. Consequently, the probability density function of the time series should be plotted and compared with the Gaussian distribution. The final stage in preparing the time series for spectral analysis is to apply a taper to reduce spectral leakage and distortion of the auto-spectrum. Following the calculation of the periodogram, spectral estimates should be combined to reduce the variability associated with the estimates and thereby ensure that the autospectrum is more representative. Finally, confidence limits should be constructed around the spectral density function so that statistically significant spectral peaks (or troughs) can be identified.},
	language = {en},
	number = {11},
	urldate = {2021-10-19},
	journal = {Earth Surface Processes and Landforms},
	author = {Hegge, Bruce J. and Masselink, Gerhard},
	year = {1996},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/\%28SICI\%291096-9837\%28199611\%2921\%3A11\%3C1021\%3A\%3AAID-ESP703\%3E3.0.CO\%3B2-D},
	keywords = {auto-spectrum, spectral analysis, time series},
	pages = {1021--1040},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/9FPWWJY8/(SICI)1096-9837(199611)21111021AID-ESP7033.0.html:text/html;Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/HLE5I8BC/Hegge and Masselink - 1996 - Spectral Analysis of Geomorphic Time Series Auto-.pdf:application/pdf},
}

@article{united_states_department_of_transportation_bureau_of_transportation_statistics_national_2019,
	title = {National {Transportation} {Statistics} (series)},
	url = {https://rosap.ntl.bts.gov/gsearch?collection=dot:35533&type1=mods.title&fedora_terms1=National+Transportation+Statistics},
	doi = {10.21949/1503663},
	language = {en},
	urldate = {2021-11-12},
	author = {United States. Department Of Transportation. Bureau Of Transportation Statistics},
	year = {2019},
	note = {Publisher: Not Available},
}

@misc{noauthor_autonomous_nodate,
	title = {Autonomous {Vehicle} {Market} {Size} \& {Share} {Report}, 2021-2030},
	url = {https://www.grandviewresearch.com/industry-analysis/autonomous-vehicles-market},
	abstract = {The global autonomous vehicle market demand is estimated to be at approximately 6.7 thousand units in 2020 and is anticipated to expand at a CAGR of 63.1\% from 2021 to 2030. Self-driving cars, also known as autonomous vehicles (AV), are a key innovation in the automotive industry},
	language = {en},
	urldate = {2021-11-12},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/CG8AF7FF/autonomous-vehicles-market.html:text/html},
}

@article{yang_semi-automated_2013,
	title = {Semi-automated extraction and delineation of {3D} roads of street scene from mobile laser scanning point clouds},
	volume = {79},
	issn = {0924-2716},
	url = {https://www.sciencedirect.com/science/article/pii/S0924271613000464},
	doi = {10.1016/j.isprsjprs.2013.01.016},
	abstract = {Accurate 3D road information is important for applications such as road maintenance and virtual 3D modeling. Mobile laser scanning (MLS) is an efficient technique for capturing dense point clouds that can be used to construct detailed road models for large areas. This paper presents a method for extracting and delineating roads from large-scale MLS point clouds. The proposed method partitions MLS point clouds into a set of consecutive “scanning lines”, which each consists of a road cross section. A moving window operator is used to filter out non-ground points line by line, and curb points are detected based on curb patterns. The detected curb points are tracked and refined so that they are both globally consistent and locally similar. To evaluate the validity of the proposed method, experiments were conducted using two types of street-scene point clouds captured by Optech’s Lynx Mobile Mapper System. The completeness, correctness, and quality of the extracted roads are over 94.42\%, 91.13\%, and 91.3\%, respectively, which proves the proposed method is a promising solution for extracting 3D roads from MLS point clouds.},
	language = {en},
	urldate = {2021-11-15},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
	author = {Yang, Bisheng and Fang, Lina and Li, Jonathan},
	month = may,
	year = {2013},
	keywords = {3D road extraction, Curb detection, Mobile laser scanning, Moving windows filtering, Scanning lines},
	pages = {80--93},
	file = {ScienceDirect Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/9YZXK7N4/Yang et al. - 2013 - Semi-automated extraction and delineation of 3D ro.pdf:application/pdf},
}

@misc{noauthor_table_nodate,
	title = {Table {HM}-51 - {Highway} {Statistics} 2019 - {Policy} {\textbar} {Federal} {Highway} {Administration}},
	url = {https://www.fhwa.dot.gov/policyinformation/statistics/2019/hm51.cfm},
	urldate = {2021-11-15},
	file = {Table HM-51 - Highway Statistics 2019 - Policy | Federal Highway Administration:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/QF9XCIJD/hm51.html:text/html},
}

@misc{noauthor_puck_nodate,
	title = {Puck Lidar Sensor, High-Value Surround Lidar},
	url = {https://velodynelidar.com/products/puck/},
	abstract = {Velodyne's Puck lidar sensor (previously VLP-16) is the highest value sensor on the market, providing reliability, power efficiency and a surround view.},
	language = {en},
	urldate = {2021-11-16},
	journal = {Velodyne Lidar},
	author = {Velodyne},
	month = nov,
	year = {2021},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/BBFU5WSK/puck.html:text/html},
}

@article{crisman_scarf_1993,
	title = {{SCARF}: a color vision system that tracks roads and intersections},
	volume = {9},
	issn = {2374-958X},
	shorttitle = {SCARF},
	doi = {10.1109/70.210794},
	abstract = {SCARF, a color vision system that recognizes difficult roads and intersections, is presented. It has been integrated into several navigation systems that drive a robot vehicle, the Navlab, on a variety of roads in many different weather conditions. SCARF recognizes roads that have degraded surfaces and edges with no lane markings in difficult shadow conditions. It also recognizes intersections with or without predictions from the navigation system. This is the first system that detects intersections in images without a priori knowledge of the intersection shape and location. SCARF uses Bayesian classification to determine a road-surface likelihood for each pixel in a reduced color image. It then evaluates a number of road and intersection candidates by matching an ideal road-surface likelihood image with the results from the Bayesian classification. The best matching candidate is passed to a path-planning system that navigates the robot vehicle on the road or intersection. The SCARF system is described in detail, results on a variety of images are presented, and Navlab test runs using SCARF are discussed.{\textless}{\textgreater}},
	number = {1},
	journal = {IEEE Transactions on Robotics and Automation},
	author = {Crisman, J.D. and Thorpe, C.E.},
	month = feb,
	year = {1993},
	note = {Conference Name: IEEE Transactions on Robotics and Automation},
	keywords = {Image edge detection, Road vehicles, Shape, Bayesian methods, Degradation, Machine vision, Navigation, Robots, Vehicle driving, Weather forecasting},
	pages = {49--58},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/PGLMA9P8/210794.html:text/html},
}

@inproceedings{kenue_lanelok_1990,
	title = {Lanelok: {Detection} {Of} {Lane} {Boundaries} {And} {Vehicle} {Tracking} {Using} {Image}-{Processing} {Techniques} - {Part} {I}: {Hough}-{Transform}, {Region}-{Tracing} {And} {Correlation} {Algorithms}},
	shorttitle = {Lanelok},
	doi = {10.1117/12.969885},
	abstract = {The purpose of this study was to develop image-processing techniques for detecting lane boundaries and vehicle tracking using an on-board video camera that resulted in several algorithms which process the image of the road scene to extract the position of lane markers and estimate the location of the lane boundaries. The purpose of this study was to develop image-processing techniques for detecting lane boundaries and vehicle tracking using an on-board video camera. It resulted in several algorithms which process the image of the road scene to extract the position of lane markers and estimate the position of the lane boundaries and the position of the vehicle within the lane. The following algorithms were developed to process the camera's output: a Hough-transform algorithm, a region-tracing algorithm, and a vehicle-tracking algorithm. These algorithms were successfully tested on 3000 real road images, including some with missing and discontinuous markers. This capability to estimate lane boundaries will play a key role in the development of advanced automotive functions such as collision warning, collision avoidance and automatic vehicle-guidance.},
	booktitle = {Other {Conferences}},
	author = {Kenue, S.},
	year = {1990},
}

@inproceedings{kenue_lanelok_1990-1,
	title = {Lanelok: {Detection} {Of} {Lane} {Boundaries} {And} {Vehicle} {Tracking} {Using} {Image}-{Processing} {Techniques} -{Part} {II}: {Template} {Matching} {Algorithms}},
	volume = {1195},
	shorttitle = {Lanelok},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/1195/0000/Lanelok--Detection-Of-Lane-Boundaries-And-Vehicle-Tracking-Using/10.1117/12.969886.full},
	doi = {10.1117/12.969886},
	abstract = {Sensing lane boundaries is a core capability for advanced automotive functions such as collision warning, collision avoidance and automatic vehicle-guidance. Part I of this study described special image-processing algorithms for the detection of lane boundaries and vehicle tracking, using images from a video camera. Part II of this study describes a new algorithm for detecting lane boundaries using template matching. This technique was selected because of its speed and its ability to include additional knowledge--two characteristics which are required for real-time, on-board vehicle applications. The algorithm has been tested successfully on over 3000 frames of videotape from interstate highways I-75 and I-94.},
	urldate = {2021-11-22},
	booktitle = {Mobile {Robots} {IV}},
	publisher = {SPIE},
	author = {Kenue, Surender K.},
	month = mar,
	year = {1990},
	pages = {234--245},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/7Z9N5Q5N/12.969886.html:text/html},
}

@article{pu_recognizing_2011,
	series = {Advances in {LIDAR} {Data} {Processing} and {Applications}},
	title = {Recognizing basic structures from mobile laser scanning data for road inventory studies},
	volume = {66},
	issn = {0924-2716},
	url = {https://www.sciencedirect.com/science/article/pii/S0924271611000955},
	doi = {10.1016/j.isprsjprs.2011.08.006},
	abstract = {Road safety inspection is currently carried out by time-consuming visual inspection. The latest mobile mapping systems provide an efficient technique for acquiring very dense point clouds along road corridors, so that automated procedures for recognizing and extracting structures can be developed. This paper presents a framework for structure recognition from mobile laser scanned point clouds. It starts with an initial rough classification into three larger categories: ground surface, objects on ground, and objects off ground. Based on a collection of characteristics of point cloud segments like size, shape, orientation and topological relationships, the objects on ground are assigned to more detailed classes such as traffic signs, trees, building walls and barriers. Two mobile laser scanning data sets acquired by different systems are tested with the recognition methods. Performance analyses of the test results are provided to demonstrate the applicability and limits of the methods. While poles are recognized for up to 86\%, classification into further categories requires further work and integration with imagery.},
	language = {en},
	number = {6, Supplement},
	urldate = {2021-11-22},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
	author = {Pu, Shi and Rutzinger, Martin and Vosselman, George and Oude Elberink, Sander},
	month = dec,
	year = {2011},
	keywords = {Segmentation, Mobile laser scanning, Feature recognition, Point cloud processing, Road inventory},
	pages = {S28--S39},
	file = {ScienceDirect Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/QV7FBHE7/Pu et al. - 2011 - Recognizing basic structures from mobile laser sca.pdf:application/pdf},
}

@article{noauthor_surface_totals_2006-2021xlsx_nodate,
	title = {Surface\_Totals\_2006-2021.xlsx},
	language = {en},
	pages = {1},
	file = {Surface_Totals_2006-2021.xlsx.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/JIFRNTFS/Surface_Totals_2006-2021.xlsx.pdf:application/pdf},
}

@misc{road_stats_2,
	title = {Office of {Highway} {Policy} {Information} - {Policy} {\textbar} {Federal} {Highway} {Administration}},
	url = {https://www.fhwa.dot.gov/policyinformation/statistics/2007/hm12.cfm},
	urldate = {2021-11-23},
	file = {Office of Highway Policy Information - Policy | Federal Highway Administration:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/G6B5RZIX/hm12.html:text/html},

	year={2008}, 

	month={Oct}
}

@misc{noauthor_chapter_nodate,
	title = {{CHAPTER} 3 {ROAD} {DESIGN}},
	url = {https://www.fao.org/3/t0099e/T0099e03.htm},
	urldate = {2021-11-29},
	file = {CHAPTER 3 ROAD DESIGN:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/A8YIWD9U/T0099e03.html:text/html},
}

@article{skorseth_gravel_nodate,
	title = {Gravel {Roads}: {Maintenance} and {Design} {Manual}},
	language = {en},
	author = {Skorseth, Ken and Selim, Ali A},
	file = {Skorseth and Selim - Gravel Roads Maintenance and Design Manual.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/VMKDDQQJ/Skorseth and Selim - Gravel Roads Maintenance and Design Manual.pdf:application/pdf},

	year={2020}, 

	month={Nov}
}

@article{noauthor_cost_nodate,
	title = {Cost {Estimating} {Guide} for {Road} {Construction}},
	language = {en},
	pages = {123},
	file = {Cost Estimating Guide for Road Construction.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/QHTBLLLK/Cost Estimating Guide for Road Construction.pdf:application/pdf},
}

@article{sotelo_color_2004,
	title = {A {Color} {Vision}-{Based} {Lane} {Tracking} {System} for {Autonomous} {Driving} on {Unmarked} {Roads}},
	volume = {16},
	issn = {1573-7527},
	url = {https://doi.org/10.1023/B:AURO.0000008673.96984.28},
	doi = {10.1023/B:AURO.0000008673.96984.28},
	abstract = {This work describes a color Vision-based System intended to perform stable autonomous driving on unmarked roads. Accordingly, this implies the development of an accurate road surface detection system that ensures vehicle stability. Although this topic has already been documented in the technical literature by different research groups, the vast majority of the already existing Intelligent Transportation Systems are devoted to assisted driving of vehicles on marked extra urban roads and highways. The complete system was tested on the BABIECA prototype vehicle, which was autonomously driven for hundred of kilometers accomplishing different navigation missions on a private circuit that emulates an urban quarter. During the tests, the navigation system demonstrated its robustness with regard to shadows, road texture, and weather and changing illumination conditions.},
	language = {en},
	number = {1},
	urldate = {2021-12-09},
	journal = {Autonomous Robots},
	author = {Sotelo, Miguel Angel and Rodriguez, Francisco Javier and Magdalena, Luis and Bergasa, Luis Miguel and Boquete, Luciano},
	month = jan,
	year = {2004},
	pages = {95--116},
	file = {Springer Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/QFKYVKYS/Sotelo et al. - 2004 - A Color Vision-Based Lane Tracking System for Auto.pdf:application/pdf},
}

@inproceedings{lutzeler_ems-vision_2000,
	address = {Dearborn, MI, USA},
	title = {{EMS}-vision: recognition of intersections on unmarked road networks},
	isbn = {978-0-7803-6363-2},
	shorttitle = {{EMS}-vision},
	url = {http://ieeexplore.ieee.org/document/898359/},
	doi = {10.1109/IVS.2000.898359},
	abstract = {The ability to recognize intersections enables an autonomous vehicle to navigate on road networks for performing complex missions. The paper gives the geometry model for intersections applied and their interaction with active viewing direction control. Quality measures indicate to performance monitoring processes the reliability of the estimation results. The perception module is integrated in the EMS-Vision system. Results from autonomous turnoff maneuvers, conducted on unmarked campus roads are discussed.},
	language = {en},
	urldate = {2021-12-09},
	booktitle = {Proceedings of the {IEEE} {Intelligent} {Vehicles} {Symposium} 2000 ({Cat}. {No}.{00TH8511})},
	publisher = {IEEE},
	author = {Lutzeler, M. and Dickmanns, E.D.},
	year = {2000},
	pages = {302--307},
	file = {Lutzeler and Dickmanns - 2000 - EMS-vision recognition of intersections on unmark.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/8VQQH4RV/Lutzeler and Dickmanns - 2000 - EMS-vision recognition of intersections on unmark.pdf:application/pdf},
}

@inproceedings{lutzeler_ems-vision_2000-1,
	title = {{EMS}-vision: recognition of intersections on unmarked road networks},
	shorttitle = {{EMS}-vision},
	doi = {10.1109/IVS.2000.898359},
	abstract = {The ability to recognize intersections enables an autonomous vehicle to navigate on road networks for performing complex missions. The paper gives the geometry model for intersections applied and their interaction with active viewing direction control. Quality measures indicate to performance monitoring processes the reliability of the estimation results. The perception module is integrated in the EMS-Vision system. Results from autonomous turn-off maneuvers, conducted on unmarked campus roads are discussed.},
	booktitle = {Proceedings of the {IEEE} {Intelligent} {Vehicles} {Symposium} 2000 ({Cat}. {No}.{00TH8511})},
	author = {Lutzeler, M. and Dickmanns, E.D.},
	month = oct,
	year = {2000},
	keywords = {Cameras, Road vehicles, Vehicle detection, Machine vision, Navigation, Geometry, Layout, Monitoring, Solid modeling, Vehicle dynamics},
	pages = {302--307},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/LJ5C3MQX/898359.html:text/html},
}

@inproceedings{jochem_vision-based_1995,
	title = {Vision-based neural network road and intersection detection and traversal},
	volume = {3},
	doi = {10.1109/IROS.1995.525907},
	abstract = {The use of artificial neural networks in the domain of autonomous driving has produced promising results. ALVINN has shown that a neural system can drive a vehicle reliably and safely on many different types of roads, ranging from paved paths to interstate highways. The next step in the evolution of autonomous driving systems is to intelligently handle road junctions. In this paper the authors present an addition to the basic ALVINN driving system which makes autonomous detection of roads and traversal of simple intersections possible. The addition is based on geometrically modelling the world, accurately imaging interesting parts of the scene using this model, and monitoring ALVINN's response to the created image.},
	booktitle = {Proceedings 1995 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}. {Human} {Robot} {Interaction} and {Cooperative} {Robots}},
	author = {Jochem, T.M. and Pomerleau, D.A. and Thorpe, C.E.},
	month = aug,
	year = {1995},
	keywords = {Remotely operated vehicles, Road vehicles, Vehicle driving, Layout, Solid modeling, Artificial neural networks, Intelligent systems, Neural networks, Road transportation, Vehicle safety},
	pages = {344--349 vol.3},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/UHV84YHU/525907.html:text/html},
}

@article{espineira_realistic_2021,
	title = {Realistic {LiDAR} {With} {Noise} {Model} for {Real}-{Time} {Testing} of {Automated} {Vehicles} in a {Virtual} {Environment}},
	volume = {21},
	issn = {1558-1748},
	doi = {10.1109/JSEN.2021.3059310},
	abstract = {The global Connected and Autonomous Mobility industry is growing at a rapid pace. To ensure the successful adoption of connected automated mobility solutions, their safety, reliability and hence the public acceptance are paramount. It is widely known that in order to demonstrate that L3+ automated systems are safer with respect to human drivers, upwards of several millions of miles need to be driven. The only way to efficiently achieve this amount of tests in a timely manner is by using simulations and high fidelity virtual environments. Two key components of being able to test an automated system in a synthetic environment are validated sensor models and noise models for each sensor technology. In fact, the sensors are the element feeding information into the system in order to enable it to safely plan the trajectory and navigate. In this paper, we propose an innovative real-time LiDAR sensor model based on beam propagation and a probabilistic rain model, taking into account raindrop distribution and size. The model can seamlessly run in real-time, synchronised with the visual rendering, in immersive driving simulators, such as the WMG 3xD simulator. The models are developed using Unreal engine, therefore demonstrating that gaming technology can be merged with the Automated Vehicles (AVs) simulation toolchain for the creation and visualization of high fidelity scenarios and for AV accurate testing. This work can be extended to add more sensors and more noise factors or cyberattacks in real-time simulations.},
	number = {8},
	journal = {IEEE Sensors Journal},
	author = {Espineira, Juan P. and Robinson, Jonathan and Groenewald, Jakobus and Chan, Pak Hung and Donzella, Valentina},
	month = apr,
	year = {2021},
	note = {Conference Name: IEEE Sensors Journal},
	keywords = {Autonomous and automated vehicles, Laser beams, Laser radar, light detection and ranging (LiDAR), Mathematical model, noise, perception sensor, rain, Rain, real-time simulation, Real-time systems, sensor models, Sensors, Testing},
	pages = {9919--9926},
	file = {Accepted Version:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/PW6NXRPF/Espineira et al. - 2021 - Realistic LiDAR With Noise Model for Real-Time Tes.pdf:application/pdf;IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/VZVHKZFX/9354172.html:text/html},
}

@misc{noauthor_autowareai_nodate,
	title = {Autoware.{AI}},
	url = {https://www.autoware.org/autoware-ai},
	language = {en},
	urldate = {2021-12-15},
	journal = {Autoware},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/5XFJPDN9/autoware-ai.html:text/html},
}

@inproceedings{fernandes_road_2014,
	address = {Coimbra, Portugal},
	title = {Road {Detection} {Using} {High} {Resolution} {LIDAR}},
	isbn = {978-1-4799-6783-4},
	url = {http://ieeexplore.ieee.org/document/7007125/},
	doi = {10.1109/VPPC.2014.7007125},
	abstract = {This paper proposes a road detection approach based solely on dense 3D-LIDAR data. The approach is built up of four stages: (1) 3D-LIDAR points are projected to a 2D reference plane; then, (2) dense height maps are computed using an upsampling method; (3) applying a sliding-window technique in the upsampled maps, probability distributions of neighboring regions are compared according to a similarity measure; ﬁnally, (4) morphological operations are used to enhance performance against disturbances. Our detection approach does not depend on road marks, thus it is suitable for applications on rural areas and inner-city with unmarked roads. Experiments have been carried out in a wide variety of scenarios using the recent KITTI-ROAD benchmark [1], obtaining promising results when compared to other state-of-art approaches.},
	language = {en},
	urldate = {2021-12-15},
	booktitle = {2014 {IEEE} {Vehicle} {Power} and {Propulsion} {Conference} ({VPPC})},
	publisher = {IEEE},
	author = {Fernandes, R. and Premebida, C. and Peixoto, P. and Wolf, D. and Nunes, U.},
	month = oct,
	year = {2014},
	pages = {1--6},
	file = {Fernandes et al. - 2014 - Road Detection Using High Resolution LIDAR.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/2937QZSG/Fernandes et al. - 2014 - Road Detection Using High Resolution LIDAR.pdf:application/pdf},
}

@article{marinello_determination_2017,
	title = {Determination of forest road surface roughness by {Kinect} depth imaging},
	volume = {60},
	copyright = {All the papers published in Annals of Forest Research are available under an open access policy (Gratis Gold  Open Access Licence ), which guaranty the free (of taxes) and unlimited access, for anyone, to entire content of the all published articles. The users are free to “read, copy, distribute, print, search or refers to the full text of these articles”, as long they mention the source.  The other materials (texts, images, graphical elements presented on the Website) are protected by copyright.  The journal exerts a permanent quality check, based on an established protocol for publishing the manuscripts. The potential article to be published are evaluated (peer-review) by members of the Editorial Board or other collaborators with competences on the paper topics. The publishing of manuscript is free of charge, all the costs being supported by Forest Research and Management Institute.  More details about Open Access:  Wikipedia:  http://en.wikipedia.org/wiki/Open\_access   DOAJ:  http://www.doaj.org/oainfo},
	issn = {20652445},
	url = {http://afrjournal.org/index.php/afr/article/view/893},
	doi = {10.15287/afr.2017.893},
	abstract = {Roughness is a dynamic property of the gravel road surface that affects safety, ride comfort as well as vehicle tyre life and maintenance costs. A rapid survey of gravel road condition is fundamental for an effective maintenance planning and definition of the intervention priorities. Different non-contact techniques such as laser scanning, ultrasonic sensors and photogrammetry have recently been proposed to reconstruct three-dimensional topography of road surface and allow extraction of roughness metrics. The application of Microsoft Kinect™ depth camera is proposed and discussed here for collection of 3D data sets from gravel roads, to be implemented in order to allow quantification of surface roughness. The objectives are to: i) verify the applicability of the Kinect sensor for characterization of different forest roads, ii) identify the appropriateness and potential of different roughness parameters and iii) analyse the correlation with vibrations recoded by 3-axis accelerometers installed on different vehicles. The test took advantage of the implementation of the Kinect depth camera for surface roughness determination of 4 different forest gravel roads and one well-maintained asphalt road as reference. Different vehicles (mountain bike, off-road motorcycle, ATV vehicle, 4WD car and compact crossover) were included in the experiment in order to verify the vibration intensity when travelling on different road surface conditions. Correlations between the extracted roughness parameters and vibration levels of the tested vehicles were then verified. Coefficients of determination of between 0.76 and 0.97 were detected between average surface roughness and standard deviation of relative accelerations, with higher values in the case of lighter vehicles.},
	language = {en},
	number = {2},
	urldate = {2021-12-16},
	journal = {Annals of Forest Research},
	author = {Marinello, Francesco and Proto, Andrea Rosario and Zimbalatti, Giuseppe and Pezzuolo, Andrea and Cavalli, Raffaele and Grigolato, Stefano},
	month = nov,
	year = {2017},
	note = {Number: 2},
	pages = {217--226},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/7Y2C2X87/Marinello et al. - 2017 - Determination of forest road surface roughness by .pdf:application/pdf;Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/TJTBQCAG/893.html:text/html},
}

@article{asvadi_3d_2016,
	title = {{3D} {Lidar}-based static and moving obstacle detection in driving environments: {An} approach based on voxels and multi-region ground planes},
	volume = {83},
	issn = {0921-8890},
	shorttitle = {{3D} {Lidar}-based static and moving obstacle detection in driving environments},
	url = {https://www.sciencedirect.com/science/article/pii/S0921889016300483},
	doi = {10.1016/j.robot.2016.06.007},
	abstract = {Artificial perception, in the context of autonomous driving, is the process by which an intelligent system translates sensory data into an effective model of the environment surrounding a vehicle. In this paper, and considering data from a 3D-LIDAR mounted onboard an intelligent vehicle, a 3D perception system based on voxels and planes is proposed for ground modeling and obstacle detection in urban environments. The system, which incorporates time-dependent data, is composed of two main modules: (i) an effective ground surface estimation using a piecewise plane fitting algorithm and RANSAC-method, and (ii) a voxel-grid model for static and moving obstacles detection using discriminative analysis and ego-motion information. This perception system has direct application in safety systems for intelligent vehicles, particularly in collision avoidance and vulnerable road users detection, namely pedestrians and cyclists. Experiments, using point-cloud data from a Velodyne LIDAR and localization data from an Inertial Navigation System were conducted for both a quantitative and a qualitative assessment of the static/moving obstacle detection module and for the surface estimation approach. Reported results, from experiments using the KITTI database, demonstrate the applicability and efficiency of the proposed approach in urban scenarios.},
	language = {en},
	urldate = {2021-12-16},
	journal = {Robotics and Autonomous Systems},
	author = {Asvadi, Alireza and Premebida, Cristiano and Peixoto, Paulo and Nunes, Urbano},
	month = sep,
	year = {2016},
	keywords = {3D representation, LIDAR perception, Obstacle detection, Scene understanding},
	pages = {299--311},
	file = {ScienceDirect Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/FD37XVS8/S0921889016300483.html:text/html},
}

@inproceedings{zhang_lidar-based_2010-1,
	title = {{LIDAR}-based road and road-edge detection},
	doi = {10.1109/IVS.2010.5548134},
	abstract = {In this paper, a LIDAR-based road and road-edge detection method is proposed to identify road regions and road-edges, which is an essential component of autonomous vehicles. LIDAR range data is decomposed into signals in elevation and signals projected on the ground plane. First, the elevation-based signals are processed by filtering techniques to identify the road candidate region, and by pattern recognition techniques to determine whether the candidate region is a road segment. Then, the line representation of the projected signals on the ground plane is identified and compared to a simple road model in the top-down view to determine whether the candidate region is a road segment with its road-edges. The proposed method provides fast processing speed and reliable detection performance of road and road-edge detection. The proposed framework has been verified through the DARPA Urban Challenge to show its robustness and efficiency on the winning entry Boss vehicle.},
	booktitle = {2010 {IEEE} {Intelligent} {Vehicles} {Symposium}},
	author = {Zhang, Wende},
	month = jun,
	year = {2010},
	note = {ISSN: 1931-0587},
	keywords = {Algorithm design and analysis, Data mining, Laser radar, Mobile robots, Remotely operated vehicles, Road vehicles, Robustness, Sensor arrays, Signal processing, Vehicle detection},
	pages = {845--848},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/G3XG39BK/5548134.html:text/html},
}

@inproceedings{zhao_road_2012,
	title = {Road network extraction from airborne {LiDAR} data using scene context},
	doi = {10.1109/CVPRW.2012.6238909},
	abstract = {We presented a novel procedure to extract ground road networks from airborne LiDAR data. First point clouds were separated into ground and non-ground parts, and ground roads were to be extracted from ground planes. Then, buildings and trees were distinguished in an energy minimization framework after incorporation of two new features. The separation provided supportive information for later road extractions. After that, we designed structure templates to search for roads on ground intensity images, and road widths and orientations were determined by a subsequent voting scheme. This local searching process produced road candidates only, in order to prune false positives and infer undetected roads, a scene-dependent Markov network was constructed to help infer a global road network. Combination of local template fitting and global MRF inference made extracted ground roads more accurate and complete. Finally, we extended developed methods to elevated roads extraction from non-ground points and combined them with the ground road network to formulate a whole network.},
	booktitle = {2012 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops}},
	author = {Zhao, Jiaping and You, Suya},
	month = jun,
	year = {2012},
	note = {ISSN: 2160-7516},
	keywords = {Buildings, Data mining, Feature extraction, Fitting, Laser radar, Roads, Vegetation},
	pages = {9--16},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/E87DMTAN/6238909.html:text/html},
}

@article{smadja_road_nodate,
	title = {{ROAD} {EXTRACTION} {AND} {ENVIRONMENT} {INTERPRETATION} {FROM} {LIDAR} {SENSORS}},
	abstract = {We present in this article a new vehicle dedicated to road surveying, equipped with a highly precise positioning system, 2D lidar scans and high deﬁnition color images. We focus at ﬁrst on the sensors extrinsic calibration process. Once all sensors have been positioned in the same coordinates system, 3D realistic environments can be computed and interpreted. Moreover, an original algorithm for road extraction has been developed. This two-step method is based on the local road shape and does not rely on the presence of curbs or guardrails. Different uses of the RanSaC algorithm are employed, for road sides rough estimation in the ﬁrst place, then for unlikely candidates elimination. Road boundary and center points are further processed for road width and curvature computation in order to feed a geographic information system. Finally, a simple extraction of trafﬁc signs and road markings is presented.},
	language = {en},
	author = {Smadja, Laurent and Ninot, Jerome and Gavrilovic, Thomas},
	pages = {7},
	file = {Smadja et al. - ROAD EXTRACTION AND ENVIRONMENT INTERPRETATION FRO.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/IMT2CFWY/Smadja et al. - ROAD EXTRACTION AND ENVIRONMENT INTERPRETATION FRO.pdf:application/pdf},
}

@article{chen_progressive_2019,
	title = {Progressive {LiDAR} adaptation for road detection},
	volume = {6},
	issn = {2329-9274},
	doi = {10.1109/JAS.2019.1911459},
	abstract = {Despite rapid developments in visual image-based road detection, robustly identifying road areas in visual images remains challenging due to issues like illumination changes and blurry images. To this end, LiDAR sensor data can be incorporated to improve the visual image-based road detection, because LiDAR data is less susceptible to visual noises. However, the main difficulty in introducing LiDAR information into visual image-based road detection is that LiDAR data and its extracted features do not share the same space with the visual data and visual features. Such gaps in spaces may limit the benefits of LiDAR information for road detection. To overcome this issue, we introduce a novel Progressive LiDAR adaptation-aided road detection (PLARD) approach to adapt LiDAR information into visual image-based road detection and improve detection performance. In PLARD, progressive LiDAR adaptation consists of two subsequent modules: 1) data space adaptation, which transforms the LiDAR data to the visual data space to align with the perspective view by applying altitude difference-based transformation; and 2) feature space adaptation, which adapts LiDAR features to visual features through a cascaded fusion structure. Comprehensive empirical studies on the well-known KITTI road detection benchmark demonstrate that PLARD takes advantage of both the visual and LiDAR information, achieving much more robust road detection even in challenging urban scenes. In particular, PLARD outperforms other state-of-the-art road detection models and is currently top of the publicly accessible benchmark leader-board.},
	number = {3},
	journal = {IEEE/CAA Journal of Automatica Sinica},
	author = {Chen, Zhe and Zhang, Jing and Tao, Dacheng},
	month = may,
	year = {2019},
	note = {Conference Name: IEEE/CAA Journal of Automatica Sinica},
	keywords = {Feature extraction, Laser radar, Roads, Three-dimensional displays, Transforms, Two dimensional displays, Visualization},
	pages = {693--702},
}

 @misc{malik_lal_2019,

	title={Basic Road Statistics of India [2016-2017]}, 

	url={https://morth.nic.in/sites/default/files/Basic%20_Road_Statics_of_India.pdf}, 

	journal={Basic Road Statistics of India [2016-17]}, 

	publisher={Ministry of Road Transport and Highways}, 

	author={Malik, Yudhvir Singh and Lal, Babni}, 

	year={2019}, 

	month={Mar}
} 


@misc{gps_map,
	title = {Coverage {Map} :: {DynaTrack} {GPS}},
	url = {http://www.dynatrackgps.com/coverage-map.html},
	urldate = {2021-12-16},
	file = {Coverage Map \:\: DynaTrack GPS:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/LIL5UPTF/coverage-map.html:text/html},
}

 @misc{4G_map, 

	title={Wireless 3G / 4G / 5G coverage map, United States}, 
	url={https://www.nperf.com/en/map/US/-/3255.Verizon-Wireless/signal/}, 
	journal={Verizon Wireless 3G / 4G / 5G coverage - nPerf.com}
} 

@inproceedings{Dosovitskiy17,
  title = { {CARLA}: {An} Open Urban Driving Simulator},
  author = {Alexey Dosovitskiy and German Ros and Felipe Codevilla and Antonio Lopez and Vladlen Koltun},
  booktitle = {Proceedings of the 1st Annual Conference on Robot Learning},
  pages = {1--16},
  year = {2017}
}


@article{sigrist_impact_1999,
	title = {Impact of forest canopy on quality and accuracy of {GPS} measurements},
	volume = {20},
	issn = {0143-1161},
	url = {https://doi.org/10.1080/014311699211228},
	doi = {10.1080/014311699211228},
	abstract = {Global Positioning System (GPS) technology has become an essential tool in the Earth observation field for georeferencing, classification and accuracy assessment activities. While it was developed to be employed primarily in the open, many users nowadays operate GPS receivers in less favourable conditions. We investigated the impact of varying types and degrees of forest cover overstorey on GPS data collection, accuracy and precision. While the occurrence of canopy overhead may degrade the positional precision by one order of magnitude, it is the presence of the foliage itself (leaf-on condition) that plays a major role in the signal reception and the positional accuracy. The relationship is inverse, with increasing relative canopy closure resulting in decreasing logging efficiency and accuracy. We also found that under larger forest canopy the Position Dilution of Precision (PDOP) values may improve signal reception without deteriorating accuracy. Moreover, the relationship between degree of canopy closure and the accuracy RMSE follows an exponential pattern with small increases in relative canopy closure leading to huge increases in positional error. Averaging proved to be a powerful way to diminish residual positional error under forest cover, 300 fixes being proposed as a good number for GPS data acquisition under mature canopy conditions. Ultimately, we judged that PDOP is not as good an indicator for positional accuracy under forest canopy as is universally acclaimed.},
	number = {18},
	urldate = {2021-12-17},
	journal = {International Journal of Remote Sensing},
	author = {Sigrist, P. and Coppin, P. and Hermy, M.},
	month = jan,
	year = {1999},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/014311699211228},
	pages = {3595--3610},
}

@article{rempel_performance_1995,
	title = {Performance of a {GPS} {Animal} {Location} {System} under {Boreal} {Forest} {Canopy}},
	volume = {59},
	issn = {0022-541X},
	url = {https://www.jstor.org/stable/3802461},
	doi = {10.2307/3802461},
	abstract = {An automated animal location system, based on Global Positioning System (GPS) technology, is being used for wildlife research. The GPS is a divergent technology, and positional accuracies vary between millimeters and tens of meters, depending on the system used and operating conditions. Before GPS-based tracking data can be used for habitat analyses, the influence of habitat on GPS-collar performance must be evaluated under various canopy conditions, including the optimal condition of no canopy. We evaluated performance of nondifferentially corrected GPS collars in an experimental forest with mature, evenly spaced trees and on wild free-ranging moose (Alces alces) to determine the influence of canopy on positional accuracy and observation rate. In an experimental forest with mature, evenly spaced trees (henceforth called spacing trial), canopy characteristics of tree species, spacing, height, basal diameter, and canopy closure had no influence on positional accuracy (P {\textgreater} 0.05), but had an influence on GPS observation rate (P {\textless} 0.001). Location error was greater if positions were based on 2-dimensional rather than 3-dimensional mode of operation (P {\textless} 0.001), with location errors of 65.5 and 45.5 m, respectively. Location error in 3-dimensional mode did not differ from the expected error of 40 m (P = 0.43). As tree density increased, observation rate decreased and the probability of the GPS receiver operating in 2-dimensional mode increased (P {\textless} 0.001), resulting in increased location error. With future development of differentially corrected GPS collars, location errors of {\textless}10 m are expected.},
	number = {3},
	urldate = {2021-12-17},
	journal = {The Journal of Wildlife Management},
	author = {Rempel, Robert S. and Rodgers, Arthur R. and Abraham, Kenneth F.},
	year = {1995},
	note = {Publisher: [Wiley, Wildlife Society]},
	pages = {543--551},
}

@article{pirti_accuracy_2008,
	title = {Accuracy {Analysis} of {GPS} {Positioning} {Near} the {Forest} {Environment}},
	volume = {29},
	issn = {1845-5719, 1848-9672},
	url = {https://hrcak.srce.hr/32194},
	abstract = {GPS has become an essential tool for georeferencing. In some cases, GPS is used for unfavorable conditions although it was developed for open field studies. This paper analyzes the achievable accuracy and performance of GPS near the forest. Three sur...},
	language = {en},
	number = {2},
	urldate = {2021-12-17},
	journal = {Croatian Journal of Forest Engineering : Journal for Theory and Application of Forestry Engineering},
	author = {Pirti, Atinç},
	month = dec,
	year = {2008},
	note = {Publisher: Fakultet šumarstva i drvne tehnologije Sveučilišta u Zagrebu},
	pages = {189--199},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/C94IN2Z9/Pirti - 2008 - Accuracy Analysis of GPS Positioning Near the Fore.pdf:application/pdf;Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/VVSVGCCM/32194.html:text/html},
}


@article{seker_experiments_nodate,
	title = {Experiments of the Propagation through Forest at GSM Frequencies (2G-3G-4G)},
	volume = {2},
	abstract = {The increasing demand of clear communication in any situation and in any environment leads people to find a better way to communicate. Since the presence of tree canopies can affect the ability of a GSM signals through its way, one of the hardest environment is forested areas. In order to find a better way to communicate, the propagation features of the environment should be known.This study investigates the attenuation characteristics of GSM (2G, 3G and 4G) frequencies in the forest. Some theoretical models from literature were studied and simulated. The electrical field of the transmitted signal was measured in Sakarya. Due to weather and seasonal conditions, experiment was re-modeled with the trees with small, thin trunk and high amount of leaves. Finally, the literature data and experimental data were compared and discussed.},
	language = {en},
	number = {8},
	author = {Seker, Saban Selim and Kunter, Fulya Callialp and Çerezci, Osman and Karabag, Kaan},
	pages = {6},
	file = {Seker et al. - Experiments of the Propagation through Forest at G.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/6UTPFRYD/Seker et al. - Experiments of the Propagation through Forest at G.pdf:application/pdf},
}

@misc{ntsb_2021,
title = {GLOBAL POSITIONING SYSTEM STANDARD POSITIONING SERVICE PERFORMANCE ANALYSIS REPORT}, 
url = {https://www.ntsb.gov/_layouts/ntsb.aviation/index.aspx}, 
author = {{Satellite Navigation Branch ANG-E66 NSTB/WAAS TE Team}}, 
journal = {NTSB Aviation Accident Database &amp; Synopses}, 
publisher = {FAA William J. Hughes Technical Center Atlantic City International Airport, NJ 08405}, 
pages = {38}, 
year = {2021}, 
month = nov
} 


@article{seker_experiments_nodate,
	title = {Experiments of the Propagation through Forest at GSM Frequencies (2G-3G-4G)},
	volume = {2},
	abstract = {The increasing demand of clear communication in any situation and in any environment leads people to find a better way to communicate. Since the presence of tree canopies can affect the ability of a GSM signals through its way, one of the hardest environment is forested areas. In order to find a better way to communicate, the propagation features of the environment should be known.This study investigates the attenuation characteristics of GSM (2G, 3G and 4G) frequencies in the forest. Some theoretical models from literature were studied and simulated. The electrical field of the transmitted signal was measured in Sakarya. Due to weather and seasonal conditions, experiment was re-modeled with the trees with small, thin trunk and high amount of leaves. Finally, the literature data and experimental data were compared and discussed.},
	language = {en},
	number = {8},
	author = {Seker, Saban Selim and Kunter, Fulya Callialp and Çerezci, Osman and Karabag, Kaan},
	pages = {6},
	file = {Seker et al. - Experiments of the Propagation through Forest at G.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/6UTPFRYD/Seker et al. - Experiments of the Propagation through Forest at G.pdf:application/pdf}
}

@misc{vlp_32c,
	title = {Ultra {Puck} {Surround} {View} {Lidar} {Sensor}},
	url = {https://velodynelidar.com/products/ultra-puck/},
	abstract = {Ultra Puck is a high-density, long-range lidar sensor that is an industry favorite for robotics, mapping, security, ADAS, AV and more.},
	language = {en},
	urldate = {2022-01-13},
	journal = {Velodyne Lidar},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/PJYU5U6R/ultra-puck.html:text/html},
}


@article{shapiro_analysis_1965,
	title = {An analysis of variance test for normality (complete samples)†},
	volume = {52},
	issn = {0006-3444},
	url = {https://doi.org/10.1093/biomet/52.3-4.591},
	doi = {10.1093/biomet/52.3-4.591},
	number = {3-4},
	urldate = {2022-01-12},
	journal = {Biometrika},
	author = {SHAPIRO, S. S. and WILK, M. B.},
	month = dec,
	year = {1965},
	pages = {591--611},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/PBP5YXLX/SHAPIRO and WILK - 1965 - An analysis of variance test for normality (comple.pdf:application/pdf;Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/4P6GEJUQ/336553.html:text/html},
}

@article{davis_covariance_1977,
	title = {The covariance matrix of normal order statistics},
	volume = {6},
	issn = {0361-0918},
	url = {https://doi.org/10.1080/03610917708812028},
	doi = {10.1080/03610917708812028},
	abstract = {An approximation is given to calculate V, the covariance matrix for normal order statistics. The approximation gives considerable improvement over previous approximations, and the computing algorithm is available from the authors.},
	number = {1},
	urldate = {2022-01-13},
	journal = {Communications in Statistics - Simulation and Computation},
	author = {Davis, C. S. and Stephens, M. A.},
	month = jan,
	year = {1977},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/03610917708812028},
	keywords = {covariance matrix calculations, generalized least squares, goodness-of-fit tests, normal distribution},
	pages = {75--81},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/6RDGVH69/03610917708812028.html:text/html},
}


@article{naaman_tight_2021,
	title = {On the tight constant in the multivariate {Dvoretzky}–{Kiefer}–{Wolfowitz} inequality},
	volume = {173},
	issn = {0167-7152},
	url = {https://www.sciencedirect.com/science/article/pii/S016771522100050X},
	doi = {10.1016/j.spl.2021.109088},
	abstract = {We derive the tight constant in the multivariate version of the Dvoretzky–Kiefer–Wolfowitz inequality. The inequality is leveraged to construct the first fully non-parametric test for multivariate probability distributions including a simple formula for the test statistic. We also generalize the test under appropriate α-mixing conditions and describe applications of the tests to machine learning and representative sampling.},
	language = {en},
	urldate = {2022-01-13},
	journal = {Statistics \& Probability Letters},
	author = {Naaman, Michael},
	month = jun,
	year = {2021},
	keywords = {Empirical process, Hypothesis test, Machine learning, Non-parametric},
	pages = {109088},
}


@article{bellekens_survey_2014,
	title = {A {Survey} of {Rigid} {3D} {Pointcloud} {Registration} {Algorithms}},
	url = {https://www.academia.edu/29792070/A_Survey_of_Rigid_3D_Pointcloud_Registration_Algorithms},
	abstract = {A Survey of Rigid 3D Pointcloud Registration Algorithms},
	language = {en},
	urldate = {2022-01-21},
	author = {Bellekens, Ben},
	month = aug,
	year = {2014},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/6SNJDKG6/A_Survey_of_Rigid_3D_Pointcloud_Registration_Algorithms.html:text/html},
}


@article{pomerleau_review_2015,
	title = {A {Review} of {Point} {Cloud} {Registration} {Algorithms} for {Mobile} {Robotics}},
	volume = {4},
	url = {https://hal.archives-ouvertes.fr/hal-01178661},
	doi = {10.1561/2300000035},
	abstract = {The topic of this review is geometric registration in robotics. Registration algorithms associate sets of data into a common coordinate system. They have been used extensively in object reconstruction, inspection, medical application, and localization of mobile robotics. We focus on mobile robotics applications in which point clouds are to be registered. While the underlying principle of those algorithms is simple, many variations have been proposed for many different applications. In this review, we give a historical perspective of the registration problem and show that the plethora of solutions can be organized and differentiated according to a few elements. Accordingly, we present a formalization of geometric registration and cast algorithms proposed in the literature into this framework. Finally, we review a few applications of this framework in mobile robotics that cover different kinds of platforms, environments, and tasks. These examples allow us to study the specific requirements of each use case and the necessary configuration choices leading to the registration implementation. Ultimately, the objective of this review is to provide guidelines for the choice of geometric registration configuration.},
	number = {1},
	urldate = {2022-01-21},
	journal = {Foundations and Trends in Robotics},
	author = {Pomerleau, François and Colas, Francis and Siegwart, Roland},
	year = {2015},
	note = {Publisher: Now Publishers},
	pages = {1--104},
	file = {HAL PDF Full Text:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/VGD83ZYG/Pomerleau et al. - 2015 - A Review of Point Cloud Registration Algorithms fo.pdf:application/pdf},
}


@inproceedings{razlaw_evaluation_2015,
	title = {Evaluation of registration methods for sparse {3D} laser scans},
	doi = {10.1109/ECMR.2015.7324196},
	abstract = {The registration of 3D laser scans is an important task in mapping applications. For the task of mapping with autonomous micro aerial vehicles (MAVs), we have developed a light-weight 3D laser scanner. Since the laser scanner is rotated quickly for fast omnidirectional obstacle perception, the acquired point clouds are particularly sparse and registration becomes challenging. In this paper, we present a thorough experimental evaluation of registration algorithms in order to determine the applicability of both the scanner and the registration algorithms. Using the estimated poses of the MAV, we aim at building local egocentric maps for both collision avoidance and 3D mapping. We use multiple metrics for assessing the quality of the different pose estimates and the quality of the resulting maps. In addition, we determine for all algorithms optimal sets of parameters for the challenging data. We make the recorded datasets publicly available and present results showing both the best suitable registration algorithm and the best parameter sets as well as the quality of the estimated poses and maps.},
	booktitle = {2015 {European} {Conference} on {Mobile} {Robots} ({ECMR})},
	author = {Razlaw, Jan and Droeschel, David and Holz, Dirk and Behnke, Sven},
	month = sep,
	year = {2015},
	keywords = {Accuracy, Buildings, Iterative closest point algorithm, Measurement, Optimization, Three-dimensional displays, Trajectory},
	pages = {1--7},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/62D5VIPQ/7324196.html:text/html},
}


@inproceedings{grant_finding_2013,
	title = {Finding planes in {LiDAR} point clouds for real-time registration},
	doi = {10.1109/IROS.2013.6696980},
	abstract = {We present a robust plane finding algorithm that when combined with plane-based frame-to-frame registration gives accurate real-time pose estimation. Our plane extraction is capable of handling large and sparse datasets such as those generated from spinning multi-laser sensors such as the Velodyne HDL-32E LiDAR. We test our algorithm on frame-to-frame registration in a closed-loop indoor path comprising 827 successive 3D laser scans (over 57 million points), using no additional information (e.g., odometry, IMU). Our algorithm outperforms, in both accuracy and time, three state-of-the-art methods, based on iterative closest point (ICP), plane-based randomized Hough transform, and planar region growing.},
	booktitle = {2013 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Grant, W. Shane and Voorhies, Randolph C. and Itti, Laurent},
	month = nov,
	year = {2013},
	note = {ISSN: 2153-0866},
	keywords = {Equations, Iterative closest point algorithm, Laser radar, Laser theory, Measurement by laser beam, Sensors, Vectors},
	pages = {4347--4354},
	file = {Full Text:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/6282F3JJ/Grant et al. - 2013 - Finding planes in LiDAR point clouds for real-time.pdf:application/pdf;IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/LKW65BBI/6696980.html:text/html},
}


@article{bachuwar_integration_2020,
	title = {Integration of {Autonomous} {Vehicle} {Frameworks} for {Software}-in-the-{Loop} {Testing}},
	volume = {2},
	issn = {2641-9637, 2641-9645},
	url = {https://www.sae.org/publications/technical-papers/content/2020-01-0709/},
	doi = {10.4271/2020-01-0709},
	abstract = {This paper presents an approach for performing software in the loop testing of autonomous vehicle software developed in the Autoware framework. Autoware is an open source software for autonomous driving that includes modules such as localization, detection, prediction, planning and control [8]. Mult},
	language = {English},
	number = {5},
	urldate = {2022-01-21},
	journal = {SAE International Journal of Advances and Current Practices in Mobility},
	author = {Bachuwar, Sanket and Bulsara, Ardashir and Dossaji, Huzefa and Gopinath, Aditya and Paredis, Chris and Pilla, Srikanth and Jia, Yunyi},
	month = apr,
	year = {2020},
	note = {Number: 2020-01-0709},
	pages = {2617--2622},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/XZ2L5JBZ/2020-01-0709.html:text/html},
}


@article{shapiro_analysis_1965,
	title = {An analysis of variance test for normality (complete samples)†},
	volume = {52},
	issn = {0006-3444},
	url = {https://doi.org/10.1093/biomet/52.3-4.591},
	doi = {10.1093/biomet/52.3-4.591},
	number = {3-4},
	urldate = {2022-01-12},
	journal = {Biometrika},
	author = {SHAPIRO, S. S. and WILK, M. B.},
	month = dec,
	year = {1965},
	pages = {591--611},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/PBP5YXLX/SHAPIRO and WILK - 1965 - An analysis of variance test for normality (comple.pdf:application/pdf;Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/4P6GEJUQ/336553.html:text/html},
}


@article{royston_extension_1982,
	title = {An {Extension} of {Shapiro} and {Wilk}'s {W} {Test} for {Normality} to {Large} {Samples}},
	volume = {31},
	issn = {1467-9876},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.2307/2347973},
	doi = {10.2307/2347973},
	abstract = {Shapiro and Wilk's (1965) W statistic arguably provides the best omnibus test of normality, but is currently limited to sample sizes between 3 and 50. W is extended up to n = 2000 and an approximate normalizing transformation suitable for computer implementation is given. A novel application of W in transforming data to normality is suggested, using the three-parameter lognormal as an example.},
	language = {en},
	number = {2},
	urldate = {2022-01-21},
	journal = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
	author = {Royston, J. P.},
	year = {1982},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.2307/2347973},
	keywords = {normalizing transformation, omnibus test, polynomial smoothing, tests of normality, w statistic},
	pages = {115--124},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/X6WZ4U2H/2347973.html:text/html},
}

@article{opencv_library,
    author = {Bradski, G.},
    citeulike-article-id = {2236121},
    journal = {Dr. Dobb's Journal of Software Tools},
    keywords = {bibtex-import},
    posted-at = {2008-01-15 19:21:54},
    priority = {4},
    title = {{The OpenCV Library}},
    year = {2000}
}


@article{miller_method_nodate,
	title = {The {Method} of {Least} {Squares}},
	language = {en},
	author = {Miller, Steven J},
	pages = {7},
	file = {Miller - The Method of Least Squares.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/VXQSG7YS/Miller - The Method of Least Squares.pdf:application/pdf},
}


@inproceedings{gojcic_perfect_2019,
	address = {Long Beach, CA, USA},
	title = {The {Perfect} {Match}: {3D} {Point} {Cloud} {Matching} {With} {Smoothed} {Densities}},
	isbn = {978-1-72813-293-8},
	shorttitle = {The {Perfect} {Match}},
	url = {https://ieeexplore.ieee.org/document/8954296/},
	doi = {10.1109/CVPR.2019.00569},
	abstract = {We propose 3DSmoothNet, a full workﬂow to match 3D point clouds with a siamese deep learning architecture and fully convolutional layers using a voxelized smoothed density value (SDV) representation. The latter is computed per interest point and aligned to the local reference frame (LRF) to achieve rotation invariance. Our compact, learned, rotation invariant 3D point cloud descriptor achieves 94.9\% average recall on the 3DMatch benchmark data set [49], outperforming the state-of-the-art by more than 20 percent points with only 32 output dimensions. This very low output dimension allows for near realtime correspondence search with 0.1 ms per feature point on a standard PC. Our approach is sensor- and sceneagnostic because of SDV, LRF and learning highly descriptive features with fully convolutional layers. We show that 3DSmoothNet trained only on RGB-D indoor scenes of buildings achieves 79.0\% average recall on laser scans of outdoor vegetation, more than double the performance of our closest, learning-based competitors [49, 17, 5, 4]. Code, data and pre-trained models are available online at https://github.com/zgojcic/3DSmoothNet.},
	language = {en},
	urldate = {2021-10-18},
	booktitle = {2019 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Gojcic, Zan and Zhou, Caifa and Wegner, Jan D. and Wieser, Andreas},
	month = jun,
	year = {2019},
	pages = {5540--5549},
	file = {Gojcic et al. - 2019 - The Perfect Match 3D Point Cloud Matching With Sm.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/J3VP5Y29/Gojcic et al. - 2019 - The Perfect Match 3D Point Cloud Matching With Sm.pdf:application/pdf},
}


@article{kaasalainen_radiometric_2009,
	title = {Radiometric {Calibration} of {LIDAR} {Intensity} {With} {Commercially} {Available} {Reference} {Targets}},
	volume = {47},
	issn = {1558-0644},
	doi = {10.1109/TGRS.2008.2003351},
	abstract = {We present a new approach for radiometric calibration of light detection and ranging (LIDAR) intensity data and demonstrate an application of this method to natural targets. The method is based on 1) using commercially available sand and gravel as reference targets and 2) the calibration of these reference targets in the laboratory conditions to know their backscatter properties. We have investigated the target properties crucial for accurate and consistent reflectance calibration and present a set of ideal targets easily available for calibration purposes. The first results from LIDAR-based brightness measurement of grass and sand show that the gravel-based calibration approach works in practice, is cost effective, and produces statistically meaningful results: Comparison of results from two separate airborne laser scanning campaigns shows that the relative calibration produces repeatable reflectance values.},
	number = {2},
	journal = {IEEE Transactions on Geoscience and Remote Sensing},
	author = {Kaasalainen, Sanna and Hyyppa, Hannu and Kukko, Antero and Litkey, Paula and Ahokas, Eero and Hyyppa, Juha and Lehner, Hubert and Jaakkola, Anttoni and Suomalainen, Juha and Akujarvi, Altti and Kaasalainen, Mikko and Pyysalo, Ulla},
	month = feb,
	year = {2009},
	note = {Conference Name: IEEE Transactions on Geoscience and Remote Sensing},
	keywords = {Backscatter, Brightness, Calibration, Costs, Hyperspectral sensors, laser measurements, laser radar, Laser radar, laser radiation effects, Laser theory, Radiometry, Reflectivity, remote sensing, Remote sensing},
	pages = {588--598},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/PTI2YXIF/4689353.html:text/html},
}

@article{schnabel_efficient_2007,
	title = {Efficient {RANSAC} for {Point}-{Cloud} {Shape} {Detection}},
	volume = {26},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2007.01016.x},
	doi = {10.1111/j.1467-8659.2007.01016.x},
	abstract = {In this paper we present an automatic algorithm to detect basic shapes in unorganized point clouds. The algorithm decomposes the point cloud into a concise, hybrid structure of inherent shapes and a set of remaining points. Each detected shape serves as a proxy for a set of corresponding points. Our method is based on random sampling and detects planes, spheres, cylinders, cones and tori. For models with surfaces composed of these basic shapes only, for example, CAD models, we automatically obtain a representation solely consisting of shape proxies. We demonstrate that the algorithm is robust even in the presence of many outliers and a high degree of noise. The proposed method scales well with respect to the size of the input point cloud and the number and size of the shapes within the data. Even point sets with several millions of samples are robustly decomposed within less than a minute. Moreover, the algorithm is conceptually simple and easy to implement. Application areas include measurement of physical parameters, scan registration, surface compression, hybrid rendering, shape classification, meshing, simplification, approximation and reverse engineering.},
	language = {en},
	number = {2},
	urldate = {2021-10-18},
	journal = {Computer Graphics Forum},
	author = {Schnabel, R. and Wahl, R. and Klein, R.},
	year = {2007},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8659.2007.01016.x},
	keywords = {geometry analysis, I.3.5: Computational Geometry and Object Modeling Curve, I.4.8: Scene Analysis Shape, large point-clouds, localized RANSAC, object representations, primitive shapes, shape fitting, solid, surface, Surface Fitting},
	pages = {214--226},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/TLC8W7IN/Schnabel et al. - 2007 - Efficient RANSAC for Point-Cloud Shape Detection.pdf:application/pdf;Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/UEBHVV4C/j.1467-8659.2007.01016.html:text/html},
}

@article{li_improved_2017,
	title = {An {Improved} {RANSAC} for {3D} {Point} {Cloud} {Plane} {Segmentation} {Based} on {Normal} {Distribution} {Transformation} {Cells}},
	volume = {9},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2072-4292/9/5/433},
	doi = {10.3390/rs9050433},
	abstract = {Plane segmentation is a basic task in the automatic reconstruction of indoor and urban environments from unorganized point clouds acquired by laser scanners. As one of the most common plane-segmentation methods, standard Random Sample Consensus (RANSAC) is often used to continually detect planes one after another. However, it suffers from the spurious-plane problem when noise and outliers exist due to the uncertainty of randomly sampling the minimum subset with 3 points. An improved RANSAC method based on Normal Distribution Transformation (NDT) cells is proposed in this study to avoid spurious planes for 3D point-cloud plane segmentation. A planar NDT cell is selected as a minimal sample in each iteration to ensure the correctness of sampling on the same plane surface. The 3D NDT represents the point cloud with a set of NDT cells and models the observed points with a normal distribution within each cell. The geometric appearances of NDT cells are used to classify the NDT cells into planar and non-planar cells. The proposed method is verified on three indoor scenes. The experimental results show that the correctness exceeds 88.5\% and the completeness exceeds 85.0\%, which indicates that the proposed method identifies more reliable and accurate planes than standard RANSAC. It also executes faster. These results validate the suitability of the method.},
	language = {en},
	number = {5},
	urldate = {2021-10-18},
	journal = {Remote Sensing},
	author = {Li, Lin and Yang, Fan and Zhu, Haihong and Li, Dalin and Li, You and Tang, Lei},
	month = may,
	year = {2017},
	note = {Number: 5
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {NDT features, normal distribution transformation, plane segmentation, point cloud, RANSAC},
	pages = {433},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/MVGNTFV3/Li et al. - 2017 - An Improved RANSAC for 3D Point Cloud Plane Segmen.pdf:application/pdf;Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/2AHRB7VV/433.html:text/html},
}

@article{li_point_2021,
	title = {Point {Cloud} {Registration} {Based} on {One}-{Point} {RANSAC} and {Scale}-{Annealing} {Biweight} {Estimation}},
	issn = {1558-0644},
	doi = {10.1109/TGRS.2020.3045456},
	abstract = {Point cloud registration (PCR) is an important task in photogrammetry and remote sensing, whose goal is to seek a seven-parameter similarity transformation to register a pair of point clouds. Traditional iterative closest point (ICP) variants highly rely on the initial parameters, and most of them cannot deal with cross-source (multisource) point clouds with scale changes. In this article, we propose a flexible correspondence-based PCR method, which is initial-guess free, fast, and robust. We first decompose the full seven-parameter registration problem into three subproblems, i.e., scale, rotation, and translation estimations, based on line vectors. Then, we propose a one-point random sample consensus (RANSAC) algorithm to estimate the scale and translation parameters. For the rotation estimation, we introduce a graduated optimization strategy into Tukey's biweight function and propose a scale-annealing biweight estimator. We evaluate the proposed method on both same-source and cross-source data. Results show that the proposed method is robust against over 99\% outliers and is one to two orders of magnitude faster than its competitors. The source code of our method will be made public.},
	journal = {IEEE Transactions on Geoscience and Remote Sensing},
	author = {Li, Jiayuan and Hu, Qingwu and Ai, Mingyao},
	year = {2021},
	note = {Conference Name: IEEE Transactions on Geoscience and Remote Sensing},
	keywords = {Laser radar, Estimation, Three-dimensional displays, Robustness, Biweight estimator, correspondence, cross-source (multisource), Detectors, Feature extraction, point cloud registration (PCR), random sample consensus (RANSAC)., Shape},
	pages = {1--14},
}

@article{yang_plane_nodate,
	title = {Plane {Detection} in {Point} {Cloud} {Data}},
	abstract = {Plane detection is a prerequisite to a wide variety of vision tasks. RANdom SAmple Consensus (RANSAC) algorithm is widely used for plane detection in point cloud data. Minimum description length (MDL) principle is used to deal with several competing hypothesis. This paper presents a new approach to the plane detection by integrating RANSAC and MDL. The method could avoid detecting wrong planes due to the complex geometry of the 3D data. The paper tests the performance of proposed method on both synthetic and real data.},
	language = {en},
	author = {Yang, Michael Ying and Forstner, Wolfgang},
	pages = {16},
	file = {Yang and Forstner - Plane Detection in Point Cloud Data.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/EDJG8BJR/Yang and Forstner - Plane Detection in Point Cloud Data.pdf:application/pdf},
}

@inproceedings{yue_new_2018,
	title = {A new plane segmentation method of point cloud based on mean shift and {RANSAC}},
	doi = {10.1109/CCDC.2018.8407394},
	abstract = {Three dimensional laser scanning technology has been widely used in machine vision and reverse engineering. Plane segmentation is an important step for object recognition in the point cloud obtained by laser scanner. Traditional plane segmentation method cannot obtain a specific plane accurately when normal is unknown. This paper proposes a new method based on Mean Shift normal clustering and RANSAC with constraints and initial point to segment the specific plane whose the normal is unknown. Firstly, the point cloud is down sampled using Voxel Grid method. Secondly, the algorithm uses Mean Shift clustering method on the normal sphere to obtain the actual normal of the plane to be segmented. Thirdly, with stopping point as initial condition and actual normal as constraint, RANSAC algorithm is used to segment the specific plane. Finally this algorithm is experimentally validated in point cloud data of actual scene.},
	booktitle = {2018 {Chinese} {Control} {And} {Decision} {Conference} ({CCDC})},
	author = {Yue, Wenlong and Lu, Junguo and Zhou, Weihang and Miao, Yubin},
	month = jun,
	year = {2018},
	note = {ISSN: 1948-9447},
	keywords = {Estimation, Three-dimensional displays, RANSAC, Clustering algorithms, Covariance matrices, Mathematical model, Mean Shift, Object segmentation, Plane Segmentation, Point Cloud, Surface reconstruction},
	pages = {1658--1663},
}

@article{tarsha-kurdi_hough-transform_2007,
	title = {Hough-{Transform} and {Extended} {RANSAC} {Algorithms} for {Automatic} {Detection} of {3D} {Building} {Roof} {Planes} from {Lidar} {Data}},
	abstract = {Airborne laser scanner technique is broadly the most appropriate way to acquire rapidly and with high density 3D data over a city. Once the 3D Lidar data are available, the next task is the automatic data processing, with major aim to construct 3D building models. Among the numerous automatic reconstruction methods, the techniques allowing the detection of 3D building roof planes are of crucial importance. Three main methods arise from the literature: region growing, Hough-transform and Random Sample Consensus (RANSAC) paradigm. Since region growing algorithms are sometimes not very transparent and not homogenously applied, this paper focuses only on the Hough-transform and the RANSAC algorithm. Their principles, their pseudocode - rarely detailed in the related literature - as well as their complete analyses are presented in this paper. An analytic comparison of both algorithms, in terms of processing time and sensitivity to cloud characteristics, shows that despite the limitation encountered in both methods, RANSAC algorithm is still more efficient than the first one. Under other advantages, its processing time is negligible even when the input data size is very large. On the other hand, Hough-transform is very sensitive to the segmentation parameters values. Therefore, RANSAC algorithm has been chosen and extended to exceed its limitations. Its major limitation is that it searches to detect the best mathematical plane among 3D building point cloud even if this plane does not always represent a roof plane. So the proposed extension allows harmonizing the mathematical aspect of the algorithm with the geometry of a roof. At last, it is shown that the extended approach provides very satisfying results, even in the case of very weak point density and for different levels of building complexity. Therefore, once the roof planes are successfully detected, the automatic building modelling can be carried out.},
	language = {en},
	author = {Tarsha-Kurdi, Fayez and Landes, Tania and Grussenmeyer, Pierre},
	year = {2007},
	pages = {7},
	file = {Tarsha-Kurdi et al. - 2007 - Hough-Transform and Extended RANSAC Algorithms for.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/L8SPGNSM/Tarsha-Kurdi et al. - 2007 - Hough-Transform and Extended RANSAC Algorithms for.pdf:application/pdf},
}

@article{smadja_road_nodate,
	title = {{ROAD} {EXTRACTION} {AND} {ENVIRONMENT} {INTERPRETATION} {FROM} {LIDAR} {SENSORS}},
	abstract = {We present in this article a new vehicle dedicated to road surveying, equipped with a highly precise positioning system, 2D lidar scans and high deﬁnition color images. We focus at ﬁrst on the sensors extrinsic calibration process. Once all sensors have been positioned in the same coordinates system, 3D realistic environments can be computed and interpreted. Moreover, an original algorithm for road extraction has been developed. This two-step method is based on the local road shape and does not rely on the presence of curbs or guardrails. Different uses of the RanSaC algorithm are employed, for road sides rough estimation in the ﬁrst place, then for unlikely candidates elimination. Road boundary and center points are further processed for road width and curvature computation in order to feed a geographic information system. Finally, a simple extraction of trafﬁc signs and road markings is presented.},
	language = {en},
	author = {Smadja, Laurent and Ninot, Jerome and Gavrilovic, Thomas},
	pages = {7},
	file = {Smadja et al. - ROAD EXTRACTION AND ENVIRONMENT INTERPRETATION FRO.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/IMT2CFWY/Smadja et al. - ROAD EXTRACTION AND ENVIRONMENT INTERPRETATION FRO.pdf:application/pdf},
}

@article{zhang_fast_2021,
	title = {Fast and {Robust} {Iterative} {Closest} {Point}},
	issn = {1939-3539},
	doi = {10.1109/TPAMI.2021.3054619},
	abstract = {The Iterative Closest Point (ICP) algorithm and its variants are a fundamental technique for rigid registration between two point sets, with wide applications in different areas from robotics to 3D reconstruction. The main drawbacks for ICP are its slow convergence as well as its sensitivity to outliers, missing data, and partial overlaps. Recent work such as Sparse ICP achieves robustness via sparsity optimization at the cost of computational speed. In this paper, we propose a new method for robust registration with fast convergence. First, we show that the classical point-to-point ICP can be treated as a majorization-minimization (MM) algorithm, and propose an Anderson acceleration approach to speed up its convergence. In addition, we introduce a robust error metric based on the Welsch's function, which is minimized efficiently using the MM algorithm with Anderson acceleration. On challenging datasets with noises and partial overlaps, we achieve similar or better accuracy than Sparse ICP while being at least an order of magnitude faster. Finally, we extend the robust formulation to point-to-plane ICP, and solve the resulting problem using a similar Anderson-accelerated MM strategy. Our robust ICP methods improve the registration accuracy on benchmark datasets while being competitive in computational time.},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Zhang, Juyong and Yao, Yuxin and Deng, Bailin},
	year = {2021},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Three-dimensional displays, Robustness, Convergence, Iterative closest point algorithm, Measurement, Acceleration, Anderson Acceleration, Fixed-point iterations, Majorlazer Minimization method, Optimization, Rigid Registration, Robust Estimator},
	pages = {1--1},
	file = {Accepted Version:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/JXDLXUVG/Zhang et al. - 2021 - Fast and Robust Iterative Closest Point.pdf:application/pdf;IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/FBQ8V8BD/9336308.html:text/html},
}

@inproceedings{choi_performance_2009,
	address = {London},
	title = {Performance {Evaluation} of {RANSAC} {Family}},
	isbn = {978-1-901725-39-1},
	url = {http://www.bmva.org/bmvc/2009/Papers/Paper355/Paper355.html},
	doi = {10.5244/C.23.81},
	abstract = {RANSAC (Random Sample Consensus) has been popular in regression problem with samples contaminated with outliers. It has been a milestone of many researches on robust estimators, but there are a few survey and performance analysis on them. This paper categorizes them on their objectives: being accurate, being fast, and being robust. Performance evaluation performed on line ﬁtting with various data distribution. Planar homography estimation was utilized to present performance in real data.},
	language = {en},
	urldate = {2022-01-27},
	booktitle = {Procedings of the {British} {Machine} {Vision} {Conference} 2009},
	publisher = {British Machine Vision Association},
	author = {Choi, Sunglok and Kim, Taemin and Yu, Wonpil},
	year = {2009},
	pages = {81.1--81.12},
	file = {Choi et al. - 2009 - Performance Evaluation of RANSAC Family.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/ZL4SUNY8/Choi et al. - 2009 - Performance Evaluation of RANSAC Family.pdf:application/pdf},
}

@article{gallo_cc-ransac_2011,
	title = {{CC}-{RANSAC}: {Fitting} planes in the presence of multiple surfaces in range data},
	volume = {32},
	issn = {0167-8655},
	shorttitle = {{CC}-{RANSAC}},
	url = {https://www.sciencedirect.com/science/article/pii/S0167865510003557},
	doi = {10.1016/j.patrec.2010.10.009},
	abstract = {Range sensors, in particular time-of-flight and stereo cameras, are being increasingly used for applications such as robotics, automotive, human-machine interface and virtual reality. The ability to recover the geometrical structure of visible surfaces is critical for scene understanding. Typical structured indoor or urban scenes are often represented via compositional models comprising multiple planar surface patches. The RANSAC robust regression algorithm is the most popular technique to date for extracting individual planar patches from noisy data sets containing multiple surfaces. Unfortunately, RANSAC fails to produce reliable results in situations with two nearby patches of limited extent, where a single plane crossing through the two patches may contain more inliers than the “correct” models. This is the case of steps, curbs, or ramps, which represent the focus of our research for the impact they can have on cars’ safe parking systems or robot navigation. In an effort to improve the quality of regression in these cases, we propose a modification of the RANSAC algorithm, dubbed CC-RANSAC, that only considers the largest connected components of inliers to evaluate the fitness of a candidate plane. We provide experimental evidence that CC-RANSAC may recover the planar patches composing a typical step or ramp with substantially higher accuracy than the traditional RANSAC algorithm.},
	language = {en},
	number = {3},
	urldate = {2022-01-27},
	journal = {Pattern Recognition Letters},
	author = {Gallo, Orazio and Manduchi, Roberto and Rafii, Abbas},
	month = feb,
	year = {2011},
	keywords = {Range data processing, RANSAC, Robust fitting, Time-of-flight applications},
	pages = {403--410},
	file = {Submitted Version:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/Q6RA6TQA/Gallo et al. - 2011 - CC-RANSAC Fitting planes in the presence of multi.pdf:application/pdf;ScienceDirect Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/Q8E4CGU7/S0167865510003557.html:text/html},
}

@inproceedings{du_fast_2018,
	address = {Cham},
	series = {Advances in {Intelligent} {Systems} and {Computing}},
	title = {The {Fast} {Lane} {Detection} of {Road} {Using} {RANSAC} {Algorithm}},
	isbn = {978-3-319-67071-3},
	doi = {10.1007/978-3-319-67071-3_1},
	abstract = {In order to ensure driving safety and advanced driver assistance systems (ADAS) attracted more and more attention. Lane departure warning system is an important part of the system. Fast and stable lane detection is a prerequisite for Lane detection under complex background. In this paper, we propose a new lane detection method through a bird’s eye view maps and modified RANSAC (random sampling) based on inspiration from the road feature extraction algorithm for remote sensing images. According to the image of a bird’s eye view, we can identify the tag line through progressive probabilistic Hough transform in the opposite lane detection. Then the group rows are detected by a new weighting scheme based on distance, we can get a candidate lane field. Each field, Lane the RANSAC algorithm is improved and the dual-model fitting. Therefore, the curvature of the road direction can be predicted and the slope of the line. Finally, our results show that lane detection algorithm is robust and real-time performance in a variety of road conditions.},
	language = {en},
	booktitle = {International {Conference} on {Applications} and {Techniques} in {Cyber} {Security} and {Intelligence}},
	publisher = {Springer International Publishing},
	author = {Du, Huan and Xu, Zheng and Ding, Yong},
	editor = {Abawajy, Jemal and Choo, Kim-Kwang Raymond and Islam, Rafiqul},
	year = {2018},
	keywords = {Bird’s eye view, Lane detection, RANSAC},
	pages = {1--7},
	file = {Springer Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/UBN3TNFC/Du et al. - 2018 - The Fast Lane Detection of Road Using RANSAC Algor.pdf:application/pdf},
}

@misc{noauthor_road_nodate,
	title = {Road {Detection} by {RANSAC} on {Randomly} {Sampled} {Patches} with {Slanted} {Plane} {Prior} - {AcademicFocus}},
	url = {https://af.global.cnki.net/stmt/TitleBrowse/KnowledgeNet/IEEE201611001185?db=STMI8320},
	urldate = {2022-01-27},
	file = {Road Detection by RANSAC on Randomly Sampled Patches with Slanted Plane Prior - AcademicFocus:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/CUQ8DHPC/IEEE201611001185.html:text/html},
}

@inproceedings{borkar_robust_2009,
	address = {Cairo, Egypt},
	title = {Robust lane detection and tracking with ransac and {Kalman} filter},
	isbn = {978-1-4244-5653-6},
	url = {http://ieeexplore.ieee.org/document/5413980/},
	doi = {10.1109/ICIP.2009.5413980},
	abstract = {In a previous paper, a simple approach to lane detection using the Hough transform and iterated matched ﬁlters was described [1]. This paper extends this work by incorporating an inverse perspective mapping to create a bird’s-eye view of the road, applying random sample consensus to help eliminate outliers due to noise and artifacts in the road, and a Kalman ﬁlter to help smooth the output of the lane tracker.},
	language = {en},
	urldate = {2022-01-27},
	booktitle = {2009 16th {IEEE} {International} {Conference} on {Image} {Processing} ({ICIP})},
	publisher = {IEEE},
	author = {Borkar, Amol and Hayes, Monson and Smith, Mark T.},
	month = nov,
	year = {2009},
	pages = {3261--3264},
	file = {Borkar et al. - 2009 - Robust lane detection and tracking with ransac and.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/DU73YTP4/Borkar et al. - 2009 - Robust lane detection and tracking with ransac and.pdf:application/pdf},
}

@inproceedings{borkar_robust_2009-1,
	title = {Robust lane detection and tracking with ransac and {Kalman} filter},
	doi = {10.1109/ICIP.2009.5413980},
	abstract = {In a previous paper, a simple approach to lane detection using the Hough transform and iterated matched filters was described. This paper extends this work by incorporating an inverse perspective mapping to create a bird's-eye view of the road, applying random sample consensus to help eliminate outliers due to noise and artifacts in the road, and a Kalman filter to help smooth the output of the lane tracker.},
	booktitle = {2009 16th {IEEE} {International} {Conference} on {Image} {Processing} ({ICIP})},
	author = {Borkar, Amol and Hayes, Monson and Smith, Mark T.},
	month = nov,
	year = {2009},
	note = {ISSN: 2381-8549},
	keywords = {Cameras, Collision avoidance, Consumer electronics, Driver circuits, Hough transform, Image edge detection, Image processing, Kalman filter, Lane detection, Matched filters, Road safety, Road transportation, Robustness},
	pages = {3261--3264},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/2YG7LTW9/5413980.html:text/html},
}

@inproceedings{yang_road_2016,
	title = {Road detection by {RANSAC} on randomly sampled patches with slanted plane prior},
	doi = {10.1109/ICSP.2016.7877966},
	abstract = {In this paper, an efficient road detection algorithm is proposed. By exploiting the recent progress of fast stereo matching algorithms, the proposed road detection algorithm relies on the accurate semi-dense disparity map only. The RANSAC algorithm is used to compute road plane parameters on randomly sampled disparity patches. Unreliable patches are removed by introducing a road plane slope constraint, and the final road plane model is computed from pixels in a valid patch set. Experimental results show that the proposed method is robust to the illumination variations in real world urban road environments, and can mark road pixels accurately and efficiently on challenging datasets.},
	booktitle = {2016 {IEEE} 13th {International} {Conference} on {Signal} {Processing} ({ICSP})},
	author = {Yang, Qingqing and Fan, Shengli and Wang, Lang and Wang, Yigang},
	month = nov,
	year = {2016},
	note = {ISSN: 2164-5221},
	keywords = {Cameras, Color, Computational modeling, Detection algorithms, Image sensors, Roads, Robustness},
	pages = {929--933},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/4RZJIFCK/7877966.html:text/html},
}

@inproceedings{guo_lane_2015,
	title = {Lane {Detection} {Method} {Based} on {Improved} {RANSAC} {Algorithm}},
	doi = {10.1109/ISADS.2015.24},
	abstract = {Lane detection based on computer vision is a key technology of Automatic Drive System for intelligent vehicles. In this paper, we propose a real-time and efficient lane detection algorithm that can detect lanes appearing in urban streets and highway roads under complex background. In order to enhance lane boundary information and to be suitable for various light conditions, we adopt canny algorithm for edge detection to get good feature points. We use the generalized curve lane parameter model, which can describe both straight and curved lanes. We propose an improved random sample consensus (RANSAC) algorithm combined with the least squares technique to estimate lane model parameters based on feature extraction. Experiments are conducted on both real road lane videos captured by Tongji University and Caltech Lane Datasets. The experimental results show that our algorithm is can meet the real time requirement and fit lane boundaries well in various challenging road conditions.},
	booktitle = {2015 {IEEE} {Twelfth} {International} {Symposium} on {Autonomous} {Decentralized} {Systems}},
	author = {Guo, Jie and Wei, Zhihua and Miao, Duoqian},
	month = mar,
	year = {2015},
	note = {ISSN: 1541-0056},
	keywords = {Algorithm design and analysis, Computational modeling, Feature extraction, Image edge detection, Improved RANSAC, Lane detection, Lane feature extraction, Mathematical model, Real-time systems, Roads},
	pages = {285--288},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/76NC4DDB/7098273.html:text/html},
}


@article{naaman_tight_2021,
	title = {On the tight constant in the multivariate {Dvoretzky}–{Kiefer}–{Wolfowitz} inequality},
	volume = {173},
	issn = {0167-7152},
	url = {https://www.sciencedirect.com/science/article/pii/S016771522100050X},
	doi = {10.1016/j.spl.2021.109088},
	abstract = {We derive the tight constant in the multivariate version of the Dvoretzky–Kiefer–Wolfowitz inequality. The inequality is leveraged to construct the first fully non-parametric test for multivariate probability distributions including a simple formula for the test statistic. We also generalize the test under appropriate α-mixing conditions and describe applications of the tests to machine learning and representative sampling.},
	language = {en},
	urldate = {2022-02-08},
	journal = {Statistics \& Probability Letters},
	author = {Naaman, Michael},
	month = jun,
	year = {2021},
	keywords = {Empirical process, Hypothesis test, Machine learning, Non-parametric},
	pages = {109088},
	file = {ScienceDirect Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/PIWBKYUN/Naaman - 2021 - On the tight constant in the multivariate Dvoretzk.pdf:application/pdf},
}


@article{derpanis_overview_nodate,
	title = {Overview of the {RANSAC} {Algorithm}},
	language = {en},
	author = {Derpanis, Konstantinos G},
	pages = {2},
	file = {Derpanis - Overview of the RANSAC Algorithm.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/UY36SISB/Derpanis - Overview of the RANSAC Algorithm.pdf:application/pdf},
}


@article{yaniv_random_2010,
	title = {Random {Sample} {Consensus} ({RANSAC}) {Algorithm}, {A} {Generic} {Implementation}},
	doi = {10.54294/ia6mzx},
	abstract = {The Random Sample Consensus (RANSAC) algorithm for robust parameter value estimation has been applied to a wide variety of parametric entities (e.g. plane, the fundamental matrix). In many implementations the algorithm is tightly integrated with code pertaining to a specific parametric object. In this paper we introduce a generic RANSAC implementation that is independent of the estimated object. Thus, the user is able to ignore outlying data elements potentially found in their input. To illustrate the use of the algorithm we implement the required components for estimating the parameter values of a hyperplane and hypersphere.},
	journal = {The Insight Journal},
	author = {Yaniv, Z.},
	year = {2010},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/LJ7QJQIB/Yaniv - 2010 - Random Sample Consensus (RANSAC) Algorithm, A Gene.pdf:application/pdf},
}


@incollection{fischler_random_1987,
	address = {San Francisco (CA)},
	title = {Random {Sample} {Consensus}: {A} {Paradigm} for {Model} {Fitting} with {Applications} to {Image} {Analysis} and {Automated} {Cartography}},
	isbn = {978-0-08-051581-6},
	shorttitle = {Random {Sample} {Consensus}},
	url = {https://www.sciencedirect.com/science/article/pii/B9780080515816500702},
	abstract = {A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced, RANSAC is capable of interpreting/ smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. A major portion of this paper describes the application of RANSAC to the Location Determination Problem (LDP): Given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing and analysis conditions. Implementation details and computational examples are also presented.},
	language = {en},
	urldate = {2022-02-08},
	booktitle = {Readings in {Computer} {Vision}},
	publisher = {Morgan Kaufmann},
	author = {Fischler, Martin A. and Bolles, Robert C.},
	editor = {Fischler, Martin A. and Firschein, Oscar},
	month = jan,
	year = {1987},
	doi = {10.1016/B978-0-08-051581-6.50070-2},
	pages = {726--740},
	file = {ScienceDirect Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/E2IEIVQY/B9780080515816500702.html:text/html},
}


@article{cantzler_random_nodate,
	title = {Random {Sample} {Consensus} ({RANSAC})},
	language = {en},
	author = {Cantzler, H},
	pages = {4},
	file = {Cantzler - Random Sample Consensus (RANSAC).pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/R9GQWRY6/Cantzler - Random Sample Consensus (RANSAC).pdf:application/pdf},
}


@inproceedings{choi_performance_2009,
	address = {London},
	title = {Performance {Evaluation} of {RANSAC} {Family}},
	isbn = {978-1-901725-39-1},
	url = {http://www.bmva.org/bmvc/2009/Papers/Paper355/Paper355.html},
	doi = {10.5244/C.23.81},
	language = {en},
	urldate = {2022-02-08},
	booktitle = {Procedings of the {British} {Machine} {Vision} {Conference} 2009},
	publisher = {British Machine Vision Association},
	author = {Choi, Sunglok and Kim, Taemin and Yu, Wonpil},
	year = {2009},
	pages = {81.1--81.12},
	file = {Choi et al. - 2009 - Performance Evaluation of RANSAC Family.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/W78BL2WE/Choi et al. - 2009 - Performance Evaluation of RANSAC Family.pdf:application/pdf},
}


@inproceedings{chum_matching_2005,
	address = {San Diego, CA, USA},
	title = {Matching with {PROSAC} — {Progressive} {Sample} {Consensus}},
	volume = {1},
	isbn = {978-0-7695-2372-9},
	url = {http://ieeexplore.ieee.org/document/1467271/},
	doi = {10.1109/CVPR.2005.221},
	abstract = {A new robust matching method is proposed. The Progressive Sample Consensus (PROSAC) algorithm exploits the linear ordering deﬁned on the set of correspondences by a similarity function used in establishing tentative correspondences. Unlike RANSAC, which treats all correspondences equally and draws random samples uniformly from the full set, PROSAC samples are drawn from progressively larger sets of top-ranked correspondences.},
	language = {en},
	urldate = {2022-02-08},
	booktitle = {2005 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR}'05)},
	publisher = {IEEE},
	author = {Chum, O. and Matas, J.},
	year = {2005},
	pages = {220--226},
	file = {Chum and Matas - 2005 - Matching with PROSAC — Progressive Sample Consensu.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/B72A83TK/Chum and Matas - 2005 - Matching with PROSAC — Progressive Sample Consensu.pdf:application/pdf},
}


@inproceedings{chum_matching_2005,
	address = {San Diego, CA, USA},
	title = {Matching with {PROSAC} — {Progressive} {Sample} {Consensus}},
	volume = {1},
	isbn = {978-0-7695-2372-9},
	url = {http://ieeexplore.ieee.org/document/1467271/},
	doi = {10.1109/CVPR.2005.221},
	abstract = {A new robust matching method is proposed. The Progressive Sample Consensus (PROSAC) algorithm exploits the linear ordering deﬁned on the set of correspondences by a similarity function used in establishing tentative correspondences. Unlike RANSAC, which treats all correspondences equally and draws random samples uniformly from the full set, PROSAC samples are drawn from progressively larger sets of top-ranked correspondences.},
	language = {en},
	urldate = {2022-02-08},
	booktitle = {2005 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR}'05)},
	publisher = {IEEE},
	author = {Chum, O. and Matas, J.},
	year = {2005},
	pages = {220--226},
	file = {Chum and Matas - 2005 - Matching with PROSAC — Progressive Sample Consensu.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/B72A83TK/Chum and Matas - 2005 - Matching with PROSAC — Progressive Sample Consensu.pdf:application/pdf},
}


@inproceedings{wan_road_2007,
	title = {A {Road} {Extraction} {Approach} {Based} on {Fuzzy} {Logic} for {High}-{Resolution} {Multispectral} {Data}},
	isbn = {978-0-7695-2874-8},
	doi = {10.1109/FSKD.2007.114},
	abstract = {In this paper, we present an approach based on information fusion for road networks extraction from high-resolution multi-spectral satellite image data that builds upon pixel-based fuzzy logic segmentation approach. This road networks extraction system includes three different modules: geometrical features processing based on local context; segmentation based on fuzzy classification; angular texture signature to refine road clusters. Experimental results show that this method is efficient and distinct in the discrimination of roads and other spectral similar land cover classes.},
	author = {Wan, Youchuan and Shen, Shaohong and Song, Yang and Liu, Shufan},
	month = sep,
	year = {2007},
	pages = {203--207},
}


@incollection{levi_3d_2012_light,
	address = {Berlin, Heidelberg},
	title = {{3D} {LIDAR}- and {Camera}-{Based} {Terrain} {Classification} {Under} {Different} {Lighting} {Conditions}},
	isbn = {978-3-642-32216-7 978-3-642-32217-4},
	url = {http://link.springer.com/10.1007/978-3-642-32217-4_3},
	abstract = {Terrain classiﬁcation is a fundamental task in outdoor robot navigation to detect and avoid impassable terrain. Camera-based approaches are wellstudied and provide good results. A drawback of these approaches, however, is that the quality of the classiﬁcation varies with the prevailing lighting conditions. 3D laser scanners, on the other hand, are largely illumination-invariant. In this work we present easy to compute features for 3D point clouds using range and intensity values. We compare the classiﬁcation results obtained using only the laser-based features with the results of camera-based classiﬁcation and study the inﬂuence of different lighting conditions.},
	language = {en},
	urldate = {2022-02-15},
	booktitle = {Autonomous {Mobile} {Systems} 2012},
	publisher = {Springer Berlin Heidelberg},
	author = {Laible, Stefan and Khan, Yasir Niaz and Bohlmann, Karsten and Zell, Andreas},
	editor = {Levi, Paul and Zweigle, Oliver and Häußermann, Kai and Eckstein, Bernd},
	year = {2012},
	doi = {10.1007/978-3-642-32217-4_3},
	note = {Series Title: Informatik aktuell},
	pages = {21--29},
	file = {Laible et al. - 2012 - 3D LIDAR- and Camera-Based Terrain Classification .pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/RQUF93GE/Laible et al. - 2012 - 3D LIDAR- and Camera-Based Terrain Classification .pdf:application/pdf},
}


@incollection{levi_3d_2012_terrain,
	address = {Berlin, Heidelberg},
	title = {{3D} {LIDAR}- and {Camera}-{Based} {Terrain} {Classification} {Under} {Different} {Lighting} {Conditions}},
	isbn = {978-3-642-32216-7 978-3-642-32217-4},
	url = {http://link.springer.com/10.1007/978-3-642-32217-4_3},
	abstract = {Terrain classiﬁcation is a fundamental task in outdoor robot navigation to detect and avoid impassable terrain. Camera-based approaches are wellstudied and provide good results. A drawback of these approaches, however, is that the quality of the classiﬁcation varies with the prevailing lighting conditions. 3D laser scanners, on the other hand, are largely illumination-invariant. In this work we present easy to compute features for 3D point clouds using range and intensity values. We compare the classiﬁcation results obtained using only the laser-based features with the results of camera-based classiﬁcation and study the inﬂuence of different lighting conditions.},
	language = {en},
	urldate = {2022-02-15},
	booktitle = {Autonomous {Mobile} {Systems} 2012},
	publisher = {Springer Berlin Heidelberg},
	author = {Laible, Stefan and Khan, Yasir Niaz and Bohlmann, Karsten and Zell, Andreas},
	editor = {Levi, Paul and Zweigle, Oliver and Häußermann, Kai and Eckstein, Bernd},
	year = {2012},
	doi = {10.1007/978-3-642-32217-4_3},
	note = {Series Title: Informatik aktuell},
	pages = {21--29},
	file = {Laible et al. - 2012 - 3D LIDAR- and Camera-Based Terrain Classification .pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/RQUF93GE/Laible et al. - 2012 - 3D LIDAR- and Camera-Based Terrain Classification .pdf:application/pdf},
}


@inproceedings{schilling_geometric_2017,
	title = {Geometric and visual terrain classification for autonomous mobile navigation},
	doi = {10.1109/IROS.2017.8206092},
	abstract = {In this paper, we present a multi-sensory terrain classification algorithm with a generalized terrain representation using semantic and geometric features. We compute geometric features from lidar point clouds and extract pixel-wise semantic labels from a fully convolutional network that is trained using a dataset with a strong focus on urban navigation. We use data augmentation to overcome the biases of the original dataset and apply transfer learning to adapt the model to new semantic labels in off-road environments. Finally, we fuse the visual and geometric features using a random forest to classify the terrain traversability into three classes: safe, risky and obstacle. We implement the algorithm on our four-wheeled robot and test it in novel environments including both urban and off-road scenes which are distinct from the training environments and under summer and winter conditions. We provide experimental result to show that our algorithm can perform accurate and fast prediction of terrain traversability in a mixture of environments with a small set of training data.},
	booktitle = {2017 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Schilling, Fabian and Chen, Xi and Folkesson, John and Jensfelt, Patric},
	month = sep,
	year = {2017},
	note = {ISSN: 2153-0866},
	keywords = {Cameras, Feature extraction, Robots, Semantics, Three-dimensional displays, Training, Visualization},
	pages = {2678--2684},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/5SA8BY9D/8206092.html:text/html},
}

@article{ojeda_terrain_2006,
	title = {Terrain characterization and classification with a mobile robot},
	volume = {23},
	issn = {1556-4967},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.20113},
	doi = {10.1002/rob.20113},
	abstract = {This paper introduces novel methods for terrain classification and characterization with a mobile robot. In the context of this paper, terrain classification aims at associating terrains with one of a few predefined, commonly known categories, such as gravel, sand, or asphalt. Terrain characterization, on the other hand, aims at determining key parameters of the terrain that affect its ability to support vehicular traffic. Such properties are collectively called “trafficability.” The proposed terrain classification and characterization system comprises a skid-steer mobile robot, as well as some common and some uncommon but optional onboard sensors. Using these components, our system can characterize and classify terrain in real time and during the robot's actual mission. The paper presents experimental results for both the terrain classification and characterization methods. The methods proposed in this paper can likely also be implemented on tracked robots, although we did not test this option in our work.},
	language = {en},
	number = {2},
	urldate = {2022-02-23},
	journal = {Journal of Field Robotics},
	author = {Ojeda, Lauro and Borenstein, Johann and Witus, Gary and Karlsen, Robert},
	year = {2006},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/rob.20113},
	pages = {103--122},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/S4Q6GAKJ/rob.html:text/html;Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/BP8CRGNE/Ojeda et al. - 2006 - Terrain characterization and classification with a.pdf:application/pdf},
}

@article{coombs_driving_2000,
	title = {Driving {Autonomously} {Offroad} up to 35 km/h},
	url = {https://www.nist.gov/publications/driving-autonomously-offroad-35-kmh},
	abstract = {A robotic HMMWV (a.k.a. "humvee") drives autonomously offroad at speeds up to 35 km/h (10 m/s, 20 mph).},
	language = {en},
	urldate = {2022-02-23},
	author = {Coombs, David and Murphy, Karl and Lacaze, Alberto and Legowik, Steven},
	month = oct,
	year = {2000},
	note = {Last Modified: 2017-02-19T20:02-05:00},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/8BERYJIA/Coombs et al. - 2000 - Driving Autonomously Offroad up to 35 kmh.pdf:application/pdf;Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/L4E82G4S/driving-autonomously-offroad-35-kmh.html:text/html},
}

@article{stavens_self-supervised_nodate,
	title = {A {Self}-{Supervised} {Terrain} {Roughness} {Estimator} for {Off}-{Road} {Autonomous} {Driving}},
	abstract = {Accurate perception is a principal challenge of autonomous oﬀ-road driving. Perceptive technologies generally focus on obstacle avoidance. However, at high speed, terrain roughness is also important to control shock the vehicle experiences. The accuracy required to detect rough terrain is signiﬁcantly greater than that necessary for obstacle avoidance.},
	language = {en},
	author = {Stavens, David and Thrun, Sebastian},
	pages = {8},
	file = {Stavens and Thrun - A Self-Supervised Terrain Roughness Estimator for .pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/UX3MHEC7/Stavens and Thrun - A Self-Supervised Terrain Roughness Estimator for .pdf:application/pdf},
}

@inproceedings{belter_rough_2010,
	title = {Rough terrain mapping and classification for foothold selection in a walking robot},
	doi = {10.1109/SSRR.2010.5981552},
	abstract = {This paper presents an algorithm for real-time building of a local grid-based elevation map from noisy 2D range measurements of the Hokuyo URG-04LX miniature laser scanner. The terrain mapping module supports a foothold selection algorithm, which employs a polynomial-based approximation method to create an adaptive decision surface. The robot learns from simple simulations, therefore no a priori expert-given rules or parameters are used. The acquired terrain map and planned footholds enable the robot to walk more stable, avoiding slippages and fall-downs.},
	booktitle = {2010 {IEEE} {Safety} {Security} and {Rescue} {Robotics}},
	author = {Belter, Dominik and Skrzypczyński, Piotr},
	month = jul,
	year = {2010},
	note = {ISSN: 2374-3247},
	keywords = {foothold selection, Laser applications, mapping, Measurement by laser beam, walking robot},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/V2KBZIRQ/5981552.html:text/html},
}

@inproceedings{bartoszyk_terrain-aware_2017,
	title = {Terrain-aware motion planning for a walking robot},
	doi = {10.1109/RoMoCo.2017.8003889},
	abstract = {In this paper, we propose a new environment model for legged robots. The model stores information about the shape of the obstacles and terrain type. We also propose the motion planner which takes into account terrain types when planning the motion of the robot. The planner is based on A* graph search method that guides RRT-Connect method for precise motion planning. With the proposed navigation system the robot is capable of planning its motion on the terrain with various terrain types and avoid regions which are potentially risky. Finally, we provide results of the experiments which show the properties of the proposed perception system and motion planner.},
	booktitle = {2017 11th {International} {Workshop} on {Robot} {Motion} and {Control} ({RoMoCo})},
	author = {Bartoszyk, Szymon and Kasprzak, Patryk and Belter, Dominik},
	month = jul,
	year = {2017},
	keywords = {Legged locomotion, Planning, Robot kinematics, Robot sensing systems, Three-dimensional displays},
	pages = {29--34},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/SYQYAPEK/8003889.html:text/html},
}

@misc{noauthor_fusion_nodate,
	title = {Fusion between a color camera and a {TOF} camera to improve traversability of agricultural vehicles - {Archive} ouverte {HAL}},
	url = {https://hal.archives-ouvertes.fr/hal-01580255/},
	urldate = {2022-02-23},
	file = {Fusion between a color camera and a TOF camera to improve traversability of agricultural vehicles - Archive ouverte HAL:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/YD8SB6FA/hal-01580255.html:text/html},
}

@inproceedings{li_rugged_2019,
	title = {Rugged - {Terrain} {Traversability} {Analyzing} {For} {Quadruped} {Robots}},
	doi = {10.1109/IRCE.2019.00008},
	abstract = {This paper presents an algorithm of feasibility analysis of the terrain to improve the adaptability of quadruped bionic robot for arbitrary environments. We use the depth camera to sense the ground environment, and utilize the rasterized Digital Elevation Model (DEM) to process the dense point clouds obtained by the camera to describe the terrain. Through calculating the geometric features in the grid, including slope value, curvature value, roughness and fluctuation, the traversability of terrain could be derived and judged. In this paper, we propose an approach to calculate the roughness characteristics, which increasing the accuracy of calculation and meanwhile adding the calculation of the grid fluctuation. The traversability of the grid is then calculated according to the corresponding formula according to the geometric characteristics of each grid. Finally, a simulation is provided to illustrate the effectiveness of the proposed method.},
	booktitle = {2019 2nd {International} {Conference} of {Intelligent} {Robotic} and {Control} {Engineering} ({IRCE})},
	author = {Li, Shangcong and Song, Rui and Zheng, Yukun and Zhao, He and Li, Yibin},
	month = aug,
	year = {2019},
	keywords = {quadruped robot, terrain, traversability analyzing},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/F7NM22FY/9107592.html:text/html},
}

@article{wilson_terrain_2014,
	title = {Terrain {Roughness} {Identification} for {High}-{Speed} {UGVs}},
	volume = {1},
	url = {https://jacr.avestia.com/2014/002.html},
	abstract = {The Volume 1 published for JACR Journal.},
	language = {en},
	urldate = {2022-02-23},
	journal = {Journal of Automation and Control Research},
	author = {Wilson, Graeme N. and Ramirez-Serrano, Alejandro},
	month = oct,
	year = {2014},
	pages = {11--21},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/4Z62XUMT/002.html:text/html},
}

@article{siva_robot_2019,
	title = {Robot adaptation to unstructured terrains by joint representation and apprenticeship learning},
	url = {https://par.nsf.gov/biblio/10095437-robot-adaptation-unstructured-terrains-joint-representation-apprenticeship-learning},
	abstract = {When a mobile robot is deployed in a field environment, e.g., during a disaster response application, the capability of adapting its navigational behaviors to unstructured terrains is essential for effective and safe robot navigation. In this paper, we introduce a novel joint terrain representation and apprenticeship learning approach to implement robot adaptation to unstructured terrains. Different from conventional learning-based adaptation techniques, our approach provides a unified problem formulation that integrates representation and apprenticeship learning under a unified regularized optimization framework, instead of treating them as separate and independent procedures. Our approach also has the capability to automatically identify discriminative feature modalities, which can improve the robustness of robot adaptation. In addition, we implement a new optimization algorithm to solve the formulated problem, which provides a theoretical guarantee to converge to the global optimal solution. In the experiments, we extensively evaluate the proposed approach in real-world scenarios, in which a mobile robot navigates on familiar and unfamiliar unstructured terrains. Experimental results have shown that the proposed approach is able to transfer human expertise to robots with small errors, achieve superior performance compared with previous and baseline methods, and provide intuitive insights on the importance of terrain feature modalities.},
	language = {en},
	urldate = {2022-02-23},
	journal = {Robotics: science and systems},
	author = {Siva, Sriram and Wigness, Maggie and Rogers, John and Zhang, Hao},
	month = jan,
	year = {2019},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/DCGHG76E/Siva et al. - 2019 - Robot adaptation to unstructured terrains by joint.pdf:application/pdf;Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/4BX3KLQA/10095437.html:text/html},
}


@inproceedings{laible_terrain_2013,
	title = {Terrain classification with conditional random fields on fused {3D} {LIDAR} and camera data},
	doi = {10.1109/ECMR.2013.6698838},
	abstract = {For a mobile robot to navigate safely and efficiently in an outdoor environment, it has to recognize its surrounding terrain. Our robot is equipped with a low-resolution 3D LIDAR and a color camera. The data from both sensors are fused to classify the terrain in front of the robot. Therefore, the ground plane is divided into a grid and each cell is classified as either asphalt, cobblestones, grass or gravel. We use height and intensity features for the LIDAR data and Local ternary patterns for the image data. By additionally taking into account the context-sensitive nature of the terrain, the results can be improved significantly. We present a method based on Conditional Random Fields and compare it with a Markov Random Field based approach. We show that the Conditional Random Field model is better suited for our task. We achieve an average true positive rate of 94.2\% for classifying the grid cells into the four terrain classes.},
	booktitle = {2013 {European} {Conference} on {Mobile} {Robots}},
	author = {Laible, Stefan and Khan, Yasir Niaz and Zell, Andreas},
	month = sep,
	year = {2013},
	keywords = {Cameras, Image color analysis, Laser radar, Robot sensing systems, Three-dimensional displays},
	pages = {172--177},
	file = {Submitted Version:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/XSIIPPPE/Laible et al. - 2013 - Terrain classification with conditional random fie.pdf:application/pdf;IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/VGM8TJFT/6698838.html:text/html},
}

@inproceedings{laible_3d_2012,
	title = {{3D} {LIDAR}- and {Camera}-{Based} {Terrain} {Classification} {Under} {Different} {Lighting} {Conditions}},
	isbn = {978-3-642-32216-7},
	doi = {10.1007/978-3-642-32217-4_3},
	abstract = {Terrain classification is a fundamental task in outdoor robot navigation to detect and avoid impassable terrain. Camera-based approaches are well-studied and provide good results. A drawback of these approaches, however, is that the quality of the classification varies with the prevailing lighting conditions. 3D laser scanners, on the other hand, are largely illumination-invariant. In this work we present easy
to compute features for 3D point clouds using range and intensity values. We compare the classification results obtained using only the laser-based features with the results of camera-based classification and study the influence of different lighting conditions.},
	author = {Laible, Stefan and Khan, Yasir Niaz and Bohlmann, Karsten and Zell, Andreas},
	month = sep,
	year = {2012},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/KG3L6MZA/Laible et al. - 2012 - 3D LIDAR- and Camera-Based Terrain Classification .pdf:application/pdf},
}

@misc{laible_map_building,
	title = {Building local terrain maps using spatio-temporal classification for semantic robot localization {\textbar} {IEEE} {Conference} {Publication} {\textbar} {IEEE} {Xplore}},
	url = {https://ieeexplore.ieee.org/document/6943213},
	urldate = {2022-02-23},
	author = {Laible, Stefan and Zell, Andreas},
	file = {Building local terrain maps using spatio-temporal classification for semantic robot localization | IEEE Conference Publication | IEEE Xplore:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/G57WCTZ6/6943213.html:text/html},
}


@article{rasmussen_combining_2002,
	title = {Combining {Laser} {Range}, {Color}, and {Texture} {Cues} for {Autonomous} {Road} {Following}},
	url = {https://www.nist.gov/publications/combining-laser-range-color-and-texture-cues-autonomous-road-following},
	abstract = {We describe preliminary results on combining depth information from a laser range-finder and color and texture image cues to train classifiers to segment ill-st},
	language = {en},
	urldate = {2022-02-22},
	author = {Rasmussen, C. E.},
	month = may,
	year = {2002},
	note = {Last Modified: 2017-02-17T12:56-05:00},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/F2S7P5JL/Rasmussen - 2002 - Combining Laser Range, Color, and Texture Cues for.pdf:application/pdf;Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/7MB9A8NW/combining-laser-range-color-and-texture-cues-autonomous-road-following.html:text/html},
}

@inproceedings{reymann_improving_2015,
	title = {Improving {LiDAR} point cloud classification using intensities and multiple echoes},
	doi = {10.1109/IROS.2015.7354098},
	abstract = {Besides precise and dense geometric information, some LiDARs also provide intensity information and multiple echoes, information that can advantageously be exploited to enhance the performance of the purely geometric classification approaches. This information indeed depends on the physical nature of the perceived surfaces, and is not strongly impacted by the scene illumination - contrary to visual information. This article investigates how such information can augment the precision of a point cloud classifier. It presents an empirical evaluation of a low cost LiDAR, introduces features related to the intensity and multiple echoes and their use in a hierarchical classification scheme. Results on varied outdoor scenes are depicted, and show that more precise class identification can be achieved using the intensity and multiple echoes than when using only geometric features.},
	booktitle = {2015 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Reymann, Christophe and Lacroix, Simon},
	month = sep,
	year = {2015},
	keywords = {Laser beams, Laser radar, Robot sensing systems, Three-dimensional displays, Visualization},
	pages = {5122--5128},
	file = {Submitted Version:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/GSPGXUF4/Reymann and Lacroix - 2015 - Improving LiDAR point cloud classification using i.pdf:application/pdf;IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/36489P6C/7354098.html:text/html},
}

@inproceedings{walas_terrain_2014,
	title = {Terrain classification using {Laser} {Range} {Finder}},
	doi = {10.1109/IROS.2014.6943273},
	abstract = {This paper presents terrain classification method based on the intensity readings from Laser Range Finder. The classification is performed on the feature vectors obtained using statistical descriptors or Fourier Transform computed for the patches of the intensity map for each terrain sample. As a classifier Support Vector Machines were used. For the set of 12 terrains results of classification are reaching the level of 98\% of the correctly recognized terrain samples. The proposed approach has a low computational cost, which is required for its real time applications. The article begins with the description of the experimental setup followed by the presentation of the proposed feature vectors for the registered intensity maps. Next, classification results, using introduced features, are given and compared to other approaches found in literature. At the end concluding remarks are given.},
	booktitle = {2014 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Walas, Krzysztof and Nowicki, Michal},
	month = sep,
	year = {2014},
	note = {ISSN: 2153-0866},
	keywords = {Capacitance-voltage characteristics, Lasers, Legged locomotion, Measurement by laser beam, Robot sensing systems, Vectors},
	pages = {5003--5009},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/LUTG8P99/6943273.html:text/html},
}

@article{wietrzykowski_boosting_2014,
	title = {Boosting support vector machines for {RGB}-{D} based terrain classification},
	volume = {8},
	issn = {1897-8649, 2080-2145},
	url = {https://bibliotekanauki.pl/articles/950938},
	abstract = {This paper deals with the terrain classification problem for an autonomous mobile robot. The robot is designed to opera…},
	language = {en},
	number = {3},
	urldate = {2022-02-23},
	journal = {Journal of Automation Mobile Robotics and Intelligent Systems},
	author = {Wietrzykowski, J. and Belter, D.},
	year = {2014},
	pages = {28--34},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/4HAHJXXL/Wietrzykowski and Belter - 2014 - Boosting support vector machines for RGB-D based t.pdf:application/pdf;Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/84PKDLWP/950938.html:text/html},
}

@article{wang_road_nodate,
	title = {Road {Terrain} {Type} {Classification} based on {Laser} {Measurement} {System} {Data}},
	abstract = {For road vehicles, knowledge of terrain types is useful in improving passenger safety and comfort. The conventional methods are susceptible to vehicle speed variations and in this paper we present a method of using Laser Measurement System (LMS) data for speed independent road type classification. Experiments were carried out with an instrumented road vehicle (CRUISE), by manually driving on a variety of road terrain types namely Asphalt, Concrete, Grass, and Gravel roads at different speeds. A looking down LMS is used for capturing the terrain data. The range data is capable of capturing the structural differences while the remission values are used to observe anomalies in surface reflectance properties. Both measurements are combined and used in a Support Vector Machines Classifier to achieve an average accuracy of 95\% on different road types.},
	language = {en},
	author = {Wang, Shifeng},
	pages = {13},
	file = {Wang - Road Terrain Type Classification based on Laser Me.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/PY8QVPXC/Wang - Road Terrain Type Classification based on Laser Me.pdf:application/pdf},
}


@article{mijakovska_generating_2014,
	title = {Generating {3D} {Model} from {Video}},
	volume = {5},
	doi = {10.5121/acij.2014.5602},
	abstract = {In this paper the process of 3D modelling from video is presented. Analysed previous research related to
this process, and specifically described algorithms for detecting and matching key points. We described
their advantages and disadvantages, and made a critical analysis of algorithms. In this paper, the three
detectors (SUSAN, Plessey and Förstner) are tested and compare. We used video taken with hand held
camera of a cube and compare these detectors on it (taking into account their parameters of accuracy and
repeatability). In conclusion, we practically made 3D model of the cube from video used these detectors in
the first step of the process and three algorithms (RANSAC, MSAC and MLESAC) for matching data.},
	journal = {Advanced Computing: An International Journal},
	author = {Mijakovska, Svetlana and Nedelkovski, Igor and Popovski, Filip},
	month = dec,
	year = {2014},
	pages = {13--19},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/973VTBPW/Mijakovska et al. - 2014 - Generating 3D Model from Video.pdf:application/pdf},
}


@article{haselich_terrain_2011,
	title = {Terrain {Classification} with {Markov} {Random} {Fields} on fused {Camera} and {3D} {Laser} {Range} {Data}},
	abstract = {In this paper we consider the problem of inter-preting the data of a 3D laser range finder. The surrounding terrain is segmented into a 2D grid where each cell can be an obstacle or negotiable region. A Markov random field models the relationships between neighboring terrain cells and classifies the whole surrounding terrain. This allows us to add context sensitive information to the grid cells where sensor noise or uncertainties could lead to false classification. Camera images provide a perfect complement to the laser range data because they add color and texture features to the point cloud. Therefore camera images are fused with the 3D points and the features from both sensors are considered for classification. We present a novel approach for online terrain classification from fused camera and laser range data by applying a Markov random field. In our experiments we achieved a recall ratio of about 90\% for detecting streets and obstacles and prove that our approach is fast enough to be used on an autonomous mobile robot in real time.},
	author = {Häselich, Marcel and Arends, Marc and Lang, Dagmar and Paulus, Dietrich},
	month = jan,
	year = {2011},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/BK6ZKXBA/Häselich et al. - 2011 - Terrain Classification with Markov Random Fields o.pdf:application/pdf},
}


@article{zhao_fusion_2014,
	title = {Fusion of {3D}-{LIDAR} and camera data for scene parsing},
	volume = {25},
	doi = {10.1016/j.jvcir.2013.06.008},
	abstract = {Fusion of information gathered from multiple sources is essential to build a comprehensive situation picture for autonomous ground vehicles. In this paper, an approach which performs scene parsing and data fusion for a 3D-LIDAR scanner (Velodyne HDL-64E) and a video camera is described. First of all, a geometry segmentation algorithm is proposed for detection of obstacles and ground areas from data collected by the Velodyne scanner. Then, corresponding image collected by the video camera is classified patch by patch into more detailed categories. After that, parsing result of each frame is obtained by fusing result of Velodyne data and that of image using the fuzzy logic inference framework. Finally, parsing results of consecutive frames are smoothed by the Markov random field based temporal fusion method. The proposed approach has been evaluated with datasets collected by our autonomous ground vehicle testbed in both rural and urban areas. The fused results are more reliable than that acquired via analysis of only images or Velodyne data.},
	journal = {Journal of Visual Communication and Image Representation},
	author = {Zhao, Gangqiang and Xiao, Xuhong and Yuan, Junsong and Ng, Gee-Wah},
	month = jan,
	year = {2014},
	pages = {165--183},
}


@article{chellappa_classification_1985,
	title = {Classification of textures using {Gaussian} {Markov} random fields},
	volume = {33},
	issn = {0096-3518},
	doi = {10.1109/TASSP.1985.1164641},
	abstract = {The problem of texture classification arises in several disciplines such as remote sensing, computer vision, and image analysis. In this paper we present two feature extraction methods for the classification of textures using two-dimensional (2-D) Markov random field (MRF) models. It is assumed that the given M × M texture is generated by a Gaussian MRF model. In the first method, the least square (LS) estimates of model parameters are used as features. In the second method, using the notion of sufficient statistics, it is shown that the sample correlations over a symmetric window including the origin are optimal features for classification. Simple minimum distance classifiers using these two feature sets yield good classification accuracies for a seven class problem.},
	number = {4},
	journal = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
	author = {Chellappa, R. and Chatterjee, S.},
	month = aug,
	year = {1985},
	note = {Conference Name: IEEE Transactions on Acoustics, Speech, and Signal Processing},
	keywords = {Computer vision, Data mining, Decorrelation, Feature extraction, Humans, Laplace equations, Least squares approximation, Markov random fields, Remote sensing, Statistics},
	pages = {959--963},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/HTU6VC7A/1164641.html:text/html},
}


@article{breiman_random_2001,
	title = {Random {Forests}},
	volume = {45},
	issn = {1573-0565},
	url = {https://doi.org/10.1023/A:1010933404324},
	doi = {10.1023/A:1010933404324},
	abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
	language = {en},
	number = {1},
	urldate = {2022-02-23},
	journal = {Machine Learning},
	author = {Breiman, Leo},
	month = oct,
	year = {2001},
	pages = {5--32},
	file = {Springer Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/AHAS877R/Breiman - 2001 - Random Forests.pdf:application/pdf},
}
@article{breiman_random_2001,
	title = {Random {Forests}},
	volume = {45},
	issn = {1573-0565},
	url = {https://doi.org/10.1023/A:1010933404324},
	doi = {10.1023/A:1010933404324},
	abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
	language = {en},
	number = {1},
	urldate = {2022-02-23},
	journal = {Machine Learning},
	author = {Breiman, Leo},
	month = oct,
	year = {2001},
	pages = {5--32},
	file = {Springer Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/AHAS877R/Breiman - 2001 - Random Forests.pdf:application/pdf},
}


@article{wallach_conditional_nodate,
	title = {Conditional {Random} {Fields}: {An} {Introduction}},
	language = {en},
	author = {Wallach, Hanna M},
	pages = {9},
	file = {Wallach - Conditional Random Fields An Introduction.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/6KYK7DW8/Wallach - Conditional Random Fields An Introduction.pdf:application/pdf},
}

  @Article{WEKA,
    title = {Open-Source Machine Learning: {R} Meets {Weka}},
    author = {Kurt Hornik and Christian Buchta and Achim Zeileis},
    journal = {Computational Statistics},
    year = {2009},
    volume = {24},
    number = {2},
    pages = {225--232},
    doi = {10.1007/s00180-008-0119-7},
  }


@article{wang_two-stage_2018,
	title = {Two-{Stage} {Road} {Terrain} {Identification} {Approach} for {Land} {Vehicles} {Using} {Feature}-{Based} and {Markov} {Random} {Field} {Algorithm}},
	volume = {33},
	issn = {1941-1294},
	doi = {10.1109/MIS.2017.2581327},
	abstract = {Road terrain identification is one of the important tasks for driving assistant systems or autonomous land vehicles. It plays a key role in improving driving strategy and enhancing fuel efficiency. In this paper, a two-stage approach using multiple sensors is presented. In the first stage, a feature-based identification approach is performed using an accelerometer, a camera, and downward-looking and forward-looking laser range finders (LRFs). This produces four classification label sequences. In the second stage, a majority vote is implemented for each label sequences to match them into synchronized road patches. Then a Markov Random Field (MRF) model is designed to generate the final optimized identification results to improve the forward-looking LRF. This approach enables the vehicle to observe the upcoming road terrain before moving onto it by fusing all the classification results using an MRF algorithm. The experiments show this approach improved the terrain identification accuracy and robustness significantly for some familiar road terrains.},
	number = {1},
	journal = {IEEE Intelligent Systems},
	author = {Wang, Shifeng and Kodagoda, Sarath and Shi, Lei and Dai, Xiang},
	month = jan,
	year = {2018},
	note = {Conference Name: IEEE Intelligent Systems},
	keywords = {Adaptation models, Analytical models, feature extraction, Hidden Markov models, machine learning, Markov Random Field, Petri nets, road terrain, Road transportation, Robot kinematics},
	pages = {29--39},
	file = {Full Text:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/FMV3V8IP/Wang et al. - 2018 - Two-Stage Road Terrain Identification Approach for.pdf:application/pdf},
}


@article{hong_road_2002,
	title = {Road {Detection} and {Tracking} for {Autonomous} {Mobile} {Robots}},
	volume = {4715},
	doi = {10.1117/12.474463},
	abstract = {As part of the Army's Demo III project, a sensor-based system has been developed to identify roads and to enable a mobile robot to drive along them. A ladar sensor, which produces range images, and a color camera are used in conjunction to locate the road surface and its boundaries. Sensing is used to constantly update an internal world model of the road surface. The world model is used to predict the future position of the road and to focus the attention of the sensors on the relevant regions in their respective images. The world model also determines the most suitable algorithm for locating and tracking road features in the images based on the current task and sensing information. The planner uses information from the world model to determine the best path for the vehicle along the road. Several different algorithms have been developed and tested on a diverse set of road sequences. The road types include some paved roads with lanes, but most of the sequences are of unpaved roads, including dirt and gravel roads. The algorithms compute various features of the road images including smoothness in the world model map and in the range domain, and color features and texture in the color domain. Performance in road detection and tracking are described and examples are shown of the system in action.},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	author = {Hong, Tsai and Rasmussen, Christopher and Chang, Tommy and Shneier, Michael},
	month = may,
	year = {2002},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/9QJBHCCT/Hong et al. - 2002 - Road Detection and Tracking for Autonomous Mobile .pdf:application/pdf},
}


@article{breiman_random_2001,
	title = {Random {Forests}},
	volume = {45},
	issn = {1573-0565},
	url = {https://doi.org/10.1023/A:1010933404324},
	doi = {10.1023/A:1010933404324},
	abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
	language = {en},
	number = {1},
	urldate = {2022-02-23},
	journal = {Machine Learning},
	author = {Breiman, Leo},
	month = oct,
	year = {2001},
	note = {Number: 1},
	pages = {5--32},
	file = {Springer Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/WLA8UH47/Breiman - 2001 - Random Forests.pdf:application/pdf},
}


@inproceedings{ho_random_1995,
	title = {Random decision forests},
	volume = {1},
	doi = {10.1109/ICDAR.1995.598994},
	abstract = {Decision trees are attractive classifiers due to their high execution speed. But trees derived with traditional methods often cannot be grown to arbitrary complexity for possible loss of generalization accuracy on unseen data. The limitation on complexity usually means suboptimal accuracy on training data. Following the principles of stochastic modeling, we propose a method to construct tree-based classifiers whose capacity can be arbitrarily expanded for increases in accuracy for both training and unseen data. The essence of the method is to build multiple trees in randomly selected subspaces of the feature space. Trees in, different subspaces generalize their classification in complementary ways, and their combined classification can be monotonically improved. The validity of the method is demonstrated through experiments on the recognition of handwritten digits.},
	booktitle = {Proceedings of 3rd {International} {Conference} on {Document} {Analysis} and {Recognition}},
	author = {Ho, Tin Kam},
	month = aug,
	year = {1995},
	keywords = {Classification tree analysis, Decision trees, Handwriting recognition, Hidden Markov models, Multilayer perceptrons, Optimization methods, Stochastic processes, Testing, Tin, Training data},
	pages = {278--282 vol.1},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/JXDMCC6G/598994.html:text/html},
}


@inproceedings{reymann_improving_2015,
	title = {Improving {LiDAR} point cloud classification using intensities and multiple echoes},
	doi = {10.1109/IROS.2015.7354098},
	abstract = {Besides precise and dense geometric information, some LiDARs also provide intensity information and multiple echoes, information that can advantageously be exploited to enhance the performance of the purely geometric classification approaches. This information indeed depends on the physical nature of the perceived surfaces, and is not strongly impacted by the scene illumination - contrary to visual information. This article investigates how such information can augment the precision of a point cloud classifier. It presents an empirical evaluation of a low cost LiDAR, introduces features related to the intensity and multiple echoes and their use in a hierarchical classification scheme. Results on varied outdoor scenes are depicted, and show that more precise class identification can be achieved using the intensity and multiple echoes than when using only geometric features.},
	booktitle = {2015 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Reymann, Christophe and Lacroix, Simon},
	month = sep,
	year = {2015},
	keywords = {Laser radar, Three-dimensional displays, Robot sensing systems, Laser beams, Visualization},
	pages = {5122--5128},
	file = {Submitted Version:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/K39MLIZD/Reymann and Lacroix - 2015 - Improving LiDAR point cloud classification using i.pdf:application/pdf;IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/CVE6P4NE/7354098.html:text/html},
}


@inproceedings{khan_high_2011,
	address = {Barcelona, Spain},
	title = {High resolution visual terrain classification for outdoor robots},
	isbn = {978-1-4673-0063-6 978-1-4673-0062-9 978-1-4673-0061-2},
	url = {http://ieeexplore.ieee.org/document/6130362/},
	doi = {10.1109/ICCVW.2011.6130362},
	abstract = {In this paper we investigate SURF features for visual terrain classiﬁcation for outdoor mobile robots. The image is divided into a grid and SURF features are calculated on the intersections of this grid. These features are then used to train a classiﬁer that can differentiate between different terrain classes. Images of ﬁve different terrain types are taken using a single camera mounted on a mobile outdoor robot. We further introduce another descriptor, which is a modiﬁed form of the dense Daisy descriptor. Random forests are used for classiﬁcation on each descriptor. Classiﬁcation results of SURF and Daisy descriptors are compared with the results from traditional texture descriptors like LBP, LTP and LATP. It is shown that SURF features perform better than other descriptors at higher resolutions. Daisy features, although not better than SURF features, also perform better than the three texture descriptors at high resolution.},
	language = {en},
	urldate = {2022-02-22},
	booktitle = {2011 {IEEE} {International} {Conference} on {Computer} {Vision} {Workshops} ({ICCV} {Workshops})},
	publisher = {IEEE},
	author = {Khan, Yasir Niaz and Komma, Philippe and Zell, Andreas},
	month = nov,
	year = {2011},
	pages = {1014--1021},
	file = {Khan et al. - 2011 - High resolution visual terrain classification for .pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/9J64RYDS/Khan et al. - 2011 - High resolution visual terrain classification for .pdf:application/pdf},
}


@inproceedings{wietrzykowski_context-aware_2019,
	address = {Cham},
	title = {Context-{Aware} {Recognition} of {Drivable} {Terrain} with {Automated} {Parameters} {Estimation}},
	isbn = {978-3-030-01370-7},
	doi = {10.1007/978-3-030-01370-7_49},
	abstract = {This paper deals with the terrain classification problem for autonomous service robots in semi-structured outdoor environments. The aim is to recognize the drivable terrain in front of a robot that navigates on roads of different surfaces, avoiding areas that are considered non-drivable. Since the system should be robust to such factors as changing lighting conditions, mud and fallen leaves, we employ multi-sensor perception with a monocular camera and a 2D laser scanner. The labeling of the terrain obtained from a Random Trees classifier is refined by context-aware inference using the Conditional Random Field. We demonstrate that automatic learning of the parameters for Conditional Random Fields improves results in comparison to similar approaches without the context-aware inference or with parameters set by hand.},
	language = {en},
	booktitle = {Intelligent {Autonomous} {Systems} 15},
	publisher = {Springer International Publishing},
	author = {Wietrzykowski, Jan and Skrzypczyński, Piotr},
	editor = {Strand, Marcus and Dillmann, Rüdiger and Menegatti, Emanuele and Ghidoni, Stefano},
	year = {2019},
	pages = {626--638},
}

@inproceedings{takubo_ndt_2009,
	title = {{NDT} scan matching method for high resolution grid map},
	doi = {10.1109/IROS.2009.5353908},
	abstract = {A new convergence calculation method of the normal distributions transform (NDT) scan matching for high resolution of grid maps is proposed. NDT scan matching algorithm usually has a good effect on large grids, so it is difficult to generate the detailed map with small grids. The proposed method employs interactive closest point (ICP) algorithm to find corresponding point, and it also enlarges the convergence area by modifying the eigenvalue of normal distribution so that the evaluation value is driven effectively for the pairing data. In addition, outlier elimination process is implemented to the scanning for sub-grid scale object. The scanning data from laser range finder (LRF) have error but its set of detected small object can be clustered to determine the center of mass (CoM) and the outlier data. The outlier commonly locates behind true points and it can be eliminated when the robot observes from other point. Experimental result shows the effectiveness of the proposed convergence algorithm and outlier elimination method.},
	booktitle = {2009 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Takubo, Tomohito and Kaminade, Takuya and Mae, Yasushi and Ohara, Kenichi and Arai, Tatsuo},
	month = oct,
	year = {2009},
	note = {ISSN: 2153-0866},
	keywords = {Convergence, Eigenvalues and eigenfunctions, Gaussian distribution, Intelligent robots, Iterative algorithms, Iterative closest point algorithm, Mesh generation, Object detection, Simultaneous localization and mapping, USA Councils},
	pages = {1517--1522},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/YQ38SZU8/5353908.html:text/html},
}


@misc{noauthor_gpsgov_nodate,
	title = {{GPS}.gov: {GPS} {Accuracy}},
	url = {https://www.gps.gov/systems/gps/performance/accuracy/},
	urldate = {2022-04-06},
	file = {GPS.gov\: GPS Accuracy:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/RQYWAXKY/accuracy.html:text/html},
}


@inproceedings{biber_normal_2003,
	title = {The {Normal} {Distributions} {Transform}: {A} {New} {Approach} to {Laser} {Scan} {Matching}},
	volume = {3},
	isbn = {978-0-7803-7860-5},
	shorttitle = {The {Normal} {Distributions} {Transform}},
	doi = {10.1109/IROS.2003.1249285},
	abstract = {Matching 2D range scans is a basic component of many localization and mapping algorithms. Most scan match algorithms require finding correspondences between the used features, i.e. points or lines. We propose an alternative representation for a range scan, the normal distributions transform. Similar to an occupancy grid, we subdivide the 2D plane into cells. To each cell, we assign a normal distribution, which locally models the probability of measuring a point. The result of the transform is a piecewise continuous and differentiable probability density, that can be used to match another scan using Newton's algorithm. Thereby, no explicit correspondences have to be established. We present the algorithm in detail and show the application to relative position tracking and simultaneous localization and map building (SLAM). First results on real data demonstrate, that the algorithm is capable to map unmodified indoor environments reliable and in real time, even without using odometry data.},
	author = {Biber, Peter and Straßer, Wolfgang},
	month = nov,
	year = {2003},
	pages = {2743--2748 vol.3},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/53JB4P3J/Biber and Straßer - 2003 - The Normal Distributions Transform A New Approach.pdf:application/pdf},
}


@misc{MATLAB_PCFITPLANE,
	title = {Fit plane to 3-{D} point cloud - {MATLAB} pcfitplane},
	url = {https://www.mathworks.com/help/vision/ref/pcfitplane.html},
	urldate = {2022-12-08},
	file = {Fit plane to 3-D point cloud - MATLAB pcfitplane:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/QSXGXB8S/pcfitplane.html:text/html},
}


@misc{xaviborras_english_2014,
	title = {English:  {RANSAC}. {Inliers}-{Outliers}},
	shorttitle = {English},
	url = {https://commons.wikimedia.org/wiki/File:RANSAC_Inliers_and_Outliers.png},
	urldate = {2022-12-08},
	author = {{Xavi.borras}},
	month = nov,
	year = {2014},
	file = {Wikimedia Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/SBJ2SGXV/FileRANSAC_Inliers_and_Outliers.html:text/html},
}


@misc{alam_using_2022,
	title = {Using the {Random} {Sample} {Consensus} ({RANSAC}) algorithm in {Python}},
	url = {https://hands-on.cloud/using-the-random-sample-consensus-ransac-algorithm-in-python/},
	abstract = {This article covers how the RANSAC algorithm works, and compares its results with the Linear Regression algorithm.},
	language = {en-us},
	urldate = {2022-12-08},
	journal = {Hands-On-Cloud},
	author = {Alam, Bashir},
	month = apr,
	year = {2022},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/5NDBI6KS/using-the-random-sample-consensus-ransac-algorithm-in-python.html:text/html},
}


@misc{noauthor_object-oriented_nodate,
	title = {Object-oriented tools for fitting conics and quadrics},
	url = {https://www.mathworks.com/matlabcentral/fileexchange/87584-object-oriented-tools-for-fitting-conics-and-quadrics},
	abstract = {A tool set for fitting various conics and quadric surfaces, e.g., ellipses, cylinders, spheres, planes, cones, and lines.},
	language = {en},
	urldate = {2022-12-08},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/9JZABB45/87584-object-oriented-tools-for-fitting-conics-and-quadrics.html:text/html},
}


@misc{noauthor_shapiro-wilk_nodate,
	title = {Shapiro-{Wilk} and {Shapiro}-{Francia} normality tests.},
	url = {https://www.mathworks.com/matlabcentral/fileexchange/13964-shapiro-wilk-and-shapiro-francia-normality-tests},
	abstract = {Shapiro-Wilk \& Shapiro-Francia parametric hypothesis test of composite normality.},
	language = {en},
	urldate = {2022-12-08},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/V33HVMAE/13964-shapiro-wilk-and-shapiro-francia-normality-tests.html:text/html},
}


@article{genuer_random_2017,
	title = {Random {Forests} for {Big} {Data}},
	volume = {9},
	issn = {22145796},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2214579616301939},
	doi = {10.1016/j.bdr.2017.07.003},
	language = {en},
	urldate = {2022-12-09},
	journal = {Big Data Research},
	author = {Genuer, Robin and Poggi, Jean-Michel and Tuleau-Malot, Christine and Villa-Vialaneix, Nathalie},
	month = sep,
	year = {2017},
	pages = {28--46},
	file = {Submitted Version:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/4TVGYUY3/Genuer et al. - 2017 - Random Forests for Big Data.pdf:application/pdf},
}

@article{breiman_no_2001,
	title = {[{No} title found]},
	volume = {45},
	issn = {08856125},
	url = {http://link.springer.com/10.1023/A:1010933404324},
	doi = {10.1023/A:1010933404324},
	number = {1},
	urldate = {2022-12-09},
	journal = {Machine Learning},
	author = {Breiman, Leo},
	year = {2001},
	pages = {5--32},
	file = {Full Text:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/6477W5JZ/Breiman - 2001 - [No title found].pdf:application/pdf},
}
